<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[const常量与define宏定义的区别]]></title>
    <url>%2F2017%2Fconst-define.html</url>
    <content type="text"><![CDATA[#define RADIUS 100; const float RADIUS = 100; (1) 编译器处理方式不同 define宏是在预处理阶段展开。 const常量是编译运行阶段使用。 (2) 类型和安全检查不同 define宏没有类型，不做任何类型检查，仅仅是展开。 const常量有具体的类型，在编译阶段会执行类型检查。 (3) 存储方式不同 define宏仅仅是展开，有多少地方使用，就展开多少次，不会分配内存。（宏定义不分配内存，变量定义分配内存。） const常量会在内存中分配(可以是堆中也可以是栈中)。 (4)const 可以节省空间，避免不必要的内存分配。 例如：#define PI 3.14159 //常量宏 const doulbe Pi=3.14159; //此时并未将Pi放入ROM中 ...... double i=Pi; //此时为Pi分配内存，以后不再分配！ double I=PI; //编译期间进行宏替换，分配内存 double j=Pi; //没有内存分配 double J=PI; //再进行宏替换，又一次分配内存！ const定义常量从汇编的角度来看，只是给出了对应的内存地址，而不是象#define一样给出的是立即数，所以，const定义的常量在程序运行过程中只有一份拷贝（因为是全局的只读变量，存在静态区），而 #define定义的常量在内存中有若干个拷贝。 (5) 提高了效率。 编译器通常不为普通const常量分配存储空间，而是将它们保存在符号表中，这使得它成为一个编译期间的常量，没有了存储与读内存的操作，使得它的效率也很高。(6) 宏替换只作替换，不做计算，不做表达式求解;宏预编译时就替换了，程序运行时，并不分配内存。const 与 #define的比较 C++ 语言可以用const来定义常量，也可以用 #define来定义常量。但是前者比后者有更多的优点： （1） const常量有数据类型，而宏常量没有数据类型。编译器可以对前者进行类型安全检查。而对后者只进行字符替换，没有类型安全检查，并且在字符替换可能会产生意料不到的错误（边际效应）。 （2） 有些集成化的调试工具可以对const常量进行调试，但是不能对宏常量进行调试。 ###【规则5-2-1】在C++ 程序中只使用const常量而不使用宏常量，即const常量完全取代宏常量。 ###【规则5-3-1】需要对外公开的常量放在头文件中，不需要对外公开的常量放在定义文件的头部。为便于管理，可以把不同模块的常量集中存放在一个公共的头文件中。 ###【规则5-3-2】如果某一常量与其它常量密切相关，应在定义中包含这种关系，而不应给出一些孤立的值。 例如： const float RADIUS = 100; const float DIAMETER = RADIUS * 2; 类中的常量有时我们希望某些常量只在类中有效。由于#define定义的宏常量是全局的，不能达到目的，于是想当然地觉得应该用const修饰数据成员来实现。const数据成员的确是存在的，但其含义却不是我们所期望的。const数据成员只在某个对象生存期内是常量，而对于整个类而言却是可变的，因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。不能在类声明中初始化const数据成员。以下用法是错误的，因为类的对象未被创建时，编译器不知道SIZE的值是什么。 class A {… const int SIZE = 100; // 错误，企图在类声明中初始化const数据成员 int array[SIZE]; // 错误，未知的SIZE }; const数据成员的初始化只能在类构造函数的初始化表中进行，例如 class A {… A(int size); // 构造函数 const int SIZE ; }; A::A(int size) : SIZE(size) // 构造函数的初始化表 { … } A a(100); // 对象 a 的SIZE值为100 A b(200); // 对象 b 的SIZE值为200 怎样才能建立在整个类中都恒定的常量呢？别指望const数据成员了，应该用类中的枚举常量来实现。例如 class A {… enum { SIZE1 = 100, SIZE2 = 200}; //枚举常量 int array1[SIZE1]; int array2[SIZE2]; }; 枚举常量不会占用对象的存储空间，它们在编译时被全部求值。枚举常量的缺点是：它的隐含数据类型是整数，其最大值有限，且不能表示浮点数（如PI=3.14159）。sizeof(A) = 1200;其中枚举部长空间。 enum EM { SIZE1 = 100, SIZE2 = 200}; //枚举常量 sizeof（EM） = 4；]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[new与malloc的区别详解]]></title>
    <url>%2F2017%2Fnew-malloc.html</url>
    <content type="text"><![CDATA[申请的内存所在位置new操作符从自由存储区（free store）上为对象动态分配内存空间，而malloc函数从堆上动态分配内存。自由存储区是C++基于new操作符的一个抽象概念，凡是通过new操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C语言使用malloc从堆上分配内存，使用free释放已分配的对应内存。 那么自由存储区是否能够是堆（问题等价于new是否能在堆上动态分配内存），这取决于operator new 的实现细节。自由存储区不仅可以是堆，还可以是静态存储区，这都看operator new在哪里为对象分配内存。 特别的，new甚至可以不为对象分配内存！定位new的功能可以办到这一点： new (place_address) type place_address为一个指针，代表一块内存的地址。当使用上面这种仅以一个地址调用new操作符时，new操作符调用特殊的operator new，也就是下面这个版本： void * operator new (size_t,void *) //不允许重定义这个版本的operator new 这个operator new不分配任何的内存，它只是简单地返回指针实参，然后右new表达式负责在place_address指定的地址进行对象的初始化工作。 2.返回类型安全性new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故new是符合类型安全性的操作符。而malloc内存分配成功则是返回void * ，需要通过强制类型转换将void*指针转换成我们需要的类型。 类型安全很大程度上可以等价于内存安全，类型安全的代码不会试图方法自己没被授权的内存区域。关于C++的类型安全性可说的又有很多了。 3.内存分配失败时的返回值new内存分配失败时，会抛出bac_alloc异常，它不会返回NULL；malloc分配内存失败时返回NULL。在使用C语言时，我们习惯在malloc分配内存后判断分配是否成功： int *a = (int *)malloc ( sizeof (int )); if(NULL == a) { ... } else { ... } 从C语言走入C++阵营的新手可能会把这个习惯带入C++： int * a = new int(); if(NULL == a) { ... } else { ... } 实际上这样做一点意义也没有，因为new根本不会返回NULL，而且程序能够执行到if语句已经说明内存分配成功了，如果失败早就抛异常了。正确的做法应该是使用异常机制： try { int *a = new int(); } catch (bad_alloc) { ... } 如果你想顺便了解下异常基础，可以看http://www.cnblogs.com/QG-whz/p/5136883.htmlC++ 异常机制分析。 4.是否需要指定内存大小使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算，而malloc则需要显式地指出所需内存的尺寸。 class A{...} A * ptr = new A; A * ptr = (A *)malloc(sizeof(A)); //需要显式指定所需内存大小sizeof(A); 当然了，我这里使用malloc来为我们自定义类型分配内存是不怎么合适的，请看下一条。 5.是否调用构造函数/析构函数使用new操作符来分配对象内存时会经历三个步骤：第一步：调用operator new 函数（对于数组是operator new[]）分配一块足够大的，原始的，未命名的内存空间以便存储特定类型的对象。第二步：编译器运行相应的构造函数以构造对象，并为其传入初值。第三部：对象构造完成后，返回一个指向该对象的指针。 使用delete操作符来释放对象内存时会经历两个步骤：第一步：调用对象的析构函数。第二步：编译器调用operator delete(或operator delete[])函数释放内存空间。总之来说，new/delete会调用对象的构造函数/析构函数以完成对象的构造/析构。而malloc则不会。如果你不嫌啰嗦可以看下我的例子： class A { public: A() :a(1), b(1.11){} private: int a; double b; }; int main() { A * ptr = (A*)malloc(sizeof(A)); return 0; } 在return处设置断点，观看ptr所指内存的内容： 可以看出A的默认构造函数并没有被调用，因为数据成员a,b的值并没有得到初始化，这也是上面我为什么说使用malloc/free来处理C++的自定义类型不合适，其实不止自定义类型，标准库中凡是需要构造/析构的类型通通不合适。 而使用new来分配对象时： int main() { A * ptr = new A; } 查看程序生成的汇编代码可以发现，A的默认构造函数被调用了： 6.对数组的处理C++提供了new[]与delete[]来专门处理数组类型: A * ptr = new A[10];//分配10个A对象 使用new[]分配的内存必须使用delete[]进行释放： delete [] ptr; new对数组的支持体现在它会分别调用构造函数函数初始化每一个数组元素，释放对象时为每个对象调用析构函数。注意delete[]要与new[]配套使用，不然会找出数组对象部分释放的现象，造成内存泄漏。 至于malloc，它并知道你在这块内存上要放的数组还是啥别的东西，反正它就给你一块原始的内存，在给你个内存的地址就完事。所以如果要动态分配一个数组的内存，还需要我们手动自定数组的大小： int * ptr = (int *) malloc( sizeof(int)* 10 );//分配一个10个int元素的数组 7.new与malloc是否可以相互调用operator new /operator delete的实现可以基于malloc，而malloc的实现不可以去调用new。下面是编写operator new /operator delete 的一种简单方式，其他版本也与之类似： void * operator new (sieze_t size) { if(void * mem = malloc(size) return mem; else throw bad_alloc(); } void operator delete(void *mem) noexcept { free(mem); } 8.是否可以被重载opeartor new /operator delete可以被重载。标准库是定义了operator new函数和operator delete函数的8个重载版本： //这些版本可能抛出异常 void * operator new(size_t); void * operator new[](size_t); void * operator delete (void * )noexcept; void * operator delete[](void *0）noexcept; //这些版本承诺不抛出异常 void * operator new(size_t ,nothrow_t&amp;) noexcept; void * operator new[](size_t, nothrow_t&amp; ); void * operator delete (void *,nothrow_t&amp; )noexcept; void * operator delete[](void *0,nothrow_t&amp; ）noexcept; 我们可以自定义上面函数版本中的任意一个，前提是自定义版本必须位于全局作用域或者类作用域中。太细节的东西不在这里讲述，总之，我们知道我们有足够的自由去重载operator new /operator delete ,以决定我们的new与delete如何为对象分配内存，如何回收对象。 而malloc/free并不允许重载。 9. 能够直观地重新分配内存使用malloc分配的内存后，如果在使用过程中发现内存不足，可以使用realloc函数进行内存重新分配实现内存的扩充。realloc先判断当前的指针所指内存是否有足够的连续空间，如果有，原地扩大可分配的内存地址，并且返回原来的地址指针；如果空间不够，先按照新指定的大小分配空间，将原有数据从头到尾拷贝到新分配的内存区域，而后释放原来的内存区域。 new没有这样直观的配套设施来扩充内存。 10. 客户处理内存分配不足在operator new抛出异常以反映一个未获得满足的需求之前，它会先调用一个用户指定的错误处理函数，这就是new-handler。new_handler是一个指针类型： namespace std { typedef void (*new_handler)(); } 指向了一个没有参数没有返回值的函数,即为错误处理函数。为了指定错误处理函数，客户需要调用set_new_handler，这是一个声明于的一个标准库函数: namespace std { new_handler set_new_handler(new_handler p ) throw(); } set_new_handler的参数为new_handler指针，指向了operator new 无法分配足够内存时该调用的函数。其返回值也是个指针，指向set_new_handler被调用前正在执行（但马上就要发生替换）的那个new_handler函数。 对于malloc，客户并不能够去编程决定内存不足以分配时要干什么事，只能看着malloc返回NULL。 总结 malloc给你的就好像一块原始的土地，你要种什么需要自己在土地上来播种 而new帮你划好了田地的分块（数组），帮你播了种（构造函数），还提供其他的设施给你使用: 当然，malloc并不是说比不上new，它们各自有适用的地方。在C++这种偏重OOP的语言，使用new/delete自然是更合适的。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL中表和视图的区别与联系]]></title>
    <url>%2F2017%2FSQL-view.html</url>
    <content type="text"><![CDATA[1.视图是数据库数据的特定子集。可以禁止所有用户访问数据库表，而要求用户只能通过视图操作数据，这种方法可以保护用户和应用程序不受某些数据库修改的影响。2.视图是抽象的，他在使用时，从表里提取出数据，形成虚的表。不过对他的操作有很多的限制。 而且视图是永远不会自己消失的除非你删除它。视图有时会对提高效率有帮助。临时表几乎是不会对性能有帮助，是资源消耗者。视图一般随该数据库存放在一起，临时表永远都是在tempdb里的。4.视图适合于多表连接浏览时使用!不适合增、删、改.，存储过程适合于使用较频繁的SQL语句，这样可以提高执行效率! 视图和表的区别和联系区别：1、视图是已经编译好的sql语句。而表不是2、视图没有实际的物理记录。而表有。3、表是内容，视图是窗口4、表只用物理空间而视图不占用物理空间，视图只是逻辑概念的存在，表可以及时对它进行修改，但视图只能有创建的语句来修改5、表是内模式，视图是外模式6、视图是查看数据表的一种方法，可以查询数据表中某些字段构成的数据，只是一些SQL语句的集合。从安全的角度说，视图可以不给用户接触数据表，从而不知道表结构。7、表属于全局模式中的表，是实表；视图属于局部模式的表，是虚表。8、视图的建立和删除只影响视图本身，不影响对应的基本表。 联系：视图（view）是在基本表之上建立的表，它的结构（即所定义的列）和内容（即所有数据行）都来自基本表，它依据基本表存在而存在。一个视图可以对应一个基本表，也可以对应多个基本表。视图是基本表的抽象和在逻辑意义上建立的新关系。]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++字符串转数字,数字转字符串]]></title>
    <url>%2F2017%2Fint-to-str.html</url>
    <content type="text"><![CDATA[字符串转数字如将“32”转为32，将“3.1415”转为3.1415，将“567283”转为567283。使用： //Convert string to integer, more int atoi ( const char * str ); //Convert string to double, more double atof ( const char * str ); // Convert string to long integer long int atol ( const char * str ); //Read formatted data from string int sscanf ( const char * str, const char * format, ...); Example1:/ atoi,atof,atol example / #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; int main () { int a;float b;long c; a=atoi(&quot;32&quot;); b=atof(&quot;3.1415&quot;); c=atol(&quot;567283&quot;); printf (&quot;%d,%f,%d&quot;,a,b,c); return 0; } Output: 32,3.141500,567283 Example2: / sscanf example / #include int main () { int a;float b;long c; sscanf (“32,3.1415,567283”,”%d,%f,%d”,&amp;a,&amp;b,&amp;c); printf (“%d,%f,%d”,a,b,c); return 0; } Output: 32,3.141500,567283 数字转字符串如将32转为“32”，将3.1415转为“3.1415”，将567283转为“567283”。使用： //Write formatted data to string int sprintf ( char * str, const char * format, ... );//C++中为了安全性使用sprintf_s //Convert integer to string (non-standard function)//This function is not defined in ANSI-C and is not part of C++, but is supported by some compilers.//A standard-compliant alternative for some cases may be sprintf. char * itoa ( int value, char * str, int base ); Example3:/ sprintf example / #include &lt;stdio.h&gt; int main () { char a[10],b[10],c[10]; sprintf(a, &quot;%d&quot;, 32); sprintf(b, &quot;%f&quot;, 3.1415); sprintf(c, &quot;%d&quot;, 567283); printf(&quot;%s,%s,%s&quot;,a,b,c); return 0; } Output: 32,3.141500,567283 使用stringstream进行字符串与数字的转换// using stringstream constructors. #include &lt;iostream&gt; #include &lt;sstream&gt; using namespace std; int main () { int a;float b;long c; char d[10],e[10],f[10]; /* string to number */ stringstream ss; ss &lt;&lt; &quot;32&quot;; ss &gt;&gt; a; ss.clear(); ss &lt;&lt; &quot;3.1415&quot;; ss &gt;&gt; b; ss.clear(); ss &lt;&lt; &quot;567283&quot;; ss &gt;&gt; c; ss.clear(); cout&lt;&lt;a&lt;&lt;&quot;,&quot;&lt;&lt;b&lt;&lt;&quot;,&quot;&lt;&lt;c&lt;&lt;endl; /* number to string */ ss &lt;&lt; a; ss &gt;&gt; d; ss.clear(); ss &lt;&lt; b; ss &gt;&gt; e; ss.clear(); ss &lt;&lt; c; ss &gt;&gt; f; ss.clear(); cout&lt;&lt;d&lt;&lt;&quot;,&quot;&lt;&lt;e&lt;&lt;&quot;,&quot;&lt;&lt;f&lt;&lt;endl; return 0; } Output: 32,3.141500,567283 32,3.141500,567283 一个笔试题，输入一个数n，把1到n按字符顺序排序 #include&lt;iostream&gt; #include&lt;string&gt; #include&lt;algorithm&gt; #include&lt;vector&gt; #include&lt;sstream&gt; using namespace std; int main() { int n; string j; cin &gt;&gt; n; char a[100]; vector&lt;string&gt;d; for (int i = 0; i &lt; n; i++){ //stringstream ss; //ss &lt;&lt; i; //string s = ss.str(); //d.push_back(s); sprintf_s(a, &quot;%d&quot;, i); d.push_back(a); } sort(d.begin(), d.end()); for (int i = 0; i &lt; n; i++){ cout &lt;&lt; d[i]&lt;&lt;&quot; &quot; ; } return 0; } 输入12，输出,0 1 10 11 2 3 4 5 6 7 8 9 小结：C++标准库中的提供了比ANSI C的更高级的一些功能，即单纯性、类型安全和可扩展性，可以使用这些库来实现安全和自动的类型转换。言下之意就是，使用stringstream进行字符串与数字的转换是更好的选择。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL常见容器实现原理——vector,list等]]></title>
    <url>%2F2017%2FSTL%E5%B8%B8%E8%A7%81%E5%AE%B9%E5%99%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E2%80%94%E2%80%94vector-list.html</url>
    <content type="text"><![CDATA[Array连续存储结构，每个元素在内存上是连续的 array是一个固定大小的顺序容器，不能动态改变大小，它的大小在定义后就不能被改变。由于array具有固定的大小，它不支持添加和删除元素或改变容器大小等其他容器拥有的操作。在定义一个array容器的时候必须指定大小。 Defined in header : &lt;array&gt; template&lt;class T, std::size_t N&gt; struct array; 内存分配策略在内存分配策略上，array也与C-style数组类似。编译器在哪里为array分配内存，取决于array定义的位置和方式。 若作为函数的局部对象，则将从栈上获得内存，与之对比是的vector，vector底层数据结构是动态数组，从自由存储区上分配内存： 若使用new操作符分配内存，则是在自由存储区上分配内存。 若作为全局变量或局部静态变量，则是在全局/静态存储区上分配的内存。 Array使用优劣(1)array比数组更安全。它提供了opeartor[]与at()成员函数，后者将进行数组越界检查。 (2)与其他容器相似，array也有自己的迭代器，因此array能够更好地与标准算法库结合起来。 (3)通过array::swap函数，可以实现线性时间内的两个数组内容的交换。 另外，不像C-style数组，array容器类型的名称不会自动转换为指针。对于C++程序员来说，array要比C-style数组更好用。 vectorvector的底层数据结构是动态数组，因此，vector的数据安排以及操作方式与std::array十很相似，它们间的唯一差别在于对空间的运用灵活性上。array为静态数组，有着静态数组最大的缺点：每次只能分配一定大小的存储空间，当有新元素插入时，要经历 “找到更大的内存空间”-&gt;“把数据复制到新空间” -&gt;“销毁旧空间” 三部曲， 对于std::array而言，这种空间管理的任务压在使用它的用户身上，用户必须把握好数据的数量，尽量在第一次分配时就给数据分配合理的空间（这有时很难做到)，以防止“三部曲”带来的代价，而数据溢出也是静态数组使用者需要注意的问题。 而vector用户不需要亲自处理空间运用问题。vector是动态空间，随着新元素的插入，旧存储空间不够用时，vector内部机制会自行扩充空间以容纳新元素，当然，这种空间扩充大部分情况下（几乎是)也逃脱不了“三部曲”，只是不需要用户自己处理，而且vector处理得更加安全高效。vector的实现技术关键就在于对其大小的控制以及重新配置时数据移动效率。 标准库的实现者使用了这样的内存分配策略：以最小的代价连续存储元素。为了使vector容器实现快速的内存分配，其实际分配的容量要比当前所需的空间多一些(预留空间)，vector容器预留了这些额外的存储区用于存放添加的新元素，于是不必为每个新元素进行一次内存分配。当继续向容器中加入元素导致备用空间被用光（超过了容量 capacity)，此时再加入元素时vector的内存管理机制便会扩充容量至两倍，如果两倍容量仍不足，就扩张至足够大的容量。容量扩张必须经历“重新配置、元素移动、释放原空间”这个浩大的工程。按照《STL源码剖析》中提供的vector源码，vector的内存配置原则为： 如果vector原大小为0，则配置1，也即一个元素的大小。 如果原大小不为0，则配置原大小的两倍。 当然，vector的每种实现都可以自由地选择自己的内存分配策略，分配多少内存取决于其实现方式，不同的库采用不同的分配策略。 迭代器失效问题 (1)vector管理的是连续的内存空间，在容器中插入（或删除)元素时，插入（或删除)点后面的所有元素都需要向后（或向前)移动一个位置，指向发生移动的元素的迭代器都失效。这里以插入操作示例： (2)随着元素的插入，原来分配的连续内存空间已经不够且无法在原地拓展新的内存空间，整个容器会被copy到另外一块内存上，此时指向原来容器元素的所有迭代器通通失效。(3)删除元素后，指向被删除元素的迭代器失效，这是显而易见的。 vector使用优劣优点： (1) 不指定一块内存大小的数组的连续存储，即可以像数组一样操作，但可以对此数组进行动态操作。通常体现在push_back() pop_back() (2) 随机访问方便，即支持[ ]操作符和vector.at() (3) 节省空间。 缺点： (1) 在内部进行插入删除操作效率低。 (2) 只能在vector的最后进行push和pop，不能在vector的头进行push和pop。 (3) 当动态添加的数据超过vector默认分配的大小时要进行整体的重新分配、拷贝与释放 list底层数据结构list同样是一个模板类，它底层数据结构为双向循环链表。因此，它支持任意位置常数时间的插入/删除操作，不支持快速随机访问。 迭代器类型:list的迭代器具备前移、后移的能力，所以list提供的是Bidirectional iterator(双向迭代器)。由于采用的是双向迭代器，自然也很方便在指定元素之前插入新节点，所以list很正常地提供了insert()操作与push_back()/pop_back()操作。 内存分配策略:list的空间配置策略，自然是像我们普通双向链表那样，有多少元素申请多少内存。它不像vector那样需要预留空间供新元素的分配，也不会因找不到连续的空间而引起整个容器的内存迁移。 迭代器失效问题list 有一个重要性质：插入操作（insert)与接合操作（splice)都不会造成原有的list迭代器失效。这在vector是不成立的，因为vactor的插入可能引起空间的重新配置，导致原来的迭代器全部失效。list的迭代器失效，只会出现在删除的时候，指向删除元素的那个迭代器在删除后失效。 通常来说，forward_list在使用灵活度上比不上list，因为它只能单向迭代元素，且提供的接口没有list多。然而，在内存的使用上，它是比list占优势的。当对内存的要求占首要位置时，应该选择forward_list。 list使用优劣优点： (1) 不使用连续内存完成动态操作。 (2) 在内部方便的进行插入和删除操作 (3) 可在两端进行push、pop 缺点： (1) 不能进行内部的随机访问，即不支持[ ]操作符和vector.at() (2) 相对于verctor占用内存多 deque底层数据结构:vector是单向开口的线性连续空间，deque则是一种双向开口的连续数据空间。所谓的双向开口，意思是可以在头尾两端分别做元素的插入和删除操作。当然vector也可以在头尾两端进行操作，但是其头部操作效果奇差，所以标准库没有为vector提供push_front或pop_front操作。与vector类似，deque支持元素的快速随机访问。deque的示意图如下： 现在问题来了：如果deque以数组来实现，如何做到在头部的常数时间插入？如果是采用链表来实现，又如何做到快速随机访问？deque的内部数据结构到底如何？想必你已经猜到了，要实现如上需求，需要由一段一段的连续空间链接起来的数据结构才能满足。 内存分配策略:deque由一段一段的连续空间所链接而成，一旦需要在deque的前端或尾端增加新空间，便配置一段定量的连续空间，并将该空间串接在deque的头部或尾部。deque复杂的迭代器架构，构建出了所有分段连续空间”整体连续“的假象。既然deque是由一段一段定长的连续空间所构成，就需要有结构来管理这些连续空间。deque采用一块map（非STL中的map)作为主控，map是一块小的连续空间，其中每个元素都是指针，指向一块较大的线性连续空间，称为缓冲区。而缓冲区才是存储deque元素的空间主体。示例图：map本身也是一块固定大小的连续空间，当缓冲区数量增多，map容不下更多的指针时，deque会寻找一块新的空间来作为map。 deque的迭代器为了使得这些分段的连续空间看起来像是一个整体，deque的迭代器必须有这样的能力：它必须能够指出分段连续空间在哪里，判断自己所指的位置是否位于某一个缓冲区的边缘，如果位于边缘，则执行operator– 或operator++时要能够自动跳到下一个缓冲区。因此，尽管deque的迭代器也是Ramdon Access Iterator 迭代器，但它的实现要比vector的复杂太多。 迭代器失效问题 (1)在deque容器首部或者尾部插入元素不会使得任何迭代器失效。 (2)在其首部或尾部删除元素则只会使指向被删除元素的迭代器失效。 (3)在deque容器的任何其他位置的插入和删除操作将使指向该容器元素的所有迭代器失效。 deque使用优劣 deque是在功能上合并了vector和list。 优点：(1) 随机访问方便，即支持[ ]操作符和vector.at() (2) 在内部方便的进行插入和删除操作 (3) 可在两端进行push、pop 缺点：(1) 占用内存多 MapMap是关联容器，以键值对的形式进行存储，方便进行查找，关键词起到索引的作用，值则表示与索引相关联的数据，以红黑树的结构实现，插入删除等操作都可以在O(log n)时间内完成 Map基本操作： 1.map a; map;支持多种类型 2.添加数据： map1.insert(pair&lt;int,string&gt; (102,&quot;wobeitianjia&quot;)); map1.insert(map&lt;int,string&gt;::value_type(102,&quot;tianjia&quot;)); map1[102]=&quot;string&quot;; 3.元素查找：map1.find(key) 返回一个迭代器指向键值为key的元素，如果没有找到，返回指向map尾部的迭代器 4.元素删除：先查找元素，map::iterator it=map1.find(key); 找到之后map1.erase(it); 5.map中的swap函数，交换的是两个容器而不是一个容器中的元素交换 6.sort函数，因为map中key按照升序进行排列的，所以不能使用sort函数 setSet是关联容器，set中每个元素都只包含一个关键字，set支持高效的关键字查询操作—检查每一个给定的关键字是否在set中，set是以红黑树的平衡二叉检索树结构实现的，支持高效插入删除，插如元素的时候会自动调整二叉树的结构，使得每个子树根节点键值大于左子树所有节点的键值，小于右子树所有节点的键值，另外还得保证左子树和右子树的高度相等 平衡二叉检索树使用中序遍历算法，检索效率高于vector，deque，list等容器，另外使用中序遍历可将键值按照从小到大遍历出来 构造set集合的主要目的是为了快速检索，不可直接去修改键值 常用操作： 1.元素插入：insert 2.中序遍历：类似vector遍历（用迭代器） 3.反向遍历：利用反向迭代器reverse_iterator set&lt;int&gt; s; set&lt;int&gt;::reverse_iterator rit; for(rit=s.rbegin();rit!=s.rend();rit++) 4.元素的删除：s.erase(2); s.clear(); 5.元素的检索：find(),若找到，返回该值迭代器的位置，否则返回最后一个元素后面一个位置s.end() it=s.find(5); if(it==s.end()) cout&lt;&lt;&quot;not find&quot;&lt;&lt;endl; else cout&lt;&lt;*it&lt;&lt;endl; 参考：http://www.cnblogs.com/DswCnblog/p/5676017.html]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[静态库和动态库的区别]]></title>
    <url>%2F2017%2F%E9%9D%99%E6%80%81%E5%BA%93%E5%92%8C%E5%8A%A8%E6%80%81%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB.html</url>
    <content type="text"><![CDATA[什么是库库是写好的现有的，成熟的，可以复用的代码。现实中每个程序都要依赖很多基础的底层库，不可能每个人的代码都从零开始，因此库的存在意义非同寻常。 本质上来说库是一种可执行代码的二进制形式，可以被操作系统载入内存执行。库有两种：静态库（.a、.lib）和动态库（.so、.dll）。 所谓静态、动态是指链接。回顾一下，将一个程序编译成可执行程序的步骤： 静态库之所以成为【静态库】，是因为在链接阶段，会将汇编生成的目标文件.o与引用到的库一起链接打包到可执行文件中。因此对应的链接方式称为静态链接。 试想一下，静态库与汇编生成的目标文件一起链接为可执行文件，那么静态库必定跟.o文件格式相似。其实一个静态库可以简单看成是一组目标文件（.o/.obj文件）的集合，即很多目标文件经过压缩打包后形成的一个文件。静态库特点总结： 静态库对函数库的链接是放在编译时期完成的。 程序在运行时与函数库再无瓜葛，移植方便。 浪费空间和资源，因为所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件。 Linux下使用ar工具、Windows下vs使用lib.exe，将目标文件压缩到一起，并且对其进行编号和索引，以便于查找和检索。一般创建静态库的步骤如图所示：动态库为什么需要动态库，其实也是静态库的特点导致。 空间浪费是静态库的一个问题。 另一个问题是静态库对程序的更新、部署和发布页会带来麻烦。如果静态库liba.lib更新了，所以使用它的应用程序都需要重新编译、发布给用户（对于玩家来说，可能是一个很小的改动，却导致整个程序重新下载，全量更新）。 动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入。不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例，规避了空间浪费问题。动态库在程序运行是才被载入，也解决了静态库对程序的更新、部署和发布页会带来麻烦。用户只需要更新动态库即可，增量更新。动态库特点总结： 动态库把对一些库函数的链接载入推迟到程序运行的时期。 可以实现进程之间的资源共享。（因此动态库也称为共享库） 将一些程序升级变得简单。 甚至可以真正做到链接载入完全由程序员在程序代码中控制（显示调用）。 Window与Linux执行文件格式不同，在创建动态库的时候有一些差异。 在Windows系统下的执行文件格式是PE格式，动态库需要一个DllMain函数做出初始化的入口，通常在导出函数的声明时需要有_declspec(dllexport)关键字。 Linux下gcc编译的执行文件默认是ELF格式，不需要初始化入口，亦不需要函数做特别的声明，编写比较方便。 与创建静态库不同的是，不需要打包工具（ar、lib.exe），直接使用编译器即可创建动态库。 区别与联系二者的不同点在于代码被载入的时刻不同。静态库的代码在编译过程中已经被载入可执行程序,因此体积比较大。动态库(共享库)的代码在可执行程序运行时才载入内存，在编译过程中仅简单的引用，因此代码体积比较小。不同的应用程序如果调用相同的库,那么在内存中只需要有一份该动态库(共享库)的实例。静态库和动态库的最大区别,静态情况下,把库直接加载到程序中,而动态库链接的时候,它只是保留接口,将动态库与程序代码独立,这样就可以提高代码的可复用度，和降低程序的耦合度。静态库在程序编译时会被连接到目标代码中，程序运行时将不再需要该静态库。动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入，因此在程序运行时还需要动态库存在]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>编译</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析extern "C"的作用]]></title>
    <url>%2F2017%2Fextern-C.html</url>
    <content type="text"><![CDATA[extern “C”的主要作用就是为了能够正确实现C++代码调用其他C语言代码。加上extern “C”后，会指示编译器这部分代码按c语言的进行编译，而不是C++的。由于C++支持函数重载，因此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名；而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般之包括函数名。 这个功能十分有用处，因为在C++出现以前，很多代码都是C语言写的，而且很底层的库也是C语言写的，为了更好的支持原来的C代码和已经写好的C语言库，需要在C++中尽可能的支持C，而extern “C”就是其中的一个策略。 这个功能主要用在下面的情况： 1、C++代码调用C语言代码 2、在C++的头文件中使用 3、在多个人协同开发时，可能有的人比较擅长C语言，而有的人擅长C++，这样的情况下也会有用到给出一个我设计的例子：moduleA、moduleB两个模块，B调用A中的代码，其中A是用C语言实现的，而B是利用C++实现的，下面给出一种实现方法： //moduleA头文件 #ifndef __MODULE_A_H //对于模块A来说，这个宏是为了防止头文件的重复引用 #define __MODULE_A_H int fun(int, int); #endif //moduleA实现文件moduleA.C //模块A的实现部分并没有改变 #include&quot;moduleA&quot; int fun(int a, int b) { return a+b; } //moduleB头文件 #idndef __MODULE_B_H //很明显这一部分也是为了防止重复引用 #define __MODULE_B_H #ifdef __cplusplus //而这一部分就是告诉编译器，如果定义了__cplusplus(即如果是cpp文件， extern &quot;C&quot;{ //因为cpp文件默认定义了该宏),则采用C语言方式进行编译 #include&quot;moduleA.h&quot; #endif … //其他代码 #ifdef __cplusplus } #endif #endif //moduleB实现文件 moduleB.cpp //B模块的实现也没有改变，只是头文件的设计变化了 #include&quot;moduleB.h&quot; int main() { cout&lt;&lt;fun(2,3)&lt;&lt;endl; } 由于C、C++编译器对函数的编译处理是不完全相同的，尤其对于C++来说，支持函数的重载，编译后的函数一般是以函数名和形参类型来命名的。 例如函数void fun(int, int)，编译后的可能是（不同编译器结果不同）_fun_int_int(不同编译器可能不同，但都采用了类似的机制，用函数名和参数类型来命名编译后的函数名)；而C语言没有类似的重载机制，一般是利用函数名来指明编译后的函数名的，对应上面的函数可能会是_fun这样的名字。看下面的一个面试题：为什么标准头文件都有类似的结构？ #ifndef __INCvxWorksh /*防止该头文件被重复引用*/ #define __INCvxWorksh #ifdef __cplusplus //告诉编译器，这部分代码按C语言的格式进行编译，而不是C++的 extern &quot;C&quot;{ #endif /*…*/ #ifdef __cplusplus } #endif #endif /*end of __INCvxWorksh*/ 分析： 显然，头文件中编译宏 &quot;#ifndef __INCvxWorksh 、#define __INCvxWorksh、#endif&quot; 的作用是为了防止该头文件被重复引用那么 #ifdef __cplusplus (其中__cplusplus是cpp中自定义的一个宏！！！) extern &quot;C&quot;{ #endif #ifdef __cplusplus } #endif 的作用是什么呢？ extern “C”包含双重含义，从字面上可以知道，首先，被它修饰的目标是”extern”的；其次，被它修饰的目标代码是”C”的。 被extern “C”限定的函数或变量是extern类型的extern是C/C++语言中表明函数和全局变量的作用范围的关键字，该关键字告诉编译器，其申明的函数和变量可以在本模块或其他模块中使用。 记住，下面的语句： extern int a; 仅仅是一个变量的声明，其并不是在定义变量a，并未为a分配空间。变量a在所有模块中作为一种全局变量只能被定义一次，否则会出错。 通常来说，在模块的头文件中对本模块提供给其他模块引用的函数和全局变量以关键字extern生命。例如，如果模块B要引用模块A中定义的全局变量和函数时只需包含模块A的头文件即可。这样模块B中调用模块A中的函数时，在编译阶段，模块B虽然找不到该函数，但并不会报错；它会在链接阶**段从模块A编译生成的目标代码中找到该函数。** extern对应的关键字是static，static表明变量或者函数只能在本模块中使用，因此，被static修饰的变量或者函数不可能被extern C修饰。 被extern “C”修饰的变量和函数是按照C语言方式进行编译和链接的：这点很重要！！！！上面也提到过，由于C++支持函数重载，而C语言不支持，因此函数被C++编译后在符号库中的名字是与C语言不同的；C++编译后的函数需要加上参数的类型才能唯一标定重载后的函数，而加上extern “C”后，是为了向编译器指明这段代码按照C语言的方式进行编译未加extern “C”声明时的链接方式： //模块A头文件 moduleA.h #idndef _MODULE_A_H #define _MODULE_A_H int foo(int x, int y); #endif 在模块B中调用该函数： //模块B实现文件 moduleB.cpp #include&quot;moduleA.h&quot; foo(2,3); 实际上，在链接阶段，连接器会从模块A生成的目标文件moduleA.obj中找_foo_int_int这样的符号！！！，显然这是不可能找到的，因为foo()函数被编译成了_foo的符号，因此会出现链接错误。 常见的做法可以参考下面的一个实现： moduleA、moduleB两个模块，B调用A中的代码，其中A是用C语言实现的，而B是利用C++实现的，下面给出一种实现方法： //moduleA头文件 #ifndef __MODULE_A_H //对于模块A来说，这个宏是为了防止头文件的重复引用 #define __MODULE_A_H int fun(int, int); #endif //moduleA实现文件moduleA.C //模块A的实现部分并没有改变 #include&quot;moduleA&quot; int fun(int a, int b) { return a+b; } //moduleB头文件 #idndef __MODULE_B_H //很明显这一部分也是为了防止重复引用 #define __MODULE_B_H #ifdef __cplusplus //而这一部分就是告诉编译器，如果定义了__cplusplus(即如果是cpp文件， extern &quot;C&quot;{ //因为cpp文件默认定义了该宏),则采用C语言方式进行编译 #include&quot;moduleA.h&quot; #endif … //其他代码 #ifdef __cplusplus } #endif #endif //moduleB实现文件 moduleB.cpp //B模块的实现也没有改变，只是头文件的设计变化了 #include&quot;moduleB.h&quot; int main() { cout&lt;&lt;fun(2,3)&lt;&lt;endl; } extern “C”的使用要点 1.可以是单一语句 extern &quot;C&quot; double sqrt(double); 2.可以是复合语句, 相当于复合语句中的声明都加了extern “C” extern &quot;C&quot; { double sqrt(double); int min(int, int); } 3.可以包含头文件，相当于头文件中的声明都加了extern “C” extern &quot;C&quot; { ＃include &lt;cmath&gt; 4.不可以将extern “C” 添加在函数内部 5.如果函数有多个声明，可以都加extern “C”, 也可以只出现在第一次声明中，后面的声明会接受第一个链接指示符的规则。 6.除extern “C”, 还有extern “FORTRAN” 等。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[static用法详解及其与const的区别]]></title>
    <url>%2F2017%2Fstatic-const.html</url>
    <content type="text"><![CDATA[C 语言的 static 关键字有三种（具体来说是两种）用途：静态局部变量：用于函数体内部修饰变量，这种变量的生存期长于该函数。int foo(){ static int i = 1; // note:1 //int i = 1; // note:2 i += 1; return i; } 要明白这个用法，我们首先要了解c/c++的内存分布，以及static所在的区间。 对于一个完整的程序，在内存中的分布情况如下： 1.栈区： 由编译器自动分配释放，像局部变量，函数参数，都是在栈区。会随着作用于退出而释放空间。3.堆区：程序员分配并释放的区域，像malloc(c),new(c++)3.全局数据区(静态区)：全局变量和静态便令的存储是放在一块的，初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。程序结束释放。4.代码区 所以上面note:1的static是在全局数据区分配的,那么它存在的意思是什么？又是什么时候初始化的呢？ 首先回答第一个问题：它存在的意义就是随着第一次函数的调用而初始化，却不随着函数的调用结束而销毁(如果把以上的note:1换成note:2,那么i就是在栈区分配了，会随着foo的调用结束而释放)。 那么第二个问题也就浮出水面了，它是在第一次调用进入note:1的时候初始化（当初面试被坑过，我居然说是一开始就初始化了，汗！！）。且只初始化一次，也就是你第二次调用foo(),不会继续初始化，而会直接跳过。 那么它跟定义一个全局变量有什么区别呢，同样是初始化一次，连续调用foo()的结果是一样的，但是，使用全局变量的话，变量就不属于函数本身了，不再仅受函数的控制，给程序的维护带来不便。 静态局部变量正好可以解决这个问题。静态局部变量保存在全局数据区，而不是保存在栈中，每次的值保持到下一次调用，直到下次赋新值。 那么我们总结一下，静态局部变量的特点（括号内为note:2,也就是局部变量的对比）：（1）该变量在全局数据区分配内存(局部变量在栈区分配内存);（2）静态局部变量在程序执行到该对象的声明处时被首次初始化，即以后的函数调用不再进行初始化(局部变量每次函数调用都会被初始化);（3）静态局部变量一般在声明处初始化，如果没有显式初始化，会被程序自动初始化为0(局部变量不会被初始化);（4）它始终驻留在全局数据区，直到程序运行结束。但其作用域为局部作用域，也就是不能在函数体外面使用它(局部变量在栈区，在函数结束后立即释放内存); 静态全局变量：定义在函数体外，用于修饰全局变量，表示该变量只在本文件可见。static int i = 1; //note:3 //int i = 1; //note:4 int foo() { i += 1; return i; } note:3和note:4有什么差异呢？你调用foo(),无论调用几次，他们的结果都是一样的。也就是说在本文件内调用他们是完全相同的。那么他们的区别是什么呢？文件隔离！ 假设我有一个文件a.c,我们再新建一个b.c,内容如下。 //file a.c //static int n = 15; //note:5 int n = 15; //note:6 //file b.c #include &lt;stdio.h&gt; extern int n; void fn() { n++; printf(&quot;after: %d\n&quot;,n); } void main() { printf(&quot;before: %d\n&quot;,n); fn(); } 我们先使用note:6,也就是非静态全局变量，发现输出为:before: 15after: 16 也就是我们的b.c通过extern使用了a.c定义的全局变量。那么我们改成使用note:5,也就是使用静态全局变量呢？gcc a.c b.c -o output.out会出现类似undeference to “n”的报错，它是找不到n的，因为static进行了文件隔离，你是没办法访问a.c定义的静态全局变量的，当然你用 #include “a.c”,那就不一样了。 以上我们就可以得出静态全局变量的特点：静态全局变量不能被其它文件所用(全局变量可以);其它文件中可以定义相同名字的变量，不会发生冲突(自然了，因为static隔离了文件，其它文件使用相同的名字的变量，也跟它没关系了); 静态函数：准确的说，静态函数跟静态全局变量的作用类似：//file a.c #include &lt;stdio.h&gt; void fn() { printf(&quot;this is non-static func in a&quot;); } //file b.c #include &lt;stdio.h&gt; extern void fn(); //我们用extern声明其他文件的fn(),供本文件使用。 void main() { fn(); } 可以正常输出：this is non-static func in a。当给void fn()加上static的关键字之后呢？ undefined reference to “fn”. 所以，静态函数的好处跟静态全局变量的好处就类似了：1.静态函数不能被其它文件所用;2.其它文件中可以定义相同名字的函数，不会发生冲突; 上面一共说了三种用法，为什么说准确来说是两种呢？1.一种是修饰变量，一种是修饰函数，所以说是两种（这种解释不多）。2.静态全局变量和修饰静态函数的作用是一样的，一般合并为一种。（这是比较多的分法）。 C++ 语言的 static 关键字有二种用途：当然以上的几种，也可以用在c++中。还有额外的两种用法： 静态数据成员：用于修饰 class 的数据成员，即所谓“静态成员”。这种数据成员的生存期大于 class 的对象（实体 instance）。静态数据成员是每个 class 有一份，普通数据成员是每个 instance 有一份，因此静态数据成员也叫做类变量，而普通数据成员也叫做实例变量 #include&lt;iostream&gt; using namespace std; class Rectangle { private: int m_w,m_h; static int s_sum; public: Rectangle(int w,int h) { this-&gt;m_w = w; this-&gt;m_h = h; s_sum += (this-&gt;m_w * this-&gt;m_h); } void GetSum() { cout&lt;&lt;&quot;sum = &quot;&lt;&lt;s_sum&lt;&lt;endl; } }; int Rectangle::s_sum = 0; //初始化 int main() { cout&lt;&lt;&quot;sizeof(Rectangle)=&quot;&lt;&lt;sizeof(Rectangle)&lt;&lt;endl; Rectangle *rect1 = new Rectangle(3,4); rect1-&gt;GetSum(); cout&lt;&lt;&quot;sizeof(rect1)=&quot;&lt;&lt;sizeof(*rect1)&lt;&lt;endl; Rectangle rect2(2,3); rect2.GetSum(); cout&lt;&lt;&quot;sizeof(rect2)=&quot;&lt;&lt;sizeof(rect2)&lt;&lt;endl; system(&quot;pause&quot;); return 0; } 由图可知：sizeof(Rectangle)=8bytes=sizeof(m_w)+sizeof(m_h)。也就是说 static 并不占用Rectangle的内存空间。那么static在哪里分配内存的呢？是的，全局数据区(静态区)。再看看GetSum()，第一次12=34，第二次18=12+23。由此可得，static只会被初始化一次，于实例无关。 结论：对于非静态数据成员，每个类对象(实例)都有自己的拷贝。而静态数据成员被当作是类的成员，由该类型的所有对象共享访问,对该类的多个对象来说，静态数据成员只分配一次内存。静态数据成员存储在全局数据区。静态数据成员定义时要分配空间，所以不能在类声明中定义。 也就是说，你每new一个Rectangle，并不会为static int s_sum的构建一份内存拷贝，它是不管你new了多少Rectangle的实例，因为它只与类Rectangle挂钩，而跟你每一个Rectangle的对象没关系。 静态成员函数：用于修饰 class 的成员函数。我们对上面的例子稍加改动： #include&lt;iostream&gt; using namespace std; class Rectangle { private: int m_w,m_h; static int s_sum; public: Rectangle(int w,int h) { this-&gt;m_w = w; this-&gt;m_h = h; s_sum += (this-&gt;m_w * this-&gt;m_h); } static void GetSum() //这里加上static { cout&lt;&lt;&quot;sum = &quot;&lt;&lt;s_sum&lt;&lt;endl; } }; int Rectangle::s_sum = 0; //初始化 int main() { cout&lt;&lt;&quot;sizeof(Rectangle)=&quot;&lt;&lt;sizeof(Rectangle)&lt;&lt;endl; Rectangle *rect1 = new Rectangle(3,4); rect1-&gt;GetSum(); cout&lt;&lt;&quot;sizeof(rect1)=&quot;&lt;&lt;sizeof(*rect1)&lt;&lt;endl; Rectangle rect2(2,3); rect2.GetSum(); //可以用对象名.函数名访问 cout&lt;&lt;&quot;sizeof(rect2)=&quot;&lt;&lt;sizeof(rect2)&lt;&lt;endl; Rectangle::GetSum(); //也可以可以用类名::函数名访问 system(&quot;pause&quot;); return 0; } 上面注释可见:对GetSum()加上static，使它变成一个静态成员函数，可以用类名::函数名进行访问。那么静态成员函数有特点呢？1.静态成员之间可以相互访问，包括静态成员函数访问静态数据成员和访问静态成员函数;2.非静态成员函数可以任意地访问静态成员函数和静态数据成员;3.静态成员函数不能访问非静态成员函数和非静态数据成员;4.调用静态成员函数，可以用成员访问操作符(.)和(-&gt;)为一个类的对象或指向类对象的指针调用静态成员函数,也可以用类名::函数名调用(因为他本来就是属于类的，用类名调用很正常) 前三点其实是一点：静态成员函数不能访问非静态(包括成员函数和数据成员)，但是非静态可以访问静态，有点晕吗？没关系，我给你个解释，因为静态是属于类的，它是不知道你创建了10个还是100个对象，所以它对你对象的函数或者数据是一无所知的，所以它没办法调用，而反过来，你创建的对象是对类一清二楚的(不然你怎么从它那里实例化呢)，所以你是可以调用类函数和类成员的，就像不管GetSum是不是static，都可以调用static的s_sum一样。 static和const的联系和区别const定义的常量在超出其作用域之后其空间会被释放，而static定义的静态常量在函数执行后不会释放其存储空间。 static表示的是静态的。类的静态成员函数、静态成员变量是和类相关的，而不是和类的具体对象相关的。即使没有具体对象，也能调用类的静态成员函数和成员变量。一般类的静态函数几乎就是一个全局函数，只不过它的作用域限于包含它的文件中。 在C++中，static静态成员变量不能在类的内部初始化。在类的内部只是声明，定义必须在类定义体的外部，通常在类的实现文件中初始化，如：double Account::Rate=2.25;static关键字只能用于类定义体内部的声明中，定义时不能标示为static 在C++中，const成员变量也不能在类定义处初始化，只能通过构造函数初始化列表进行，并且必须有构造函数。 const数据成员 只在某个对象生存期内是常量，而对于整个类而言却是可变的。因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。所以不能在类的声明中初始化const数据成员，因为类的对象没被创建时，编译器不知道const数据成员的值是什么。 const数据成员的初始化只能在类的构造函数的初始化列表中进行。要想建立在整个类中都恒定的常量，应该用类中的枚举常量来实现，或者static cosnt class Test { public: Test():a(0){} enum {size1=100,size2=200}; private: const int a;//只能在构造函数初始化列表中初始化 static int b;//在类的实现文件中定义并初始化 const static int c;//与 static const int c;相同。 }; int Test::b=0;//static成员变量不能在构造函数初始化列表中初始化，因为它不属于某个对象。 cosnt int Test::c=0;//注意：给静态成员变量赋值时，不需要加static修饰符。但要加cosnt cosnt成员函数主要目的是防止成员函数修改对象的内容。即const成员函数不能修改成员变量的值，但可以访问成员变量。当方法成员函数时，该函数只能是const成员函数。 static成员函数主要目的是作为类作用域的全局函数。不能访问类的非静态数据成员。类的静态成员函数没有this指针，这导致：1、不能直接存取类的非静态成员变量，调用非静态成员函数2、不能被声明为virtual 关于static、const、static cosnt、const static成员的初始化问题： 类里的const成员初始化：在一个类里建立一个const时，不能给他初值 class foo { public: foo():i(100){} private: const int i=100;//error!!! }; //或者通过这样的方式来进行初始化 foo::foo():i(100) {} 类里的static成员初始化：类中的static变量是属于类的，不属于某个对象，它在整个程序的运行过程中只有一个副本，因此不能在定义对象时 对变量进行初始化，就是不能用构造函数进行初始化，其正确的初始化方法是： 数据类型 类名::静态数据成员名=值； class foo { public: foo(); private: static int i; }; int foo::i=20; 这表明： 1、初始化在类体外进行，而前面不加static，以免与一般静态变量或对象相混淆 2、初始化时不加该成员的访问权限控制符private、public等 3、初始化时使用作用域运算符来表明它所属的类，因此，静态数据成员是类的成员而不是对象的成员。 类里的static cosnt 和 const static成员初始化这两种写法的作用一样，为了便于记忆，在此值说明一种通用的初始化方法： class Test { public: static const int mask1; const static int mask2; }; const Test::mask1=0xffff; const Test::mask2=0xffff; //它们的初始化没有区别，虽然一个是静态常量一个是常量静态。静态都将存储在全局变量区域，其实最后结果都一样。可能在不同编译器内，不同处理，但最后结果都一样。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析C/C++中的volatile关键字]]></title>
    <url>%2F2017%2Fvolatile.html</url>
    <content type="text"><![CDATA[为什么用volatile？C/C++ 中的 volatile 关键字和 const 对应，用来修饰变量，通常用于建立语言级别的 memory barrier。这是 BS 在 “The C++ Programming Language” 对 volatile 修饰词的说明： A volatile specifier is a hint to a compiler that an object may change its value in ways not specified by the language so that aggressive optimizations must be avoided. volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等。遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问。声明时语法：int volatile vInt; 当要求使用 volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。而且读取的数据立刻被保存。例如： volatile int i=10; int a = i; ... // 其他代码，并未明确告诉编译器，对 i 进行过操作 int b = i; volatile 指出 i 是随时可能发生变化的，每次使用它的时候必须从 i的地址中读取，因而编译器生成的汇编代码会重新从i的地址读取数据放在 b 中。而优化做法是，由于编译器发现两次从 i读数据的代码之间的代码没有对 i 进行过操作，它会自动把上次读的数据放在 b 中。而不是重新从 i 里面读。这样以来，如果 i是一个寄存器变量或者表示一个端口数据就容易出错，所以说 volatile 可以保证对特殊地址的稳定访问。注意，在 VC 6 中，一般调试模式没有进行代码优化，所以这个关键字的作用看不出来。下面通过插入汇编代码，测试有无 volatile 关键字，对程序最终代码的影响. 输入下面的代码： #include &lt;stdio.h&gt; void main() { int i = 10; int a = i; printf(&quot;i = %d&quot;, a); // 下面汇编语句的作用就是改变内存中 i 的值 // 但是又不让编译器知道 __asm { mov dword ptr [ebp-4], 20h } int b = i; printf(&quot;i = %d&quot;, b); } 然后，在 Debug 版本模式运行程序，输出结果如下： i = 10 i = 32 然后，在 Release 版本模式运行程序，输出结果如下： i = 10 i = 10 输出的结果明显表明，Release 模式下，编译器对代码进行了优化，第二次没有输出正确的 i 值。下面，我们把 i 的声明加上 volatile 关键字，看看有什么变化： #include &lt;stdio.h&gt; void main() { volatile int i = 10; int a = i; printf(&quot;i = %d&quot;, a); __asm { mov dword ptr [ebp-4], 20h } int b = i; printf(&quot;i = %d&quot;, b); } 分别在 Debug 和 Release 版本运行程序，输出都是： i = 10 i = 32 这说明这个 volatile 关键字发挥了它的作用。其实不只是“内嵌汇编操纵栈”这种方式属于编译无法识别的变量改变，另外更多的可能是多线程并发访问共享变量时，一个线程改变了变量的值，怎样让改变后的值对其它线程 visible。一般说来，volatile用在如下的几个地方：1) 中断服务程序中修改的供其它程序检测的变量需要加volatile；2) 多任务环境下各任务间共享的标志应该加volatile；3) 存储器映射的硬件寄存器通常也要加volatile说明，因为每次对它的读写都可能由不同意义； volatile 指针和 const 修饰词类似，const 有常量指针和指针常量的说法，volatile 也有相应的概念： 修饰由指针指向的对象、数据是 const 或 volatile 的： const char* cpch; volatile char* vpch; 注意：对于 VC，这个特性实现在 VC 8 之后才是安全的。 指针自身的值——一个代表地址的整数变量，是 const 或 volatile 的： char* const pchc; char* volatile pchv; 注意：(1) 可以把一个非volatile int赋给volatile int，但是不能把非volatile对象赋给一个volatile对象。(2) 除了基本类型外，对用户定义类型也可以用volatile类型进行修饰。(3) C++中一个有volatile标识符的类只能访问它接口的子集，一个由类的实现者控制的子集。用户只能用const_cast来获得对类型接口的完全访问。此外，volatile向const一样会从类传递到它的成员。 多线程下的volatile有些变量是用volatile关键字声明的。当两个线程都要用到某一个变量且该变量的值会被改变时，应该用volatile声明，该关键字的作用是防止优化编译器把变量从内存装入CPU寄存器中。如果变量被装入寄存器，那么两个线程有可能一个使用内存中的变量，一个使用寄存器中的变量，这会造成程序的错误执行。volatile的意思是让编译器每次操作该变量时一定要从内存中真正取出，而不是使用已经存在寄存器中的值，如下： volatile BOOL bStop = FALSE; (1) 在一个线程中： while( !bStop ) { ... } bStop = FALSE; return; (2) 在另外一个线程中，要终止上面的线程循环： bStop = TRUE; while( bStop ); //等待上面的线程终止，如果bStop不使用volatile申明，那么这个循环将是一个死循环，因为bStop已经读取到了寄存器中，寄存器中bStop的值永远不会变成FALSE，加上volatile，程序在执行时，每次均从内存中读出bStop的值，就不会死循环了。 这个关键字是用来设定某个对象的存储位置在内存中，而不是寄存器中。因为一般的对象编译器可能会将其的拷贝放在寄存器中用以加快指令的执行速度，例如下段代码中： ... int nMyCounter = 0; for(; nMyCounter&lt;100;nMyCounter++) { ... } ... 在此段代码中，nMyCounter的拷贝可能存放到某个寄存器中（循环中，对nMyCounter的测试及操作总是对此寄存器中的值进行），但是另外又有段代码执行了这样的操作：nMyCounter -= 1;这个操作中，对nMyCounter的改变是对内存中的nMyCounter进行操作，于是出现了这样一个现象：nMyCounter的改变不同步。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux IO模式及 select、poll、epoll详解]]></title>
    <url>%2F2017%2Flinux-IO.html</url>
    <content type="text"><![CDATA[同步IO和异步IO，阻塞IO和非阻塞IO分别是什么，到底有什么区别？不同的人在不同的上下文下给出的答案是不同的。所以先限定一下本文的上下文。 本文讨论的背景是Linux环境下的network IO。 概念说明在进行解释之前，首先要说明几个概念： 用户空间和内核空间 进程切换 进程的阻塞 文件描述符 缓存 I/O 用户空间与内核空间现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。 进程切换为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。 从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化： 保存处理机上下文，包括程序计数器和其他寄存器。 更新PCB信息。 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。 选择另一个进程执行，并更新其PCB。 更新内存管理的数据结构。 恢复处理机上下文。 进程的阻塞正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。 文件描述符fd文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。 缓存 I/O缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 缓存 I/O 的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 IO模式刚才说了，对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO） 异步 I/O（asynchronous IO） 注：由于signal driven IO在实际中并不常用，所以我这只提及剩下的四种IO Model。 阻塞 I/O（blocking IO）在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 非阻塞 I/O（nonblocking IO）linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。 I/O 多路复用（ IO multiplexing）IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。 这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 异步 I/O（asynchronous IO）linux下的asynchronous IO其实用得很少。先看一下它的流程：用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 总结blocking和non-blocking的区别调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。 synchronous IO和asynchronous IO的区别在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的： A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked; 两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 有人会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。 而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。各个IO Model的比较如图所示：通过上面的图片，可以发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。 I/O 多路复用之select、poll、epoll详解select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 selectint select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。 select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的几大缺点： （1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 （2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大 （3）select支持的文件描述符数量太小了，默认是1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。 pollint poll (struct pollfd *fds, unsigned int nfds, int timeout); 不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 epollepoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 epoll操作过程epoll操作过程需要三个接口，分别如下： int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)； int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); int epoll_create(int size);创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)； 函数是对指定描述符fd执行op操作。– epfd：是epoll_create()的返回值。– op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。 分别添加、删除和修改对fd的监听事件。– fd：是需要监听的fd（文件描述符）– epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下： struct epoll_event { __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; //events可以是以下几个宏的集合： EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）； EPOLLOUT：表示对应的文件描述符可以写； EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR：表示对应的文件描述符发生错误； EPOLLHUP：表示对应的文件描述符被挂断； EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);等待epfd上的io事件，最多返回maxevents个事件。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。 工作模式epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 LT模式LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。 ET模式ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once) ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 总结假如有这样一个例子： 我们已经把一个用来从管道中读取数据的文件句柄(RFD)添加到epoll描述符 这个时候从管道的另一端被写入了2KB的数据 调用epoll_wait(2)，并且它会返回RFD，说明它已经准备好读取操作 然后我们读取了1KB的数据 调用epoll_wait(2)…… LT模式：如果是LT模式，那么在第5步调用epoll_wait(2)之后，仍然能受到通知。 ET模式：如果我们在第1步将RFD添加到epoll描述符的时候使用了EPOLLET标志，那么在第5步调用epoll_wait(2)之后将有可能会挂起，因为剩余的数据还存在于文件的输入缓冲区内，而且数据发出端还在等待一个针对已经发出数据的反馈信息。只有在监视的文件句柄上发生了某个事件的时候 ET 工作模式才会汇报事件。因此在第5步的时候，调用者可能会放弃等待仍在存在于文件输入缓冲区内的剩余数据。 当使用epoll的ET模型来工作时，当产生了一个EPOLLIN事件后，读数据的时候需要考虑的是当recv()返回的大小如果等于请求的大小，那么很有可能是缓冲区还有数据未读完，也意味着该次事件还没有处理完，所以还需要再次读取： while(rs){ buflen = recv(activeevents[i].data.fd, buf, sizeof(buf), 0); if(buflen &lt; 0){ // 由于是非阻塞的模式,所以当errno为EAGAIN时,表示当前缓冲区已无数据可读 // 在这里就当作是该次事件已处理处. if(errno == EAGAIN){ break; } else{ return; } } else if(buflen == 0){ // 这里表示对端的socket已正常关闭. } if(buflen == sizeof(buf){ rs = 1; // 需要再次读取 } else{ rs = 0; } } Linux中的EAGAIN含义Linux环境下开发经常会碰到很多错误(设置errno)，其中EAGAIN是其中比较常见的一个错误(比如用在非阻塞操作中)。从字面上来看，是提示再试一次。这个错误经常出现在当应用程序进行一些非阻塞(non-blocking)操作(对文件或socket)的时候。 例如，以 O_NONBLOCK的标志打开文件/socket/FIFO，如果你连续做read操作而没有数据可读。此时程序不会阻塞起来等待数据准备就绪返回，read函数会返回一个错误EAGAIN，提示你的应用程序现在没有数据可读请稍后再试。又例如，当一个系统调用(比如fork)因为没有足够的资源(比如虚拟内存)而执行失败，返回EAGAIN提示其再调用一次(也许下次就能成功)。 代码演示下面是一段不完整的代码且格式不对，意在表述上面的过程，去掉了一些模板代码。 #define IPADDRESS &quot;127.0.0.1&quot; #define PORT 8787 #define MAXSIZE 1024 #define LISTENQ 5 #define FDSIZE 1000 #define EPOLLEVENTS 100 listenfd = socket_bind(IPADDRESS,PORT); struct epoll_event events[EPOLLEVENTS]; //创建一个描述符 epollfd = epoll_create(FDSIZE); //添加监听描述符事件 add_event(epollfd,listenfd,EPOLLIN); //循环等待 for ( ; ; ){ //该函数返回已经准备好的描述符事件数目 ret = epoll_wait(epollfd,events,EPOLLEVENTS,-1); //处理接收到的连接 handle_events(epollfd,events,ret,listenfd,buf); } //事件处理函数 static void handle_events(int epollfd,struct epoll_event *events,int num,int listenfd,char *buf) { int i; int fd; //进行遍历;这里只要遍历已经准备好的io事件。num并不是当初epoll_create时的FDSIZE。 for (i = 0;i &lt; num;i++) { fd = events[i].data.fd; //根据描述符的类型和事件类型进行处理 if ((fd == listenfd) &amp;&amp;(events[i].events &amp; EPOLLIN)) handle_accpet(epollfd,listenfd); else if (events[i].events &amp; EPOLLIN) do_read(epollfd,fd,buf); else if (events[i].events &amp; EPOLLOUT) do_write(epollfd,fd,buf); } } //添加事件 static void add_event(int epollfd,int fd,int state){ struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_ADD,fd,&amp;ev); } //处理接收到的连接 static void handle_accpet(int epollfd,int listenfd){ int clifd; struct sockaddr_in cliaddr; socklen_t cliaddrlen; clifd = accept(listenfd,(struct sockaddr*)&amp;cliaddr,&amp;cliaddrlen); if (clifd == -1) perror(&quot;accpet error:&quot;); else { printf(&quot;accept a new client: %s:%d\n&quot;,inet_ntoa(cliaddr.sin_addr),cliaddr.sin_port); //添加一个客户描述符和事件 add_event(epollfd,clifd,EPOLLIN); } } //读处理 static void do_read(int epollfd,int fd,char *buf){ int nread; nread = read(fd,buf,MAXSIZE); if (nread == -1) { perror(&quot;read error:&quot;); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLIN); //删除监听 } else if (nread == 0) { fprintf(stderr,&quot;client close.\n&quot;); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLIN); //删除监听 } else { printf(&quot;read message is : %s&quot;,buf); //修改描述符对应的事件，由读改为写 modify_event(epollfd,fd,EPOLLOUT); } } //写处理 static void do_write(int epollfd,int fd,char *buf) { int nwrite; nwrite = write(fd,buf,strlen(buf)); if (nwrite == -1){ perror(&quot;write error:&quot;); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLOUT); //删除监听 }else{ modify_event(epollfd,fd,EPOLLIN); } memset(buf,0,MAXSIZE); } //删除事件 static void delete_event(int epollfd,int fd,int state) { struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_DEL,fd,&amp;ev); } //修改事件 static void modify_event(int epollfd,int fd,int state){ struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_MOD,fd,&amp;ev); } //注：另外一端我就省了 epoll总结在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。) epoll的优点主要是一下几个方面： 监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。 IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSI的七层协议经典架构]]></title>
    <url>%2F2017%2FISO-OSI.html</url>
    <content type="text"><![CDATA[OSI(Open System interconnection)开放系统互连参考模型 ISO(International Standards Organization)国际标准化组织 第一层：物理层 机械性能：接口的型状，尺寸的大小，引脚的数目和排列方式等。 电气性能：接口规定信号的电压、电流、阻抗、波形、速率及平衡特性等。 工程规范：接口引脚的意义、特性、标准。 工作方式：确定数据位流的传输方式，如：单工、半双工或全双工。 物理层协议有： 美国电子工业协会(EIA)的RS232，RS422，RS423，RS485等； 国际电报电话咨询委员会(CCITT)的X.25、X.21等； 物理层的数据单位是位(BIT)，典型设备是集线器HUB。这层主要和硬件有关，与软件关系不大。 第二层：链路层 链路层屏蔽传输介质的物理特征，使数据可靠传送。 内容包括介质访问控制、连接控制、顺序控制、流量控制、差错控制和仲裁协议等。 链路层协议有： 协议有面向字符的通讯协议(PPP)和面向位的通讯协议(HDLC)。 仲裁协议：802.3、802.4、802.5，即： CSMA/CD(Carrier Sense Multiple Access with Collision Detection)、Token Bus、Token Ring 链路层数据单位是帧，实现对MAC地址的访问，典型设备是交换机Switch。 第三层：网络层网络层管理连接方式和路由选择。连接方式：虚电路(Virtual Circuits)和数据报(Datagram)服务。虚电路是面向连接的(Connection-Oriented)，数据通讯一次路由，通过会话建立的一条通路。数据报是非连接的(Connectionless-Oriented)，每个数据报都有路由能力。网络层的数据单位是包，使用的是IP地址，典型设备是路由器Router。这一层可以进行流量控制，但流量控制更多的是使用第二层或第四层。 第四层：传输层 提供端到端的服务。可以实现流量控制、负载均衡。 传输层信息包含端口、控制字和校验和。 传输层协议主要是TCP和UDP。 传输层位于OSI的第四层，这层使用的设备是主机本身。 第五层：会话层 会话层主要内容是通过会话进行身份验证、会话管理和确定通讯方式。 一旦建立连接，会话层的任务就是管理会话。 第六层：表示层 表示层主要是解释通讯数据的意义，如代码转换、格式变换等，使不同的终端可以表示。 还包括加密与解密、压缩与解压缩等。 第七层：应用层 应用层应该是直接面向用户的程序或服务，包括系统程序和用户程序， 例如www、FTP、DNS、POP3和SMTP等都是应用层服务。 数据在发送时是数据从应用层至物理层的一个打包的过程，接收时是数据从物理层至应用层的一个解包的过程， 从功能角度可分为三组，1、2层解决网络信道问题，3、4层解决传输问题，5、6、7层处理对应用进程的访问。 从控制角度可分为二组，第1、2、3层是通信子网层，第4、5、6、7层是主机控制层。]]></content>
      <categories>
        <category>TCPIP</category>
      </categories>
      <tags>
        <tag>网络协议，OSI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图解TCP建立与断开过程的状态]]></title>
    <url>%2F2017%2Ftcp3-4.html</url>
    <content type="text"><![CDATA[TCP的三次握手过程可能大家比较熟悉了，但经历的各种状态可能还不熟。 三次握手和四次挥手的状态转移图如下： 如图，由于第二次握手接收端发送SYN+ACK信号所以握手只用了三次，挥手由于接收端ACK和FIN分两次发的，所以挥手需要四次。 最后接收端需要一个TIME_WAIT状态，如果TCP client端最后一次发送的ACK丢失了，它将重新发送。TIME_WAIT状态中所需要的时间是依赖于实现方法的。典型的值为30秒、1分钟和2分钟。等待之后连接正式关闭，并且所有的资源(包括端口号)都被释放。 整个Client（发送端）状态图如下： 整个Server（接收端）状态图如下：]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>TCP</tag>
        <tag>三次握手</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下C++开发入门学习]]></title>
    <url>%2F2017%2Flinux-Cpp.html</url>
    <content type="text"><![CDATA[开发环境CentOS Linux 7Kernel 3.10.0-327.e17.x86_64 一般linux安装完之后默认就已经安装了GCC(GNU Compiler Collection)，你可以查看一下gcc和g++的版本号检查gcc和g++是否已经安装。 gcc -v g++ -v g++和gcc的区别简单的说gcc是C的编译器，g++是C++的编译器。那是不是说gcc只能编译编译C语言，而g++只能编译C++呢？其实不是，gcc也可以编译C++程序，而C++是C的基础上发展而来的，所以g++也不可能编译不了c语言。它们之间的区别有如下几点： 后缀为.c的，gcc把它当作是C程序，而g++当作是c++程序；后缀为.cpp的，两者都会认为是c++程序。注意，虽然c++是c的超集，但是两者对语法的要求是有区别的，C++的语法规则更加严谨一些。 编译阶段，g++会调用gcc，对于c++代码，两者是等价的，但是因为gcc命令不能自动和C＋＋程序使用的库联接，所以通常用g++来完成链接，为了统一起见，干脆编译/链接统统用g++了，这就给人一种错觉，好像cpp程序只能用g++似的。用gcc进行编译，在选项中加上要链接的库，也可以编译c++。 第一个程序说到程序，第一个肯定就是HelloWorld，那我们也从HelloWorld开始吧，写一个最简单的Hello程序，并编译和运行。 [luowf@luoweifu Cplusplus]$ pwd /home/luowf/workspace/Cplusplus //在vim中编写第一个HelloWorld程序 [luowf@luoweifu Cplusplus]$ vi HelloWorld.cpp 1 #include &lt;iostream&gt; 2 3 int main() 4 { 5 std::cout &lt;&lt; &quot;Hello Wolrd!&quot; &lt;&lt; std::endl; 6 return 0; 7 } //编译程序 [luowf@luoweifu Cplusplus]$ g++ HelloWorld.cpp [luowf@luoweifu Cplusplus]$ ls a.out HelloWorld.cpp test1 test2 [luowf@luoweifu Cplusplus]$ ./a.out Hello Wolrd! g++ -o test1 HelloWorld.cpp 从HelloWorld.cpp编译生成test1文件，test1为可执行文件，没有后缀 如果不写-o test1 会默认生成一个a.out可执行文件 c/c++运行流程分解预处理阶段对c源文件预处理生成中间文件e.i [root@localhost c]# g++ -E funcuse.c -o e.i 编译阶段对预处理文件进行处理生成汇编语言文件e.s [root@localhost c]# g++ -S e.i -o e.s 上述两部可以直接合并为 [root@localhost c]# g++ -s e.i -o e.s 汇编阶段生成目标文件，目标文件是机器代码，但不能执行，必须将目标文件与其他目标文件或库文件连接生成可执行的二进制文件才能执行 [root@localhost c]# g++ -c e.s -o e.o 生成执行文件 [root@localhost c]# g++ e.o -o result 运行result [root@localhost c]# ./result 在linux操作系统中运行程序必须指定程序所在的目录，除非程序的目录已经列在PATH环境变量中，所以程序前必须加./ 注：echo $? 显示main函数的返回值（int型） 如果想让编译和运行同时进行可以采用如下命令： gcc funcuse.c -o result &amp;&amp; ./result &amp;&amp;表示如果成功就。。。如果编译成功，会直接运行程序 头文件与源文件程序如果复杂的话，程序的各个部分会分别存储在不同的文件中，按照逻辑进行划分。 头文件的作用就是被其他的.cpp包含,本身并不参与编译，但实际上它们的内容却在多个.cpp文件中得到了 编译. 头文件中应该只放变量和函数的声明，而不能放它们的定义 这个规则是有三个例外的 头文件中可以写const对象的定义 头文件中可 以写内联函数（inline）的定义 头文件中可以写类 （class）的定义 分离式编译如果将程序分成若干子程序，怎样在linux下进行编译呢？ 下面以求圆的面积为例来说明 Circle.h #ifndef CIRCLE_H #define CIRCLE_H class Circle { private: double r; public: Circle(); Circle(double R); double Area(); }; #endif Circle.cpp #include &quot;Circle.h&quot; #include &lt;iostream&gt; using namespace std; Circle::Circle() { this-&gt;r=5.0; } Circle::Circle(double R) { this-&gt;r=R; } double Circle:: Area() { return 3.14*r*r; } main.cpp #include &quot;Circle.h&quot; #include &lt;iostream&gt; using namespace std; int main(int argc, char *argv[]) { Circle c(3); cout&lt;&lt;&quot;Area=&quot;&lt;&lt;c.Area()&lt;&lt;endl; return 0; } 编译： [root@localhost cpp]# g++ -c Circle.cpp -o Circle.o [root@localhost cpp]# g++ -c main.cpp -o main.o [root@localhost cpp]# g++ main.o Circle.o -o main [root@localhost cpp]# ./main Area=28.26 -c命令表示编译，头文件不许显式编译，但实际已经编译。如果只修改了一个源文件，只需要编译改动的文件 Makefile但如果我们的程序有几百个源程序的时候，怎么办？难道也要编译器重新一个一个的编译？ makefile关系到了整个工程的编译规则。一个工程中的源文件不计数，其按类型、功能、模块分别放在若干个目录中，makefile定义了一系列的规则来指定，哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译，甚至于进行更复杂的功能操作，因为makefile就像一个Shell脚本一样，其中也可以执行操作系统的命令。 makefile带来的好处就是——“自动化编译”，一旦写好，只需要一个make命令，整个工程完全自动编译，极大的提高了软件开发的效率 #此行为注释 main: main.o Circle.o g++ main.o Circle.o -o main Circle.o:Circle.cpp g++ -c Circle.cpp -o Circle.o main.o:main.cpp g++ -c main.cpp -o main.o 注意：g++命令开头的行前面必须有tab空格，不然会报错： * missing separator. Stop**如果将名字命名为Makefile或makefile，只需要在命令行下敲入make就可以进行自动化编译 [root@localhost cpp]# make g++ -c main.cpp -o main.o g++ -c Circle.cpp -o Circle.o g++ main.o Circle.o -o main [root@localhost cpp]# ./main Area=28.26 参考： http://blog.163.com/dong_box/blog/static/2625977820103310933870/ http://www.chinaunix.net/old_jh/23/408225.html http://blog.csdn.net/livelylittlefish/article/details/3854220 GDB调试启动gdb [root@localhost c]# gdb GNU gdb (GDB) Red Hat Enterprise Linux (7.2-48.el6) Copyright (C) 2010 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type &quot;show copying&quot; and &quot;show warranty&quot; for details. This GDB was configured as &quot;i686-redhat-linux-gnu&quot;. For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;. 调试之前要先进性编译链接 [root@localhost c]# g++ -g funcuse.c -o dbug 进行调试 [root@localhost c]# gdb dbug Reading symbols from /home/weiwei/Desktop/c/dbug...done. 列出代码 (gdb) list 1 #include 2 3 int main(){ 4 for(int i=0 ; i&lt;5; i++){ 5 printf(“this is %d\n”,i); 6 } 7 return 0; 8 } (gdb) list 3,5 3 int main(){ 4 for(int i=0 ; i&lt;5; i++){ 5 printf(&quot;this is %d\n&quot;,i); 执行程序 (gdb) run Starting program: /home/weiwei/Desktop/c/dbug this is 0 this is 1 this is 2 this is 3 this is 4 设置断点 (gdb) break 5 Breakpoint 1 at 0x8048487: file funcuse.c, line 5. 运行 (gdb) r Starting program: /home/weiwei/Desktop/c/dbug Breakpoint 1, main () at funcuse.c:5 5 printf(&quot;this is %d\n&quot;,i); Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.25.el6.i686 libgcc-4.4.5-6.el6.i686 libstdc++-4.4.5-6.el6.i686 到断点处程序停止，继续运行输入continue (gdb) c Continuing. this is 0 Breakpoint 1, main () at funcuse.c:5 5 printf(&quot;this is %d\n&quot;,i); (gdb) c Continuing. this is 1 Breakpoint 1, main () at funcuse.c:5 5 printf(&quot;this is %d\n&quot;,i); (gdb) c Continuing. this is 2 检测某个值 (gdb) watch i Hardware watchpoint 2: i (gdb) c Continuing. this is 3 Hardware watchpoint 2: i Old value = 3 New value = 4 0x080484a0 in main () at funcuse.c:4 4 for(int i=0 ; i&lt;5; i++){ 查看某一个特定的变量 (gdb) print i 自动显示变量的值，每次运行到断点处都会自动显示 (gdb) display i 查看当前自动显示的所有变量 (gdb) info display Auto-display expressions now in effect: Num Enb Expression 1: y i 查看变量类型 (gdb) whatis i type = int 单步执行，step进入函数内部( 使用return命令跳出来 ，跳出前可以使用finish执行完函数体)，next把函数当成一条语句不进入函数内部 (gdb) step (gdb) next 删除编号为1的断点 (gdb) delete 1 程序编译常用命令将源代码编译成目标文件,不进行链接 gcc -c HelloWorld.cpp 在编译的时候，依据操作系统给予优化执行速度 gcc -O HelloWorld.cpp -c 将目标文件链接成二进行(可执行)文件 gcc -o HelloWorld HelloWorld.o -lstdc++ HelloWorld是可执行文件名，HelloWorld.o是目标文件名；如果是.c后缀的C源文件不用加-lstdc++，如果是.cpp后缀的C++源文件，要加-lstdc++。 在进行二进制文件制作时，将链接的函数库与相关的路径填入 (.cpp文件)gcc -lstdc++ HelloWorld.cpp 或 (.c文件)gcc HelloWorld.c -lm -L /usr/Lib -I /usr/include 说明：-lm 指的是libm.so或libm.a这个函数库文件；-L 后面接的路径是刚才上面那个函数库的搜索目录；-I 后面的是源码内的include文件(也就是包含的math.h头文件)所在的目录； 将编译链接的结果输出成某个特定的文件名 gcc -lstdc++ -o HelloWorld HelloWorld.cpp helloWorld为输出的文件名 在编译的时候，输出较多的信息说明 gcc -lstdc++ -o HelloWorld HelloWorld.cpp -Wall]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中程序编译流程解析]]></title>
    <url>%2F2017%2Fbianyiliucheng.html</url>
    <content type="text"><![CDATA[程序处理的基本流程如图： 预处理预处理相当于根据预处理指令组装新的C/C++程序。经过预处理，会产生一个没有宏定义，没有条件编译指令，没有特殊符号的输出文件，这个文件的含义同原本的文件无异，只是内容上有所不同。 读取C/C++源程序，对其中的伪指令（以#开头的指令）进行处理 ①将所有的“#define”删除，并且展开所有的宏定义 ②处理所有的条件编译指令，如：“#if”、“#ifdef”、“#elif”、“#else”、“endif”等。这些伪指令的引入使得程序员可以通过定义不同的宏来决定编译程序对哪些代码进行处理。预编译程序将根据有关的文件，将那些不必要的代码过滤掉。 ③处理“#include”预编译指令，将被包含的文件插入到该预编译指令的位置。 （注意：这个过程可能是递归进行的，也就是说被包含的文件可能还包含其他文件） 删除所有的注释 添加行号和文件名标识。 以便于编译时编译器产生调试用的行号信息及用于编译时产生的编译错误或警告时能够显示行号 保留所有的#pragma编译器指令 编译将预处理完的文件进行一系列词法分析、语法分析、语义分析及优化后，产生相应的汇编代码文件。 汇编将编译完的汇编代码文件翻译成机器指令，并生成可重定位目标程序的.o文件，该文件为二进制文件，字节编码是机器指令。 汇编器是将汇编代码转变成机器可以执行的指令，每一个汇编语句几乎都对应一条机器指令。所以汇编器的汇编过程相对于编译器来讲比较简单，它没有复杂的语法，也没有语义，也不需要做指令优化，只是根据汇编指令和机器指令的对照表一一翻译即可。 链接通过链接器将一个个目标文件（或许还会有库文件）链接在一起生成一个完整的可执行程序。由汇编程序生成的目标文件并不能立即就被执行，其中可能还有许多没有解决的问题。 例如，某个源文件中的函数可能引用了另一个源文件中定义的某个符号（如变量或者函数调用等）；在程序中可能调用了某个库文件中的函数，等等。所有的这些问题，都需要经链接程序的处理方能得以解决。 链接程序的主要工作就是将有关的目标文件彼此相连接，也就是将在一个文件中引用的符号同该符号在另外一个文件中的定义连接起来，使得所有的这些目标文件成为一个能够被操作系统装入执行的统一整体。 至此，大致经过这几个步骤，一个完整的可执行程序产生了。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>编译</tag>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下的C++多线程编程学习（二）]]></title>
    <url>%2F2017%2Fthread2.html</url>
    <content type="text"><![CDATA[上一篇中讲到一个多线程报数功能。为了描述方便和代码简洁起见，我们可以只输出最后的报数结果来观察程序是否运行出错。这也非常类似于统计一个网站每天有多少用户登录，每个用户登录用一个线程模拟，线程运行时会将一个表示计数的变量递增。程序在最后输出计数的值表示有今天多少个用户登录，如果这个值不等于我们启动的线程个数，那显然说明这个程序是有问题的。整个程序代码如下： #include &lt;stdio.h&gt; #include &lt;process.h&gt; #include &lt;windows.h&gt; volatile long g_nLoginCount; //登录次数 unsigned int __stdcall Fun(void *pPM); //线程函数 const int THREAD_NUM = 10; //启动线程数 unsigned int __stdcall ThreadFun(void *pPM) { Sleep(100); //some work should to do g_nLoginCount++; Sleep(50); return 0; } int main() { g_nLoginCount = 0; HANDLE handle[THREAD_NUM]; for (int i = 0; i &lt; THREAD_NUM; i++) handle[i] = (HANDLE)_beginthreadex(NULL, 0, ThreadFun, NULL, 0, NULL); WaitForMultipleObjects(THREAD_NUM, handle, TRUE, INFINITE); printf(&quot;有%d个用户登录后记录结果是%d\n&quot;, THREAD_NUM, g_nLoginCount); return 0; } 程序中模拟的是10个用户登录，程序将输出结果：和上一篇的线程报数程序一样，程序输出的结果好象并没什么问题。下面我们增加点用户来试试，现在模拟50个用户登录，为了便于观察结果，在程序中将50个用户登录过程重复20次，代码如下： #include &lt;stdio.h&gt; #include &lt;windows.h&gt; volatile long g_nLoginCount; //登录次数 unsigned int __stdcall Fun(void *pPM); //线程函数 const DWORD THREAD_NUM = 50;//启动线程数 DWORD WINAPI ThreadFun(void *pPM) { Sleep(100); //some work should to do g_nLoginCount++; Sleep(50); return 0; } int main() { printf(&quot; 原子操作 Interlocked系列函数的使用\n&quot;); printf(&quot; -- by MoreWindows( http://blog.csdn.net/MoreWindows ) --\n\n&quot;); //重复20次以便观察多线程访问同一资源时导致的冲突 int num= 20; while (num--) { g_nLoginCount = 0; int i; HANDLE handle[THREAD_NUM]; for (i = 0; i &lt; THREAD_NUM; i++) handle[i] = CreateThread(NULL, 0, ThreadFun, NULL, 0, NULL); WaitForMultipleObjects(THREAD_NUM, handle, TRUE, INFINITE); printf(&quot;有%d个用户登录后记录结果是%d\n&quot;, THREAD_NUM, g_nLoginCount); } return 0; } 运行结果如下图：现在结果水落石出，明明有50个线程执行了g_nLoginCount++;操作，但结果输出是不确定的，有可能为50，但也有可能小于50。 要解决这个问题，我们就分析下g_nLoginCount++;操作。在VS2013编译器对g_nLoginCount++;这一语句打个断点，再按F5进入调试状态，然后按下Debug工具栏的反编汇按钮，这样就出现了汇编代码窗口。可以发现在C/C++语言中一条简单的自增语句其实是由三条汇编代码组成的，如下图所示。 讲解下这三条汇编意思： 第一条汇编将g_nLoginCount的值从内存中读取到寄存器eax中。 第二条汇编将寄存器eax中的值与1相加，计算结果仍存入寄存器eax中。 第三条汇编将寄存器eax中的值写回内存中。 这样由于线程执行的并发性，很可能线程A执行到第二句时，线程B开始执行，线程B将原来的值又写入寄存器eax中，这样线程A所主要计算的值就被线程B修改了。这样执行下来，结果是不可预知的——可能会出现50，可能小于50。 因此在多线程环境中对一个变量进行读写时，我们需要有一种方法能够保证对一个值的递增操作是原子操作——即不可打断性，一个线程在执行原子操作时，其它线程必须等待它完成之后才能开始执行该原子操作。这种涉及到硬件的操作会不会很复杂了，幸运的是，Windows系统为我们提供了一些以Interlocked开头的函数来完成这一任务（下文将这些函数称为Interlocked系列函数）。 1.增减操作LONG__cdecl InterlockedIncrement(LONG volatile* Addend); LONG__cdecl InterlockedDecrement(LONG volatile* Addend); 返回变量执行增减操作之后的值。 LONG__cdec InterlockedExchangeAdd(LONG volatile* Addend, LONGValue); 返回运算后的值，注意！加个负数就是减。 2.赋值操作LONG__cdecl InterlockedExchange(LONG volatile* Target, LONGValue); Value就是新值，函数会返回原先的值。 在本例中只要使用InterlockedIncrement()函数就可以了。将线程函数代码改成： DWORD WINAPI ThreadFun(void *pPM) { Sleep(100);//some work should to do //g_nLoginCount++; InterlockedIncrement((LPLONG)&amp;g_nLoginCount); Sleep(50); return 0; } 程序中是用50个线程模拟用户登录，有兴趣的同学可以试下用100个线程来模拟一下（上机试试绝对会有意外发现^_^）。 改成100后，问题出在WaitForMultipleObjects函数，最大等待数为64若需实现大于64的情况需要做一些改变。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>多线程编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下的C++多线程编程学习（一）]]></title>
    <url>%2F2017%2Fthread1.html</url>
    <content type="text"><![CDATA[学习C++很久了却一直没有学到多线程编程的知识，现在就来学习一下并做个整理。我们可以用CreateThread和_beginthreadex来创建多线程程序，那么他们之间有什么样的区别呢？先看一个实例，下面这个程序的主线程会创建了一个子线程并等待其运行完毕，子线程就输出它的线程ID号然后输出一句经典名言——Hello World。整个程序的代码非常简短，只有区区几行。 //最简单的创建多线程实例 #include &lt;stdio.h&gt; #include &lt;windows.h&gt; //子线程函数 DWORD WINAPI ThreadFun(LPVOID pM) { printf(&quot;子线程的线程ID号为：%d\n子线程输出Hello World\n&quot;, GetCurrentThreadId()); return 0; } //主函数，所谓主函数其实就是主线程执行的函数。 int main() { printf(&quot; 最简单的创建多线程实例\n&quot;); printf(&quot; -- by MoreWindows( http://blog.csdn.net/MoreWindows ) --\n\n&quot;); HANDLE handle = CreateThread(NULL, 0, ThreadFun, NULL, 0, NULL); WaitForSingleObject(handle, INFINITE); return 0; } 下面来细讲下代码中的一些函数 CreateThread函数功能：创建线程 函数原型： HANDLE WINAPI CreateThread( LPSECURITY_ATTRIBUTES lpThreadAttributes, //第一个参数表示线程内核对象的安全属性，一般传入NULL表示使用默认设置。 SIZE_T dwStackSize, //第二个参数表示线程栈空间大小。传入0表示使用默认大小（1MB）。 LPTHREAD_START_ROUTINE lpStartAddress, //第三个参数表示新线程所执行的线程函数地址，多个线程可以使用同一个函数地址。 LPVOID lpParameter, //第四个参数是传给线程函数的参数。 DWORD dwCreationFlags, //第五个参数指定额外的标志来控制线程的创建，为0表示线程创建之后立即就可以进行调度，如果为CREATE_SUSPENDED则表示线程创建后暂停运行，这样它就无法调度，直到调用ResumeThread()。 LPDWORD lpThreadId //第六个参数将返回线程的ID号，传入NULL表示不需要返回该线程ID号。 ); 函数返回值： 成功返回新线程的句柄，失败返回NULL。 WaitForSingleObject函数功能：等待函数 – 使线程进入等待状态，直到指定的内核对象被触发。 函数原形： DWORD WINAPI WaitForSingleObject( HANDLE hHandle, //第一个参数为要等待的内核对象。 DWORD dwMilliseconds //第二个参数为最长等待的时间，以毫秒为单位，如传入5000就表示5秒， 传入0就立即返回，传入INFINITE表示无限等待。 ); 函数说明： 因为线程的句柄在线程运行时是未触发的，线程结束运行，句柄处于触发状态。所以可以用WaitForSingleObject()来等待一个线程结束运行。 函数返回值： 在指定的时间内对象被触发，函数返回WAIT_OBJEC\T_0。超过最长等待时间对象仍未被触发返回WAIT_TIMEOUT。传入参数有错误将返回WAIT_FAILED。 _beginthreadex的区别CreateThread()函数是Windows提供的API接口，在C/C++语言另有一个创建线程的函数_beginthreadex()，在很多书上（包括《Windows核心编程》）提到过尽量使用_beginthreadex()来代替使用CreateThread()，这是为什么了？ 为了解决像strerror()、strtok()、tmpnam()、gmtime()、asctime()等函数也会遇到这种由多个线程访问修改导致的数据覆盖问题。Windows操作系统提供了这样的一种解决方案——每个线程都将拥有自己专用的一块内存区域来供标准C运行库中所有有需要的函数使用。而且这块内存区域的创建就是由C/C++运行库函数_beginthreadex()来负责的。 _beginthreadex()函数在创建新线程时会分配并初始化一个_tiddata块。这个_tiddata块自然是用来存放一些需要线程独享的数据。事实上新线程运行时会首先将_tiddata块与自己进一步关联起来。然后新线程调用标准C运行库函数如strtok()时就会先取得_tiddata块的地址再将需要保护的数据存入_tiddata块中。这样每个线程就只会访问和修改自己的数据而不会去篡改其它线程的数据了。因此，如果在代码中有使用标准C运行库中的函数时，尽量使用_beginthreadex()来代替CreateThread()。 接下来，类似于上面的程序用CreateThread()创建输出“Hello World”的子线程，下面使用_beginthreadex()来创建多个子线程： //创建多子个线程实例 #include &lt;stdio.h&gt; #include &lt;process.h&gt; #include &lt;windows.h&gt; //子线程函数 unsigned int __stdcall ThreadFun(PVOID pM) { printf(&quot;线程ID号为%4d的子线程说：Hello World\n&quot;, GetCurrentThreadId()); return 0; } //主函数，所谓主函数其实就是主线程执行的函数。 int main() { printf(&quot; 创建多个子线程实例 \n&quot;); printf(&quot; -- by MoreWindows( http://blog.csdn.net/MoreWindows ) --\n\n&quot;); const int THREAD_NUM = 5; HANDLE handle[THREAD_NUM]; for (int i = 0; i &lt; THREAD_NUM; i++) handle[i] = (HANDLE)_beginthreadex(NULL, 0, ThreadFun, NULL, 0, NULL); WaitForMultipleObjects(THREAD_NUM, handle, TRUE, INFINITE); return 0; }]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>多线程编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析Linux进程间通信的几种方式]]></title>
    <url>%2F2017%2Flinux-commu.html</url>
    <content type="text"><![CDATA[进程通信的目的 数据传输一个进程需要将它的数据发送给另一个进程，发送的数据量在一个字节到几M字节之间 共享数据多个进程想要操作共享数据，一个进程对共享数据 通知事一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。 资源共享多个进程之间共享同样的资源。为了作到这一点，需要内核提供锁和同步机制。 进程控制有些进程希望完全控制另一个进程的执行（如Debug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变 linux使用的进程间通信方式管道( pipe )管道这种通讯方式有两种限制，一是半双工的通信，数据只能单向流动，二是只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 流管道s_pipe: 去除了第一种限制,可以双向传输. 管道可用于具有亲缘关系进程间的通信，命名管道:name_pipe克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信； 信号量( semophore )信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 信号是比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程本身；linux除了支持Unix早期信号语义函数sigal外，还支持语义符合Posix.1标准的信号函数sigaction（实际上，该函数是基于BSD的，BSD为了实现可靠信号机制，又能够统一对外接口，用sigaction函数重新实现了signal函数）； 消息队列( message queue )消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 消息队列是消息的链接表，包括Posix消息队列system V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。 信号 ( singal )信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 主要作为进程间以及同一进程不同线程之间的同步手段。 共享内存( shared memory )共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。 使得多个进程可以访问同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。 套接字( socket )套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信 更为一般的进程间通信机制，可用于不同机器之间的进程间通信。起初是由Unix系统的BSD分支开发出来的，但现在一般可以移植到其它类Unix系统上：Linux和System V的变种都支持套接字。 进程间通信各种方式效率比较 注:无连接: 指无需调用某种形式的OPEN,就有发送消息的能力流控制:如果系统资源短缺或者不能接收更多消息,则发送进程能进行流量控制 各种通信方式的比较和优缺点 管道：速度慢，容量有限，只有父子进程能通讯 FIFO：任何进程间都能通讯，但速度慢 消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题 信号量：不能传递复杂消息，只能用来同步 共享内存区：能够很容易控制容量，速度快，但要保持同步。比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存 如果用户传递的信息较少或是需要通过信号来触发某些行为．前文提到的软中断信号机制不失为一种简捷有效的进程间通信方式． 但若是进程间要求传递的信息量比较大或者进程间存在交换数据的要求，那就需要考虑别的通信方式了。 无名管道简单方便．但局限于单向通信的工作方式．并且只能在创建它的进程及其子孙进程之间实现管道的共享： 有名管道虽然可以提供给任意关系的进程使用．但是由于其长期存在于系统之中，使用不当容易出错．所以普通用户一般不建议使用。 消息缓冲可以不再局限于父子进程，而允许任意进程通过共享消息队列来实现进程间通信，并由系统调用函数来实现消息发送和接收之间的同步，从而使得用户在使用消息缓冲进行通信时不再需要考虑同步问题，使用方便，但是信息的复制需要额外消耗CPU的时间，不适宜于信息量大或操作频繁的场合。 共享内存针对消息缓冲的缺点改而利用内存缓冲区直接交换信息，无须复制，快捷、信息量大是其优点。 但是共享内存的通信方式是通过将共享的内存缓冲区直接附加到进程的虚拟地址空间中来实现的，因此，这些进程之间的读写操作的同步问题操作系统无法实现。必须由各进程利用其他同步工具解决。另外，由于内存实体存在于计算机系统中，所以只能由处于同一个计算机系统中的诸进程共享。不方便网络通信。 共享内存块提供了在任意数量的进程之间进行高效双向通信的机制。每个使用者都可以读取写入数据，但是所有程序之间必须达成并遵守一定的协议，以防止诸如在读取信息之前覆写内存空间等竞争状态的出现。 不幸的是，Linux无法严格保证提供对共享内存块的独占访问，甚至是在您通过使用IPC_PRIVATE创建新的共享内存块的时候也不能保证访问的独占性。 同时，多个使用共享内存块的进程之间必须协调使用同一个键值。]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ socket网络编程学习（二）TCP/UDP编程]]></title>
    <url>%2F2017%2Fsocket2.html</url>
    <content type="text"><![CDATA[原理部分 在网络编程中最常用的方案便是Client/Server (客户机/服务器)模型。在这种方案中客户应用程序向服务器程序请求服务。一个服务程序通常在一个众所周知的地址监听对服务的请求，也就是说，服务进程一 直处于休眠状态，直到一个客户向这个服务的地址提出了连接请求。在这个时刻，服务程序被”惊醒”并且为客户提供服务－对客户的请求作出适当的反应。 为了方便这种Client/Server模型的网络编程，90年代初，由Microsoft联合了其他几家公司共同制定了一套WINDOWS下的网络编 程接口，即Windows Sockets规范，它不是一种网络协议,而是一套开放的、支持多种协议的Windows下的网络编程接口。现在的Winsock已经基本上实现了与协议 无关，你可以使用Winsock来调用多种协议的功能，但较常使用的是TCP/IP协议。Socket实际在计算机中提供了一个通信端口，可以通过这个端 口与任何一个具有Socket接口的计算机通信。应用程序在网络上传输，接收的信息都通过这个Socket接口来实现。 微软为 Visual C++定义了Winsock类如CAsyncSocket类和派生于CAsyncSocket 的CSocket类，它们简单易用，读者朋友当然可以使用这些类来实现自己的网络程序，但是为了更好的了解Winsock API编程技术，我们这里探讨怎样使用底层的API函数实现简单的 Winsock 网络应用程式设计，分别说明如何在Server端和Client端操作Socket，实现基于TCP/IP的数据传送，最后给出相关的源代码。 在VC中进行WINSOCK的API编程开发的时候，需要在项目中使用下面的三个文件，否则会出现编译错误。 1．WINSOCK.H: 这是WINSOCK API的头文件，需要包含在项目中。 2．WSOCK32.LIB: WINSOCK API连接库文件。在使用中，一定要把它作为项目的非缺省的连接库包含到项目文件中去。 3．WINSOCK.DLL: WINSOCK的动态连接库，位于WINDOWS的安装目录下。 服务器端操作 socket（套接字）在初始化阶段调用WSAStartup() 此函数在应用程序中初始化Windows Sockets DLL ，只有此函数调用成功后，应用程序才可以再调用其他Windows Sockets DLL中的API函数。在程式中调用该函数的形式如下：WSAStartup((WORD)((1&lt;&lt;8|1)， （LPWSADATA）&amp;WSAData)，其中(1&lt;&lt;8|1)表示我们用的是WinSocket1.1版本，WSAata用来存 储系统传回的关于WinSocket的资料。 建立Socket 初始化WinSock的动态连接库后，需要在 服务器端建立一个监听的Socket，为此可以调用Socket()函数用来建立这个监听的Socket，并定义此Socket所使用的通信协议。此函数 调用成功返回Socket对象，失败则返回INVALID_SOCKET(调用WSAGetLastError()可得知原因，所有WinSocket 的API函数都可以使用这个函数来获取失败的原因)。 SOCKET PASCAL FAR socket( int af, int type, int protocol ) 参数: af:目前只提供 PF_INET(AF_INET)； type：Socket 的类型 (SOC\K_STREAM、SOCK_DGRAM)； protocol：通讯协定(如果使用者不指定则设为0)； 如果要建立的是遵从TCP/IP协议的socket，第二个参数type应为SOCK_STREAM，如为UDP（数据报）的socket，应为SOCK_DGRAM。 绑定端口 接下来要为服务器端定义的这个监听的Socket指定一个地址及端口（Port），这样客户端才知道待会要连接哪一个地址的哪个端口，为此我们要调用bind()函数，该函数调用成功返回0，否则返回SOCKET_ERROR。 int PASCAL FAR bind( SOCKET s, const struct sockaddr FAR *name,int namelen ); 参 数： s：Socket对象名； name：Socket的地址值，这个地址必须是执行这个程式所在机器的IP地址； namelen：name的长度； 如果使用者不在意地址或端口的值，那么可以设定地址为INADDR_ANY，及Port为0，Windows Sockets 会自动将其设定适当之地址及Port (1024 到 5000之间的值)。此后可以调用getsockname()函数来获知其被设定的值。 监听 当服务器端的Socket对象绑定完成之后,服务器端必须建立一个监听的队列来接收客户端的连接请求。listen()函数使服务器端的Socket 进入监听状态，并设定可以建立的最大连接数(目前最大值限制为 5, 最小值为1)。该函数调用成功返回0，否则返回SOCKET_ERROR。 int PASCAL FAR listen( SOCKET s, int backlog ); 参 数： s：需要建立监听的Socket； backlog：最大连接个数； 服务器端的Socket调用完listen（）后，如果此时客户端调用connect（）函数提出连接申请的话，Server 端必须再调用accept() 函数，这样服务器端和客户端才算正式完成通信程序的连接动作。为了知道什么时候客户端提出连接要求，从而服务器端的Socket在恰当的时候调用 accept()函数完成连接的建立，我们就要使用WSAAsyncSelect（）函数，让系统主动来通知我们有客户端提出连接请求了。该函数调用成功 返回0，否则返回SOCKET_ERROR。 int PASCAL FAR WSAAsyncSelect( SOCKET s, HWND hWnd,unsigned int wMsg, long lEvent ); 参数： s：Socket 对象； hWnd ：接收消息的窗口句柄； wMsg：传给窗口的消息； lEvent：被注册的网络事件，也即是应用程序向窗口发送消息的网路事件，该值为下列值FD_READ、FD_WRITE、FD_OOB、 FD_ACCEPT、FD_CONNECT、FD_CLOSE的组合，各个值的具体含意为FD_READ：希望在套接字S收到数据时收到消 息；FD_WRITE：希望在套接字S上可以发送数据时收到消息；FD_ACCEPT：希望在套接字S上收到连接请求时收到消息；FD_CONNECT： 希望在套接字S上连接成功时收到消息；FD_CLOSE：希望在套接字S上连接关闭时收到消息；FD_OOB：希望在套接字S上收到带外数据时收到消息。 具体应用时，wMsg应是在应用程序中定义的消息名称，而消息结构中的lParam则为以上各种网络事件名称。所以，可以在窗口处理自定义消息函数中使用 以下结构来响应Socket的不同事件： switch(lParam) { case FD_READ: … break; case FD_WRITE: … break; … } 服务器端接受客户端的连接请求 当Client提出连接请求时，Server 端hwnd视窗会收到Winsock Stack送来我们自定义的一个消息，这时，我们可以分析lParam，然后调用相关的函数来处理此事件。为了使服务器端接受客户端的连接请求，就要使用 accept() 函数，该函数新建一Socket与客户端的Socket相通，原先监听之Socket继续进入监听状态，等待他人的连接要求。该函数调用成功返回一个新产 生的Socket对象，否则返回INVALID_SOCKET。 SOCKET PASCAL FAR accept( SCOKET s, struct sockaddr FAR addr,int FAR addrlen ); 参数：s：Socket的识别码； addr：存放来连接的客户端的地址； addrlen：addr的长度 结束 socket 连接 结束服务器和客户端的通信连接是很简单的，这一过程可以由服务器或客户机的任一端启动，只要调用closesocket()就可以了，而要关闭 Server端监听状态的socket，同样也是利用此函数。另外，与程序启动时调用WSAStartup()憨数相对应，程式结束前，需要调用 WSACleanup() 来通知Winsock Dll释放Socket所占用的资源。这两个函数都是调用成功返回0，否则返回SOCKET_ERROR。 int PASCAL FAR closesocket( SOCKET s ); 参数：s：Socket 的识别码； int PASCAL FAR WSACleanup( void ); 参数： 无 TCP与UDP在socket编程中的区别TCP与UDP的区别基于连接与无连接 对系统资源的要求（TCP较多，UDP少） UDP程序结构较简单 流模式与数据报模式 TCP保证数据正确性，UDP可能丢包 TCP保证数据顺序，UDP不保证 部分满足以下几点要求时，应该采用UDP 面向数据报方式 网络数据大多为短消息 拥有大量Client 对数据安全性无特殊要求 网络负担非常重，但对响应速度要求高 具体编程时的区别 socket()的参数不同 UDP Server不需要调用listen和accept UDP收发数据用sendto/recvfrom函数 TCP：地址信息在connect/accept时确定 UDP：在sendto/recvfrom函数中每次均 需指定地址信息 UDP：shutdown函数无效 man—-socket通过查看socket的man手册可以看到socket函数的第一个参数的值可以为下面这些值：Name PurposePF_UNIX, PF_LOCAL Local communicationPF_INET IPv4 Internet protocolsPF_INET6 IPv6 Internet protocolsPF_IPX IPX - Novell protocolsPF_NETLINK Kernel user interface devicePF_X25 ITU-T X.25 / ISO-8208 protocolPF_AX25 Amateur radio AX.25 protocolPF_ATMPVC Access to raw ATM PVCsPF_APPLETALK AppletalkPF_PACKET Low level packet interface 编程区别通常我们在说到网络编程时默认是指TCP编程，即用前面提到的socket函数创建一个socket用于TCP通讯，函数参数我们通常填为SOCK_STREAM。即socket(PF_INET, SOCK_STREAM, 0)，这表示建立一个socket用于流式网络通讯。 SOCK_STREAM这种的特点是面向连接的，即每次收发数据之前必须通过connect建立连接，也是双向的，即任何一方都可以收发数据，协议本身提供了一些保障机制保证它是可靠的、有序的，即每个包按照发送的顺序到达接收方。 而SOCK_DGRAM这种是User Datagram Protocol协议的网络通讯，它是无连接的，不可靠的，因为通讯双方发送数据后不知道对方是否已经收到数据，是否正常收到数据。任何一方建立一个socket以后就可以用sendto发送数据，也可以用recvfrom接收数据。根本不关心对方是否存在，是否发送了数据。它的特点是通讯速度比较快。大家都知道TCP是要经过三次握手的，而UDP没有。 TCP编程的服务器端一般步骤是： 1、创建一个socket，用函数socket()； 2、设置socket属性，用函数setsockopt(); * 可选 3、绑定IP地址、端口等信息到socket上，用函数bind(); 4、开启监听，用函数listen()； 5、接收客户端上来的连接，用函数accept()； 6、收发数据，用函数send()和recv()，或者read()和write(); 7、关闭网络连接； 8、关闭监听； #include &lt;stdio.h&gt; #include &lt;Winsock2.h&gt; #pragma comment(lib, &quot;ws2_32.lib&quot;) void main() { WORD wVersionRequested; WSADATA wsaData; int err; wVersionRequested = MAKEWORD( 1, 1 ); err = WSAStartup( wVersionRequested, &amp;wsaData ); if ( err != 0 ) { return; } if ( LOBYTE( wsaData.wVersion ) != 1 || HIBYTE( wsaData.wVersion ) != 1 ) { WSACleanup( ); return; } SOCKET sockSrv=socket(AF_INET,SOCK_STREAM,0); SOCKADDR_IN addrSrv; addrSrv.sin_addr.S_un.S_addr=htonl(INADDR_ANY); addrSrv.sin_family=AF_INET; addrSrv.sin_port=htons(6000); bind(sockSrv,(SOCKADDR*)&amp;addrSrv,sizeof(SOCKADDR));// 绑定端口 listen(sockSrv,5); SOCKADDR_IN addrClient;// 连接上的客户端ip地址 int len=sizeof(SOCKADDR); while(1) { SOCKET sockConn=accept(sockSrv,(SOCKADDR*)&amp;addrClient,&amp;len);// 接受客户端连接,获取客户端的ip地址 char sendBuf[50]; sprintf(sendBuf,&quot;Welcome %s to here!&quot;,inet_ntoa(addrClient.sin_addr));// 组合消息发送出去 send(sockConn,sendBuf,strlen(sendBuf)+1,0);// 发送消息到客户端 char recvBuf[50]; recv(sockConn,recvBuf,50,0);// 接受客户端消息 printf(&quot;%s\n&quot;,recvBuf); //closesocket(sockConn);//断开连接 } } TCP编程的客户端一般步骤是： 1、创建一个socket，用函数socket()； 2、设置socket属性，用函数setsockopt(); 可选 3、绑定IP地址、端口等信息到socket上，用函数bind(); 可选 4、设置要连接的对方的IP地址和端口等属性； 5、连接服务器，用函数connect()； 6、收发数据，用函数send()和recv()，或者read()和write(); 7、关闭网络连接； #include &lt;stdio.h&gt; #include &lt;Winsock2.h&gt; #pragma comment(lib, &quot;ws2_32.lib&quot;) void main() { WORD wVersionRequested; WSADATA wsaData;//WSAata用来存储系统传回的关于WinSocket的资料。 int err; wVersionRequested = MAKEWORD( 1, 1 ); err = WSAStartup( wVersionRequested, &amp;wsaData ); if ( err != 0 ) { return; } if ( LOBYTE( wsaData.wVersion ) != 1 ||HIBYTE( wsaData.wVersion ) != 1 ) { WSACleanup( ); return; } SOCKET sockClient=socket(AF_INET,SOCK_STREAM,0);// AF_INET ..tcp连接 //初始化连接与端口号 SOCKADDR_IN addrSrv; addrSrv.sin_addr.S_un.S_addr=inet_addr(&quot;127.0.0.1&quot;);//本机地址，服务器在本机开启 addrSrv.sin_family=AF_INET; addrSrv.sin_port=htons(6000);// 设置端口号 connect(sockClient,(SOCKADDR*)&amp;addrSrv,sizeof(SOCKADDR));//连接服务器 char recvBuf[50]; recv(sockClient,recvBuf,50,0);//接受数据 printf(&quot;%s\n&quot;,recvBuf); send(sockClient,&quot;hello&quot;,strlen(&quot;hello&quot;)+1,0);//发送数据 closesocket(sockClient);//关闭连接 WSACleanup(); } UDP编程的服务器端一般步骤是： 1、创建一个socket，用函数socket()； 2、设置socket属性，用函数setsockopt();* 可选 3、绑定IP地址、端口等信息到socket上，用函数bind(); 4、循环接收数据，用函数recvfrom(); 5、关闭网络连接； #include &lt;stdio.h&gt; #include &lt;Winsock2.h&gt; #pragma comment(lib, &quot;ws2_32.lib&quot;) void main() { //初始化socket库 WORD wVersionRequested; WSADATA wsaData; int err; wVersionRequested = MAKEWORD( 1, 1 ); err = WSAStartup( wVersionRequested, &amp;wsaData ); if ( err != 0 ) { return; } if ( LOBYTE( wsaData.wVersion ) != 1 || HIBYTE( wsaData.wVersion ) != 1 ) { WSACleanup( ); return; } SOCKET sockSrv = socket( AF_INET , SOCK_DGRAM , 0 ) ; SOCKADDR_IN addrSrv ; addrSrv.sin_addr.S_un.S_addr = htonl(INADDR_ANY) ; addrSrv.sin_family = AF_INET ; addrSrv.sin_port = htons(4000) ; bind( sockSrv , (SOCKADDR*)&amp;addrSrv , sizeof(SOCKADDR) ) ; char sendBuf[100] ; char recvBuf[100] ; char tempBuf[200] ; SOCKADDR_IN addrClient ; int len = sizeof(SOCKADDR) ; while (1) { recvfrom(sockSrv,recvBuf,100,0,(SOCKADDR*)&amp;addrClient,&amp;len) ; if ( &apos;q&apos; == recvBuf[0] ) { sendto(sockSrv,&quot;q&quot;,strlen(&quot;q&quot;)+1,0,(SOCKADDR*)&amp;addrClient,len) ; printf(&quot;chat end!\n&quot;) ; break ; } sprintf(tempBuf,&quot;%s say : %s&quot;,inet_ntoa(addrClient.sin_addr),recvBuf) ; printf( &quot;%s\n&quot; , tempBuf ) ; printf( &quot;Please input data:\n&quot; ) ; gets( sendBuf ) ; sendto(sockSrv,sendBuf,strlen(sendBuf)+1,0,(SOCKADDR*)&amp;addrClient,len) ; } closesocket( sockSrv ) ; WSACleanup() ; } UDP编程的客户端一般步骤是： 1、创建一个socket，用函数socket()； 2、设置socket属性，用函数setsockopt(); 可选 3、绑定IP地址、端口等信息到socket上，用函数bind(); 可选 4、设置对方的IP地址和端口等属性; 5、发送数据，用函数sendto(); 6、关闭网络连接； #include &lt;stdio.h&gt; #include &lt;Winsock2.h&gt; #pragma comment(lib, &quot;ws2_32.lib&quot;) void main() { //初始化socket库 WORD wVersionRequested; WSADATA wsaData; int err;wVersionRequested = MAKEWORD( 1, 1 ); err = WSAStartup( wVersionRequested, &amp;wsaData ); if ( err != 0 ) { return; } if ( LOBYTE( wsaData.wVersion ) != 1 || HIBYTE( wsaData.wVersion ) != 1 ) { WSACleanup( ); return; } SOCKET sockClient = socket( AF_INET , SOCK_DGRAM , 0 ) ; SOCKADDR_IN addrSrv ; addrSrv.sin_addr.S_un.S_addr = inet_addr(&quot;127.0.0.1&quot;) ; addrSrv.sin_family = AF_INET ; addrSrv.sin_port = htons(4000) ; char sendBuf[100] ; char recvBuf[100] ; char tempBuf[200] ; int len = sizeof(SOCKADDR) ; while (1) { printf(&quot;Please input data:\n&quot;); gets( sendBuf ) ; sendto( sockClient , sendBuf , strlen(sendBuf) , 0 , (SOCKADDR*)&amp;addrSrv , len ) ; recvfrom( sockClient , recvBuf , 100 , 0 , (SOCKADDR*)&amp;addrSrv , &amp;len ) ; if ( &apos;q&apos; == recvBuf[0] ) { sendto(sockClient , &quot;q&quot; , strlen(&quot;q&quot;)+1 , 0 , (SOCKADDR*)&amp;addrSrv , len) ; printf(&quot;chat end!&quot;) ; break ; } sprintf( tempBuf , &quot;%s say: %s\n&quot; , inet_ntoa(addrSrv.sin_addr) , recvBuf ) ; printf( tempBuf ) ; } closesocket(sockClient) ; WSACleanup() ; }]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>socket</tag>
        <tag>网络编程</tag>
        <tag>TCP/UDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基础知识总结]]></title>
    <url>%2F2017%2Flinux.html</url>
    <content type="text"><![CDATA[Linux结构可以把Linux系统看作由四部分构成：内核、用户界面、文件结构和实用工具。 /bin 普通用户的可执行文件，系统的任何用户都可以执行该目录中的命令 /boot 存放Linux操作系统启动时所需要的文件 /dev 系统中所有设备文件 /etc 系统中的配置文件 /home 普通用户的宿主目录，每个用户在该目下都有一个于用户名同名的目录。 /mnt 中的子目录用于系统中可移动设备的挂载点 /root 超级用户root的宿主目录 /sbin 系统中的管理命令，普通用户不能执行 /tmp 系统的临时目录 /usr 系统应用程序的相关文件 /var 系统中经常变化的文件如日志文件和用户邮件 通配符： * 代表多个字母或数字 ？ 一个 别名： 命令：alias显示系统当前定义的所有alias alias cp =&apos;cp-i&apos; alias ll=&apos;ls -l --color = tty&apos; Linux基本命令启动 shutdown - r now 重启 shutdown - h now 立刻关机 reboot 重启 文件查看和连接cat cat [选项] (file1)… more 显示文件内容，带分页 less 显示文件内容，带分页 grep 在文本中查询指定内容管道命令[把上一个命令的结果给|后的命令处理] grep &quot;shunping&quot; aaa.java grep -n ...... 显示行数 grep -n &quot;shunping&quot; aaa.java &gt; kkk.bak 重定向命令 ls -l &gt; a.txt 列表的内容写入文件 a.txt（覆盖写） ls -l &gt;&gt; a.txt 追加写到文件的末尾 find的使用：在特定目录下搜索并显示指定名称的文件和目录，搜索一段时间内被存取/变更的文件或目录。 find /home -amin -10 十分钟内存取的文件和目录 find /home -atime -10 十小时 find /home -cmin -10 十分钟内更改过的 find /home -size +10k 大小为10k的 将目前目录及其子目录下所有延伸档名是 c 的档案列出来。 #find . -name “*.c”将目前目录其其下子目录中所有一般档案列出 #find . -ftype f将目前目录及其子目录下所有最近 20 分钟内更新过的档案列出 #find . -ctime -20 命令的操作more more [选项] …分屏显示命令 less less [选项] 按页显示命令 clear 清除屏幕命令 history 查看历史命令记录 目录相关cd .. 可进入上一层目录 cd - 进入上一个进入的目录 cd ~ 可进入用户的home目录 pwd 显示当前在哪个路径 ls 列出文件和目录 ls -a 显示隐藏文件 ls -l 显示常列表格式 mkdir 建立目录 rmdir 删除空目录 touch 建立空文件 文件权限文件操作cp 复制命令 mv 移动文件和改文件rm 删除文件和目录rm -rf * 删除所有内容（包括目录和文件）如何修改文件的访问权限 chmod 777 along 范例 :将档案 file1.txt 设为所有人皆可读取: chmod ugo+r file1.txt 将档案 file1.txt 设为所有人皆可读取: chmod a+r file1.txt 将档案 file1.txt 与 file2.txt 设为该档案拥有者,与其所属同一个群体者可写入,但其他以外的人则不可写入: chmod ug+w,o-w file1.txt file2.txt 将 ex1.py 设定为只有该档案拥有者可以执行: chmod u+x ex1.py 将目前目录下的所有档案与子目录皆设为任何人可读取: chmod -R a+r * 用户组操作su- 切换成系统管理员 su 用户之间的切换 logout 用户注销 useradd xiaoming 添加用户（root下） passwd xiaoming 设置xiaoming的密码 userdel xiaoming 删除用户 userdel -r xiaoming删除用户及其主目录 每个用户必须属于某一个组，不能独立于组外。每个文件有所有者、所在组、其它组的概念 *1，所有者：一般指创建者 用ls -ahl 命令可以查看文件的所有者 用chown 用户名 文件名 来修改文件的所有者 *2，文件所在组 —-用户所在的组 ls -ahl 可以看见文件的所有组 chgrp 组名 文件名 修改文件所在组 *3，其它组—除开文件的所有者和所在组的用户外， 系统其他用户都是文件的其他组 添加组 ---groupadd policeman 查看Linux中所有组 ： vi /etc/group 查看该文件或cat /etc/group | more 创建用户并指定将该用户分配到哪个组 useradd -g 组名 用户名 查看Linux中所有用户信息：vi /etc/passwd 或者cat /etc/passwd 文件权限：—–分为三种：r-可读，用四表示w-可写，用2表示x-可执行，用1表示 -d ：指定用户主目录，默认情况下，将会在/home目录下新建一个与用户名相同的用户主目录 删除用户的命令为userdel，该命令的格式为：userdel &lt;用户名&gt; 修改用户属性 usermod –g&lt;主组名&gt; -G &lt;组名&gt; -d &lt;用户主目录&gt; -s &lt;用户shell&gt; 在添加用户时，可以指定将该用户添加到哪个组中，同样的用root的管理权限可以改变某个用户所在的组：usermod -g 组名 用户名 可以用 usermod -d 目录名 用户名 改变该用户登录的初始目录 增加用户组 groupadd &lt;新组名&gt; 删除用户组 groupdel &lt;组名&gt; 修改组成员：直接编辑/etc/group文件，将用户名写到对应的组名的后面 whoami命令的功能在于显示用户自身的用户名。 who [选项]：该命令主要用于查看当前在线的用户情况 w命令 ：用于显示登录到系统的用户情况 finger命令可用于查找和显示用户信息，并且在查找后显示指定账号的相关信息 chfn命令能够改变系统存储的用户信息 切换用户身份：su [用户名] 帮助命令man &lt;command&gt; info &lt;command&gt; help [command] VI命令vi有三种基本工作模式，分别是：命令模式（command mode）、插入模式（insert mode）和底行模式（last line mode） 进入vi： 命令“vi 文件名” 命令“vi”，在退出vi时再指定文件名 选项“+n”，表示希望在进入vi之后，光标处于文件中第n行上， 选项“+”表示希望在进入vi之后光标处于文件最末行。 保存文件: 1.在命令模式下,连按两次大写字母。 2.在末行模式下: :w vi保存当前编辑的文件，但并不退出vi，而是继续等待用户输入命令。 :w &lt;newfile&gt; :w! &lt;newfile&gt; 把当前文件的内容保存到指定的文件newfile中，如果newfile已经存在，则覆盖原有内容。 在末行模式下，有四种方法可以退出vi返回到shell： :q 系统退出vi返回到shell。在用此命令时，若编辑的文件没有被保存，则vi在窗口的最末行给出提示信息。 :q! vi放弃所作修改而直接退到shell下。 :wq 先保存文件，然后再退出vi返回到shell。 :x 该命令的功能与命令模式下的ZZ命令功能相同 0（数字0） 移到当前行的行首 $ 移到当前行的行尾 设备硬盘操作挂载设备 查看设备：使用命令“fdisk –l”可以查看系统的存储设备 挂载设备 ：首先使用mkdir命令建立挂载点目录，然后再使用mount命令挂载相关设备 mkfs [选项][-t &lt;文件系统类型&gt;] [设备名称] [区块数] 说明：把指定的设备格式为指定的文件系统。 查看磁盘使用情况 df [-参数] 比如， df-l 查看某个目录是在哪个分区 df [目录全路径] 查看Linux系统分区具体情况 fdish -l 网络配置配置网络接口可以使用三种不同的工具来完成： 1使用网络接口配置程序netconfig 2使用图形配置工具 3使用终端命令ifconfig 监控网络状态信息:显示网络统计信息的命令netstat此命令用来显示整个系统目前的网络情况。例如目前的连接、数据包传递数据 、或路由表的内容。如 netstat -an netstat -anp|more (查看网络端口的使用的情况)显示数据包经过历程命令：traceroute route 查看路由表 1.追踪路由 ：tracert 目标ip/域名 2.测试两个ip是否畅通：ping 目标IP 3.window下查看IP情况：ipconfig 4.Linux/unix下查看IP情况：ifconfig 5.linux 网络环境配置： 第一种： (1) 用root身份登陆，运行setup命令进入到text mode setup utility 对网络进行配置，这里可以进行ip、子网掩码、默认网管、dns的设置 (2) 这时网卡的配置没有立即生效，运行 /etc/rc.d/init.d/network restart命令我们刚才作的配置生效。 第二种： (1)ifconfig eth0 x.x.x.x对网卡进行设置 (2)infconfig eth0 network x.x.x.x对子网掩码设置 对广播地址和dns使用默认的 注意：这样配置网络会立即生效，但是是临时生效 第三种： (1) 修改/etc/sysconfig/network-scripts/ifcfg-eth0 这个文件的各个属性可以修改，包括ip，子网掩码、广播地址、默认网关 (2)这是网卡的配置没有生效运行/etc/rc.d/init.d/network restart 命令我们刚才做的设置才生效Linux中的所有设备都是文件，这种方法是最底层的方法，永久性修改 VMware下Linux和window ping (1) windows下ipconfig查看VM网卡IP (2) 配置Linux的IP使两者处于同一个子网的 即可以ping通 ifconfig &lt;设备名&gt; &lt;IP地址&gt; netmask &lt;掩码&gt; 例如： ifconfig eth0 192.168.15.11 netmask 255.255.255.0 在网络配置界面中，通过“激活”或者“解除”按钮可以启动或者禁用网络接口， 网络控制程序network /etc/rc.d/init.d/network start|stop|restart 命令ifconfig : ifconfig &lt;设备名&gt; [up|down] 命令ifup/ifdown ifup eth0 ifdown eth0 安装软件获取最新版本的Apache源代码 将源代码解压缩 ./configure –- prefix=/home/myapache 执行编译命令：make 执行安装命令：make install 账号和用户管理 用户和组的配置信息保存在以下三个文件中： /etc/passwd /etc/shadow /etc/etc/group 更改文件所有者chownchown [选项] user[:group] &lt;file&gt;... 更改文件访问权限命令chmod chmod [选项] &lt;mode&gt; &lt;file&gt;... mode：[ugoa][[+-=][rwxX]...][,…]， mode也可以用数字来表示权限： chmod abc file a,b,c各为一个数字，分别表示User、Group、及Other的权限。权限是关于可读（r）、可写(w)、可执行(r)三个属性设置值的和，其中r=4，w=2，x=1， 例如： 若要rwx属性，则4+2+1=7； 若要rw-属性，则4+2=6； 若要r-x属性，则4+1=7 进程管理Linux操作系统包括三种不同类型的进程，每种进程都有自己的特点和属性： 交互进程:由shell启动的进程。 批处理进程:这种进程和终端没有联系，是一个进程序列。 守护进程:在后台持续运行的进程。 前台启动:一般地，用户键入一个命令，就已经启动了一个前台的进程。 后台启动 :对于非常耗时进程，可以然进程在后台运行。从后台启动进程其实就是在命令结尾加上一个“&amp;”号 每个进程，都会对应一个父进程，而这个父进程可以复制多个子进程每个进程都可能以两种方式存在：后台或前台 进程就是正在执行的程序 显示系统执行的进程：ps命令，可以不加任何参数 1. ps -a :显示当前终端的所有进程信息 2：ps -u :以用户的格式显示进程信息 3. ps -x :显示后台进程运行的参数 ps -aux 终止进程：kill/killall 终止某个进程：kill 进程号 如：kill 6251 kill -q 5222 ：因为某些进程会捕捉某些信息，如果直接不能结束进程，可以使用“ -q”传送信息 动态监控进程：top top和ps类似，top在执行一段时间可以更新正在进行的进程 1.监视特定用户 top：输入此命令,按回车键，查看执行的进程 u：然后输入“u” 回车，在输入用户名即可 2.终止指定的进程 top： k: 输入k回车，再输入要结束的进程ID 3.top -d 10 :指定系统更新进程的时间为10秒 按小q退出 任务调度任务调度指系统在某个时间执行的特定的命令和程序 任务调度分类： 1.系统工作：有些重要的工作必须周而复始的执行，如病毒扫描….. 2.个别用户工作：个别用户可能希望执行某些程序 置任务调度文件：/etc/crontab 设置个人任务调度：执行crontab -e命令 接着输入任务到调度文件 如：5**** ls -l /etc/ &gt; /tmp/to.txt 意思是说每小时的第五分钟执行ls -l /etc/ &gt; /tmp/to.txt 任务调度的使用： 1.设置任务 crontab -e 2.每隔一定时间去执行 data &gt; /home/mydata1 希望每天凌晨2：00执行 date &gt;&gt; /home/mydate 02*** date &gt;&gt; /home/mydate 调度文件的规则： 字段名称 说明 范围 分钟 每小时第几分钟 0~59 小时 每日的第几个小时 0~23 日期 每月的第几天 1~31 日历 每年的第几个月 1~12 星期 每周的第几天 0~6 3.怎么样调度多个任务？ a.在crontab -e 中直接写 b.可以把所有的任务写入一个可执行文件（shell编程） 例子： vi mytask.sh date &gt;&gt; /home/mydate cp /home/mydate /root chmod 744 mytask.sh crontab -e ***** /root/mytask.sh 终止任务调度： crontab -r ：终止任务调度 crontab -l ：列出当前有哪些任务调度 at命令在shell提示符下输入”at 时间”，然后按回车键。这时在下一行shell会等待用户继续输入要执行的命令。每一行输入一个命令，所有命令都输入完毕后按Ctrl+d键结束。 将各个命令写入shell脚本中，然后使用下面格式设置在指定时间执行shell脚本中的命令： at 时间 –f脚本文件。 batch命令crone命令在系统启动时由一个shell脚本自动启动，进入后台。 cron启动后搜索/var/spool/cron目录，寻找以/etc/passwd文件中的用户名命名的crontab文件，被找到的这种文件将载入内存。 如果没有crontab文件，就转入“休眠”状态，释放系统资源。 cron每分钟“醒”过来一次，查看当前是否有需要运行的命令。 如果发现某个用户设置了crontab文件，它将以该用户的身份去运行文件中指定的命令。命令执行结束后，任何输出都将作为邮件发送给crontab的所有者，或者/etc/crontab文件中MAILTO环境变量中指定的用户。 内存查看命令free 磁盘空间用量查看命令df shell命令作为命令语言互动式地解释和执行用户输入的命令只是shell功能的一个方面 另外shell还可以进行程序设计，他提供了定义变量和参数的手段以及丰富的程序控制结构。使用shell类似于DOS中的批处理文件称为shell script shell有很多，常用的有3种：/bin/sh /bin/csh /bin/ksh 查看shell种类 ：ls -l /bin/*sh 1.查看目前使用的是哪种shell env [该命令可以显示当前操作系统的环境变量] 2.shell的修改: 直接输入：chsh -s 输入新的shell 如：/bin/csh 设置日期1.date命令。可以直接输入date 来查看系统时间 2.利用date命令来更改系统时间 date MMDDHHMCCYY.SS:指定月月日日时时分分年年年年.秒秒 3.查看日历：cal 3 2002 ：查看2001年3月的日历 4.查看年历：cal 2008 软件安装1.linux JDK的安装 a.把**.iso 文件挂载在虚拟机上做好配置 mount /mnt/cdrom unmount /mnt/cdrom b.把安装文件拷贝到 /home cp 文件 /home c.cd /home d.安装 ./**.bin e.看看文件 /etc/profile[环境配置文件] f.配置刚才自己安装的JDK 2.eclipse a.安装文件拷贝到 /home b.安装 tar -zxvf **.tar.gz c.启动eclipse[进入图形界面] startx ./eclipse ./eclipse &amp; 后台方式运行 RPM管理介绍：一种用于互联网下载包的打包及安装工具，它包含在某些Linux分发版中。它生成 具有.RPM扩展名的文件。 RPM是RedHat Package Manager（RedHat软件包管理工具）的缩写 RPM包的名称格式：apache-1.3.23-11.i386.rpm **RPM 常用命令 rpm -qa:查询所安装的所有rpm软件包 rpm -qa | more rpm -pa | grep x rpm -q 软件包名 （查询软件包是否安装） rpm -q foo rpm -qi 软件包名：查询软件包信息 rpm -ql file rpm -ql 软件包名 ：查询软件包中的文件 rpm -ql file rpm -qf文件全路径名：查询文件所属的软件包 rpm -qf /etc/passwd rpm -qp包文件名：查询包的信息、对这个软件包的介绍 rpm -qp jdk-1-5_linux -i586.rpm 安装rpm包： rpm -i RPM包路径名称：安装包到当前系统 i = install rpm -ivh RPM包全路径名称：安装包到当前系统有提示信息 参数说明：i = install 安装 v = verbase 提示 h = hash 进度条 删除rpm包：rpm -e jdk 如果其它软件包依赖于您要卸载的软件包，卸载时则会产生错误的信息 如果忽略这个错误信息继续卸载，使用 --nodeps命令行选项 升级rpm包： rpm -u RPM包全路径包 其他cat主要有三大功能：1.一次显示整个文件。2.从键盘创建一个文件，只能创建新文件,不能编辑已有文件.3.将几个文件合并为一个文件 touch命令 创建空白文件或修改文件时间 apache目录访问控制的参数有：AuthName:验证窗口的名称AuthType:验证的类型，这里定义的是BasicAuthUserFile:验证所使用的帐号密码配置文件Require:指定可以登录网页的用户 Linux下多线程编程常用的pthread库提供的函数名和意义：pthread_create 创建一个线程pthread_join用来等待一个线程的结束pthread_mutex_init 初始化一个线程互斥锁pthread_exit结束一个线程 Linux操作系统包括三种不同类型的进程，每种进程都有自己的特点和属性。 1.交互进程——由一个shell启动的进程。交互进程既可以在前台运行，也可以在后台运行。 2.批处理进程——这种进程和终端没有联系，是一个进程序列。 3.监控进程（也称守护进程）——Linux系统启动时启动的进程，并在后台运行。 arm-linux-gcc -g -o example example.c-g选项，加入GDB能够 使用 的调试信息, 使用 GDB调试时比较方便 arm-linux-gcc -o example example.c不加-c、-S、-E参数，编译器将执行预处理、编译、汇编、连接操作直接生成可执行代码。-o参数用于指定输出的文件，输出文件名为example,如果不指定输出文件，则默认输出a.out arm-linux-gcc -c -o example.o example.c-c参数将对源程序example.c进行预处理、编译、汇编操作，生成example.0文件去掉指定输出选项”-o example.o”自动输出为example.o,所以说在这里-o加不加都可以 arm-linux-gcc -S -o example.s example.c -S参数将对源程序example.c进行预处理、编译，生成example.s文件 -o选项同上]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ socket网络编程学习（一）背景知识]]></title>
    <url>%2F2017%2Fsocket1.html</url>
    <content type="text"><![CDATA[引言在计算机通信领域，socket 被翻译为“套接字”，它是计算机之间进行通信的一种约定或一种方式。通过 socket 这种约定，一台计算机可以接收其他计算机的数据，也可以向其他计算机发送数据。 socket 的典型应用就是 Web 服务器和浏览器：浏览器获取用户输入的URL，向服务器发起请求，服务器分析接收到的URL，将对应的网页内容返回给浏览器，浏览器再经过解析和渲染，就将文字、图片、视频等元素呈现给用户。学习 socket，也就是学习计算机之间如何通信，并编写出实用的程序。 IP地址（IP Address）计算机分布在世界各地，要想和它们通信，必须要知道确切的位置。确定计算机位置的方式有多种，IP 地址是最常用的，例如，114.114.114.114 是国内第一个、全球第三个开放的 DNS 服务地址，127.0.0.1 是本机地址。其实，我们的计算机并不知道 IP 地址对应的地理位置，当要通信时，只是将 IP 地址封装到要发送的数据包中，交给路由器去处理。路由器有非常智能和高效的算法，很快就会找到目标计算机，并将数据包传递给它，完成一次单向通信。目前大部分软件使用 IPv4 地址，但 IPv6 也正在被人们接受，尤其是在教育网中，已经大量使用。 端口（Port）有了 IP 地址，虽然可以找到目标计算机，但仍然不能进行通信。一台计算机可以同时提供多种网络服务，例如Web服务、FTP服务（文件传输服务）、SMTP服务（邮箱服务）等，仅有 IP 地址，计算机虽然可以正确接收到数据包，但是却不知道要将数据包交给哪个网络程序来处理，所以通信失败。为了区分不同的网络程序，计算机会为每个网络程序分配一个独一无二的端口号（Port Number），例如，Web服务的端口号是 80，FTP 服务的端口号是 21，SMTP 服务的端口号是 25。端口（Port）是一个虚拟的、逻辑上的概念。可以将端口理解为一道门，数据通过这道门流入流出，每道门有不同的编号，就是端口号。如下图所示： 协议（Protocol）协议（Protocol）就是网络通信的约定，通信的双方必须都遵守才能正常收发数据。协议有很多种，例如 TCP、UDP、IP 等，通信的双方必须使用同一协议才能通信。协议是一种规范，由计算机组织制定，规定了很多细节，例如，如何建立连接，如何相互识别等。协议仅仅是一种规范，必须由计算机软件来实现。例如 IP 协议规定了如何找到目标计算机，那么各个开发商在开发自己的软件时就必须遵守该协议，不能另起炉灶。所谓协议族（Protocol Family），就是一组协议（多个协议）的统称。最常用的是 TCP/IP 协议族，它包含了 TCP、IP、UDP、Telnet、FTP、SMTP 等上百个互为关联的协议，由于 TCP、IP 是两种常用的底层协议，所以把它们统称为 TCP/IP 协议族。 数据传输方式计算机之间有很多数据传输方式，各有优缺点，常用的有两种： SOCK_STREAM 和 SOCK_DGRAM。1) SOCK_STREAM 表示面向连接的数据传输方式。数据可以准确无误地到达另一台计算机，如果损坏或丢失，可以重新发送，但效率相对较慢。常见的 http 协议就使用 SOCK_STREAM 传输数据，因为要确保数据的正确性，否则网页不能正常解析。 2) SOCK_DGRAM 表示无连接的数据传输方式。计算机只管传输数据，不作数据校验，如果数据在传输中损坏，或者没有到达另一台计算机，是没有办法补救的。也就是说，数据错了就错了，无法重传。因为 SOCK_DGRAM 所做的校验工作少，所以效率比 SOCK_STREAM 高。 QQ 视频聊天和语音聊天就使用 SOCK_DGRAM 传输数据，因为首先要保证通信的效率，尽量减小延迟，而数据的正确性是次要的，即使丢失很小的一部分数据，视频和音频也可以正常解析，最多出现噪点或杂音，不会对通信质量有实质的影响。 注意：SOCK_DGRAM 没有想象中的糟糕，不会频繁的丢失数据，数据错误只是小概率事件。 有可能多种协议使用同一种数据传输方式，所以在 socket 编程中，需要同时指明数据传输方式和协议。 综上所述：IP地址和端口能够在广袤的互联网中定位到要通信的程序，协议和数据传输方式规定了如何传输数据，有了这些，两台计算机就可以通信了。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>socket</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win7滑轮滚动excel就停止工作的解决方法]]></title>
    <url>%2F2017%2Fexcel-win7.html</url>
    <content type="text"><![CDATA[重装系统后又安装了office 2013，但这次的excel正常使用没什么问题，一拉进度条或滚动滑轮就停止工作，网上很多什么修改注册表和删除文件的方法都没有，安装Microsoft的补丁也没用，最后下载替换了一个dll文件就解决了，不管32还是64位都可以解决。 下载地址：http://www.dllzj.com/osf.dll/ 解压后把dll文件放到office15文件夹下替换即可。]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>win7</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串匹配——KMP算法的C++实现]]></title>
    <url>%2F2017%2FKMP-alg.html</url>
    <content type="text"><![CDATA[字符串匹配是计算机的基本任务之一。举例来说，有一个字符串”BBC ABCDAB ABCDABCDABDE”，我想知道，里面是否包含另一个字符串”ABCDABD”？ 暴力匹配算法假设现在我们面临这样一个问题：有一个文本串S，和一个模式串P，现在要查找P在S中的位置，怎么查找呢？如果用暴力匹配的思路，并假设现在文本串S匹配到 i 位置，模式串P匹配到 j 位置，则有：如果当前字符匹配成功（即S[i] == P[j]），则i++，j++，继续匹配下一个字符；如果失配（即S[i]! = P[j]），令i = i - (j - 1)，j = 0。相当于每次匹配失败时，i 回溯，j 被置为0。 理清楚了暴力匹配算法的流程及内在的逻辑，咱们可以写出暴力匹配的代码，如下： int ViolentMatch(char* s, char* p) { int sLen = strlen(s); int pLen = strlen(p); int i = 0; int j = 0; while (i &lt; sLen &amp;&amp; j &lt; pLen) { if (s[i] == p[j]) { //①如果当前字符匹配成功（即S[i] == P[j]），则i++，j++ i++; j++; } else { //②如果失配（即S[i]! = P[j]），令i = i - (j - 1)，j = 0 i = i - j + 1; j = 0; } } //匹配成功，返回模式串p在文本串s中的位置，否则返回-1 if (j == pLen) return i - j; else return -1; } KMP算法下面先直接给出KMP的算法流程（如果感到一点点不适，没关系，坚持下，稍后会有具体步骤及解释，越往后看越会柳暗花明☺）：假设现在文本串S匹配到 i 位置，模式串P匹配到 j 位置如果j = -1，或者当前字符匹配成功（即S[i] == P[j]），都令i++，j++，继续匹配下一个字符；如果j != -1，且当前字符匹配失败（即S[i] != P[j]），则令 i 不变，j = next[j]。此举意味着失配时，模式串P相对于文本串S向右移动了j - next [j] 位。换言之，当匹配失败时，模式串向右移动的位数为：失配字符所在位置 - 失配字符对应的next 值（next 数组的求解会在下文的3.3.3节中详细阐述），即移动的实际位数为：j - next[j]，且此值大于等于1。很快，你也会意识到next 数组各值的含义：代表当前字符之前的字符串中，有多大长度的相同前缀后缀。例如如果next [j] = k，代表j 之前的字符串中有最大长度为k 的相同前缀后缀。此也意味着在某个字符失配时，该字符对应的next 值会告诉你下一步匹配中，模式串应该跳到哪个位置（跳到next [j] 的位置）。如果next [j] 等于0或-1，则跳到模式串的开头字符，若next [j] = k 且 k &gt; 0，代表下次匹配跳到j 之前的某个字符，而不是跳到开头，且具体跳过了k 个字符。转换成代码表示，则是： int KmpSearch(char* s, char* p) { int i = 0; int j = 0; int sLen = strlen(s); int pLen = strlen(p); while (i &lt; sLen &amp;&amp; j &lt; pLen) { //①如果j = -1，或者当前字符匹配成功（即S[i] == P[j]），都令i++，j++ if (j == -1 || s[i] == p[j]) { i++; j++; } else { //②如果j != -1，且当前字符匹配失败（即S[i] != P[j]），则令 i 不变，j = next[j] //next[j]即为j所对应的next值 j = next[j]; } } if (j == pLen) return i - j; else return -1; } 步骤①寻找前缀后缀最长公共元素长度②求next数组` void GetNext(char* p,int next[]) { int pLen = strlen(p); next[0] = -1; int k = -1; int j = 0; while (j &lt; pLen - 1) { //p[k]表示前缀，p[j]表示后缀 if (k == -1 || p[j] == p[k]) { ++k; ++j; next[j] = k; } else { k = next[k]; } } }` ③根据next数组进行匹配综上，KMP的next 数组相当于告诉我们：当模式串中的某个字符跟文本串中的某个字符匹配失配时，模式串下一步应该跳到哪个位置。如模式串中在j 处的字符跟文本串在i 处的字符匹配失配时，下一步用next [j] 处的字符继续跟文本串i 处的字符匹配，相当于模式串向右移动 j - next[j] 位。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>KMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链表的常见操作]]></title>
    <url>%2F2017%2Fnodelist.html</url>
    <content type="text"><![CDATA[若只论链表与二叉树，链表又更容易将指针指的出神入化，二叉树稍逊，一个 left, 一个 right 的二次元世界，弄不出什么花来。 所以想要把握指针的灵魂，练就一身弹”指”神通的俊功夫，还得多练练链表。 下面，我就随意截取几道经典的链表问题，陪诸君练练手。（为简化问题，凸显实质，皆为单链表） struct ListNode { int val; ListNode *next; ListNode(int x) : val(x), next(nullptr) {} }; 链表的逆 1-&gt;2-&gt;3-&gt;4-&gt;5 ^ root想要逆序，最直接的想法，就是希望上图中的链表指向反过来。我们借用一个空指针 node 指向一个空节点: 1-&gt;2-&gt;3-&gt;4-&gt;5 | ListNode* reverse(ListNode *root) { ^ | ListNode *node = nullptr; root | } | null | ^ | node | 第一步，我们希望节点1从单链表中剥离，于是让其指向 node, 但我们不能因此而找不到链表索引，故需要一个额外的指针 next, 指向后续节点：几个简单的指针转移，便将节点1反向的去指向了 node 节点。如法炮制的话，节点2, 节点3, 节点4, 节点5 都调转枪头，我们的目的便达到了。 ListNode* reverse(ListNode *root) { ListNode *node = nullptr; while (root) { ListNode *next = root-&gt;next; root-&gt;next = node; node = root; root = next; } return node; } 链表除重1-&gt;1-&gt;2-&gt;2-&gt;3-&gt;4^headcur如果用一个指针 cur 来指向当前节点的话，出现重复的条件即为：cur-&gt;value == cur-&gt;next-&gt;value，如上图中，1 与 1 是重复的。我们只要想办法去掉重复的那个 1 即可。 1-&gt;1-&gt;2-&gt;2-&gt;3-&gt;4 | if (cur-&gt;val == cur-&gt;next-&gt;val) { ^ ^ ^ | ListNode *next = cur-&gt;next-&gt;next; cur next | delete cur-&gt;next; | ^ | cur-&gt;next = next; |_____| | } 这个思路简单，易懂，但这个问题却又是很多复杂问题的基础。还是需要注意的。 ListNode *removeDuplicates(ListNode *head) { if (head == nullptr) return head; for (ListNode *cur=head; cur-&gt;next; ) if (cur-&gt;val == cur-&gt;next-&gt;val) { ListNode *next = cur-&gt;next-&gt;next; delete cur-&gt;next; cur-&gt;next = next; } else { cur = cur-&gt;next; } return head; } 链表合并a(1-&gt;2-&gt;3) b(4-&gt;5-&gt;6) ==&gt; 1-&gt;4-&gt;2-&gt;5-&gt;3-&gt;6这个问题本身非常简单，但想通过这个基本问题，引申出链表问题一个非常常见的技巧。即设立 dummy 节点，可以称为是傀儡节点，其作用在于让合成的新链表有一个着手点。这个节点的值可以随意，我们最终返回的，实际上是 dummy.next;要注意，每一步指针的捣腾都是按照顺序的，用笔纸画一画会比较清楚。 ListNode *shuffleMerge(ListNode *a, ListNode *b) { ListNode dummy(0), *tail = &amp;dummy; while (a &amp;&amp; b) { tail-&gt;next = a; tail = a; a = a-&gt;next; tail-&gt;next = b; tail = b; b = b-&gt;next; } tail-&gt;next = a ? a : b; return dummy.next; } 移动节点a(1-&gt;2-&gt;3),b(1-&gt;2-&gt;3)==&gt; a(2-&gt;3),b(1-&gt;1-&gt;2-&gt;3)这个问题几乎不足为道，但这个操作，将有助于咱们更深入的对链表进行研究。封装这个操作，我们可以避免纠缠于非常基本的问题。(a 为 source(s), b 为 dest(d)) void moveNode(ListNode **destRef, ListNode **sourceRef) { ListNode *newNode = *sourceRef; *sourceRef = newNode-&gt;next; newNode-&gt;next = *destRef; *destRef = newNode; } 顺序合并1-&gt;3-&gt;5 , 2-&gt;4-&gt;6 ==&gt; 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;6 这也是非常基本的操作，结合上述的傀儡节点与 moveNode 两个技巧，应该可以很轻松的写出如下思路： ListNode *sortedMerge(ListNode *a, ListNode *b) { ListNode dummy(0), *tail = &amp;dummy; for ( ;a &amp;&amp; b; tail = tail-&gt;next) { if (a-&gt;val &lt;= b-&gt;val) moveNode(&amp;(tail-&gt;next), &amp;a); else moveNode(&amp;(tail-&gt;next), &amp;b); } tail-&gt;next = a ? a : b; return dummy.next; } 傀儡节点毕竟耗费了额外的空间，同样的思路，能否改进为不耗费额外空间呢？我们来思考另一个例子： ListNode *sortedMerge(ListNode *a, ListNode *b) { ListNode *ret = nullptr, **lastPtrRef = &amp;ret; for (; a &amp;&amp; b; lastPtrRef = &amp;((*lastPtrRef)-&gt;next)) { if (a-&gt;val &lt;= b-&gt;val) moveNode(lastPtrRef, &amp;a); else moveNode(lastPtrRef, &amp;b); } *lastPtrRef = a ? a : b; return ret; } 思路完全一致，但不消耗额外空间。即无需傀儡，直接上位。 另，这个问题也可以用递归解决，权当额外思考题了(可能更加直观)： ListNode *sortedMerge(ListNode *a, ListNode *b) { ListNode *ret = nullptr; if (a == nullptr) return b; else if (b == nullptr) return a; if (a-&gt;val &lt;= b-&gt;val) { ret = a; ret-&gt;next = sortedMerge(a-&gt;next, b); } else { ret = b; ret-&gt;next = sortedMerge(a, b-&gt;next); } return ret; } 顺序插入newnode(4),head(1-&gt;3-&gt;5-&gt;7-&gt;8)==&gt; 1-&gt;3-&gt;4-&gt;5-&gt;7-&gt;8 给一个有序链表 head, 一个新节点 newNode. 将新节点插入该链表中。 问题本身简单到不行，但我们仅仅是以此来复习一下上次所讲的三种策略。 直接插入法（教科书法） 傀儡节点 引用法（指针的指针） 首先最朴素的第一种方法，也是教科书上经常讲述的方案。在这个问题里，我们需要分别考虑两种情况：其一，newNode 的值比 head 还要小，那么它应该直接放到最前面（这个动作是连接而非插入）；其二，newNode 的值比 head 要大，那么毫无疑问，需要遍历整个链表，找到 newNode 应该插入的位置，进行插入。 if (*headRef == nullptr || (*headRef)-&gt;val &gt;= newNode-&gt;val) { newNode-&gt;next = *headRef; *headRef = newNode; } else { ListNode *curr = *headRef; while (curr-&gt;next != nullptr &amp;&amp; curr-&gt;next-&gt;val &lt; newNode-&gt;val) curr = curr-&gt;next; newNode-&gt;next = curr-&gt;next; curr-&gt;next = newNode; } 简单又好理解。 然后我们来看看第二种，很常用的傀儡法。为了避免像上面分两种情况分别处理那么麻烦，不如自立山头，统一处理。 void sortedInsert(ListNode **headRef, ListNode *newNode) { ListNode dummy(0), *tail = &amp;dummy; dummy.next = *headRef; while (tail-&gt;next != NULL &amp;&amp; tail-&gt;next-&gt;val &lt; newNode-&gt;val) tail = tail-&gt;next; newNode-&gt;next = tail-&gt;next; tail-&gt;next = newNode; *headRef = dummy.next; } 可以看到，代码完全照搬上面的第二种情况。更加紧凑。 好了，最后我们来看看最精简的第三种方案，使用引用。细心的童鞋会发现，上面我们定位的一直是 curr-&gt;next 节点。这个 next 很罗嗦，但普通的插入，必须要知道前后节点，所以也是不得已为之。如果我们采用引用，则只需要知道后面的节点即可。 ListNode **currRef = headRef; while (*currRef != nullptr &amp;&amp; (*currRef)-&gt;val &lt; newNode-&gt;val) currRef = &amp;((*currRef)-&gt;next); newNode-&gt;next = *currRef; *currRef = newNode; 可以看到，我们将 newNode-&gt;next 指向 curr 节点后，直接将 newNode 节点生生挪到链表里去了。这是因为 currRef 处于链表中第 2 个(从 0 开始)位置，当 *currRef = newNode 之后，相当于将这个位置指向的地址换成了 newNode. 而 newNode 已经和后面的节点相连，所以很顺利的顺延了后续链表。 寥寥五行，非常精简。上述三种思路都应该掌握，而核心应该掌握最后一种方案。 链表排序我们趁热打铁，上面讨论了 sortedInsert 方法的实现。那么我们倒过来，实现最基础的面试题，插入排序。 思路呢，非常简单，弄一个空链表：ListNode *newHead = nullptr;, 然后遍历整个链表，将每一个节点 sortedInsert 到 newHead 中。代码如下： void insertSort(ListNode **headRef) { ListNode *newHead = nullptr; for (ListNode *curr = *headRef, *next; curr; curr = next) { next = curr-&gt;next; sortedInsert(&amp;newHead, curr); } *headRef = newHead; } 转自：https://segmentfault.com/a/1190000002490878#articleHeader3]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析openstack虚拟化技术]]></title>
    <url>%2F2017%2Fvirtualization.html</url>
    <content type="text"><![CDATA[opensatck Openstack：OpenStack is a cloud operating system that controls large pools of compute, storage, and networking resources throughout a datacenter, all managed through a dashboard that gives administrators control while empowering their users to provision resources through a web interface. 以上是官网对 OpenStack 的定义，OpenStack 对数据中心的计算、存储和网络资源进行统一管理。 由此可见，OpenStack 针对的是 IT 基础设施，是 IaaS 这个层次的云操作系统。 虚拟化虚拟化是云计算的基础。虚拟机共享物理机的 CPU、内存、IO 硬件资源，但逻辑上虚拟机之间是相互隔离的。物理机我们一般称为宿主机（Host），宿主机上面的虚拟机称为客户机（Guest）。Host将自己的硬件资源虚拟化并提供给 Guest 使用主要是通过一个叫做 Hypervisor 的程序实现的。 Hypervisor是一种运行在物理服务器和操作系统之间的中间软件层,可允许多个操作系统和应用共享一套基础物理硬件，因此也可以看作是虚拟环境中的“元”操作系统，它可以协调访问服务器上的所有物理设备和虚拟机，也叫虚拟机监视器（Virtual Machine Monitor）。Hypervisor是所有虚拟化技术的核心。非中断地支持多工作负载迁移的能力是Hypervisor的基本功能。当服务器启动并执行Hypervisor时，它会给每一台虚拟机分配适量的内存、CPU、网络和磁盘，并加载所有虚拟机的客户操作系统。根据 Hypervisor 的实现方式和所处的位置，虚拟化又分为两种：1型虚拟化和2型虚拟化 1型虚拟化Hypervisor 直接安装在物理机上，多个虚拟机在 Hypervisor 上运行。Hypervisor 实现方式一般是一个特殊定制的 Linux 系统。Xen 和 VMWare 的 ESXi 都属于这个类型。 2型虚拟化物理机上首先安装常规的操作系统，比如 Redhat、Ubuntu 和 Windows。Hypervisor 作为 OS 上的一个程序模块运行，并对管理虚拟机进行管理。KVM、VirtualBox 和 VMWare Workstation 都属于这个类型。 理论上讲：1型虚拟化一般对硬件虚拟化功能进行了特别优化，性能上比2型要高；2型虚拟化因为基于普通的操作系统，会比较灵活，比如支持虚拟机嵌套。嵌套意味着可以在KVM虚拟机中再运行KVM。 KVM下面重点介绍KVM这种2型虚拟化技术。基本概念KVM 全称是Kernel-Based Virtual Machine。即 KVM 是基于 Linux 内核实现的。OpenStack 对 KVM 支持得也最好。KVM有一个内核模块叫 kvm.ko，只用于管理虚拟 CPU 和内存。而IO 的虚拟化，比如存储和网络设备由Linux 内核和Qemu来实现。即KVM 本身只关注虚拟机调度和内存管理这两个方面。IO 外设的任务交给 Linux 内核和Qemu。 Libvirt简单说就是 KVM 的管理工具。其实，Libvirt除了能管理 KVM 这种 Hypervisor，还能管理 Xen，VirtualBox 等。OpenStack底层也使用 Libvirt，所以很有必要学习一下。Libvirt 包含 3 个东西：后台 daemon 程序 libvirtd、API库和命令行工具 virsh libvirtd是服务程序，接收和处理 API 请求； API 库使得其他人可以开发基于 Libvirt 的高级工具，比如 virt-manager，这是个图形化的 KVM 管理工具，后面我们也会介绍； virsh 是我们经常要用的KVM 命令行工具，后面会有使用的示例。 作为 KVM 和OpenStack 的实施人员，virsh 和virt-manager 是一定要会用的。 CPU虚拟化KVM 的虚拟化是需要CPU 硬件支持的。虚机中的每一个虚拟 vCPU 则对应 qemu-kvm 进程中的一个线程。看下图即虚机的 vCPU 总数可以超过物理 CPU 数量，这个叫 CPU overcommit（超配）。 KVM 允许 overcommit，这个特性使得虚机能够充分利用宿主机的 CPU 资源。但在使用overcommit 的时候，需要对虚机的负载情况有所了解，需要测试。 内存虚拟化KVM 通过内存虚拟化共享物理系统内存，动态分配给虚拟机。看下图为了在一台机器上运行多个虚拟机，KVM 需要实现 VA（虚拟内存） -&gt; PA（物理内存） -&gt; MA（机器内存）直接的地址转换。虚机 OS 控制虚拟地址到客户内存物理地址的映射（VA -&gt; PA），但是虚机 OS 不能直接访问实际机器内存，因此 KVM 需要负责映射客户物理内存到实际机器内存 （PA -&gt; MA）。内存也是可以 overcommit 的，即所有虚机的内存之和可以超过宿主机的物理内存。但使用时也需要充分测试，否则性能会受影响。 网络虚拟化这是 OpenStack 官网上给出的计算节点（可以理解为 KVM 的宿主机）虚拟网络的逻辑图，上面的网络设备很多，层次也很复杂。网络虚拟化中最重要的两个东西：Linux Bridge 和 VLAN。]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>-openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析面向对象编程思想]]></title>
    <url>%2F2017%2Fobject.html</url>
    <content type="text"><![CDATA[面向对象的三个基本特征面向对象的三个基本特征是：封装、继承、多态。其中，封装可以隐藏实现细节，使得代码模块化；继承可以扩展已存在的代码模块（类）；它们的目的都是为了——代码重用。而多态则是为了实现另一个目的——接口重用！ 什么是封装？封装可以隐藏实现细节，使得代码模块化；封装是把过程和数据包围起来，对数据的访问只能通过已定义的界面。面向对象计算始于这个基本概念，即现实世界可以被描绘成一系列完全自治、封装的对象，这些对象通过一个受保护的接口访问其他对象。在面向对象编程上可理解为：把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。 什么是继承？继承是指这样一种能力：它可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。其继承的过程，就是从一般到特殊的过程。通过继承创建的新类称为“子类”或“派生类”。被继承的类称为“基类”、“父类”或“超类”。要实现继承，可以通过“继承”（Inheritance）和“组合”（Composition）来实现。在某些 OOP 语言中，一个子类可以继承多个基类。但是一般情况下，一个子类只能有一个基类，要实现多重继承，可以通过多级继承来实现。继承的实现方式？继承概念的实现方式有三类：实现继承、接口继承和可视继承。 实现继承是指使用基类的属性和方法而无需额外编码的能力； 接口继承是指仅使用属性和方法的名称、但是子类必须提供实现的能力； 可视继承是指子窗体（类）使用基窗体（类）的外观和实现代码的能力 什么是多态？多态性（polymorphisn）是允许你将父对象设置成为和一个或更多的他的子对象相等的技术，赋值之后，父对象就可以根据当前赋值给它的子对象的特性以不同的方式运作。简单的说，就是一句话：允许将子类类型的指针赋值给父类类型的指针。实现多态，有二种方式，覆盖，重载。覆盖：是指子类重新定义父类的虚函数的做法。重载：是指允许存在多个同名函数，而这些函数的参数表不同（或许参数个数不同，或许参数类型不同，或许两者都不同）。 分析：“重载”是指在同一个类中相同的返回类型和方法名，但是参数的个数和类型可以不同“覆盖\重写”是在不同的类中。 其实，重载的概念并不属于“面向对象编程”，重载的实现是：编译器根据函数不同的参数表，对同名函数的名称做修饰，然后这些同名函数就成了不同的函数（至少对于编译器来说是这样的）。如，有两个同名函数：function func(p:integer):integer;和function func(p:string):integer;。那么编译器做过修饰后的函数名称可能是这样的：int_func、str_func。对于这两个函数的调用，在编译器间就已经确定了，是静态的（记住：是静态）。也就是说，它们的地址在编译期就绑定了（早绑定），因此，重载和多态无关！真正和多态相关的是“覆盖”。当子类重新定义了父类的虚函数后，父类指针根据赋给它的不同的子类指针，动态（记住：是动态！）的调用属于子类的该函数，这样的函数调用在编译期间是无法确定的（调用的子类的虚函数的地址无法给出）。因此，这样的函数地址是在运行期绑定的（晚邦定）。结论就是：重载只是一种语言特性，与多态无关，与面向对象也无关！引用一句Bruce Eckel的话：“不要犯傻，如果它不是晚邦定，它就不是多态。” 附一张很形象的图]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>object</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析C++之STL迭代器]]></title>
    <url>%2F2017%2Fiterator.html</url>
    <content type="text"><![CDATA[泛型编程 STL是一种泛型编程。面向对象编程关注的是编程的数据方面，而泛型编程关注的是算法。它们之间的共同点是抽象和创建可重用代码，但理念决然不同。 泛型编程旨在编写独立于数据类型的代码，在C++中完成通用程序的工具是模板，模板使得算法独立于存储的数据类型，而迭代器使算法独立于使用的容器的类型。 什么是迭代器迭代器可以理解为一种泛型的指针，可以指向容器中的任一位置；而普通指针可以指向内存中的任一地址。STL的每一个容器类模版中，都定义了一组对应的迭代器类。使用迭代器，算法函数可以访问容器中指定位置的元素，而无需关心元素的具体类型。泛型编程中的函数不仅独立于容器中存储的数据类型，而且独立于容器本身的数据结构。模板提供了存储在容器中的数据类型的通用表示，因此，还需要遍历容器中的值的通用表示，迭代器正是这样的通用表示。比如我们可以创建一个find()函数，不仅可以查找数组，链表，也可以查找其他的容器类型。 迭代器的用法(1) 每种容器类型都定义了自己的迭代器类型，如vector:vector&lt;int&gt;::iterator iter;这条语句定义了一个名为iter的变量，它的数据类型是由vector定义的iterator类型。 (2) 使用迭代器读取vector中的每一个元素：vector&lt;int&gt; ivec(10,1); for(vector&lt;int&gt;::iterator iter=ivec.begin();iter!=ivec.end();++iter) { *iter=2; //使用 * 访问迭代器所指向的元素 } const_iterator: 只能读取容器中的元素，而不能修改。 for(vector&lt;int&gt;::const_iterator citer=ivec.begin();citer!=ivec.end();citer++) { cout&lt;&lt;*citer; //*citer=3; error } vector::const_iterator 和 const vector::iterator的区别const vector::iterator newiter=ivec.begin();*newiter=11; //可以修改指向容器的元素//newiter++; //迭代器本身不能被修改 (3) iterator的算术操作：iterator除了进行++,–操作，可以将iter+n,iter-n赋给一个新的iteraor对象。还可以使用一个iterator减去另外一个iterator.const vector::iterator newiter=ivec.begin();vector::iterator newiter2=ivec.end();cout&lt;&lt;”\n”&lt;&lt;newiter2-newiter;一個很典型使用vector的STL程式: #include &lt;vector&gt; #include &lt;iostream&gt; using namespace std; int main(void) { vector&lt;int&gt; v; v.push_back(1); v.push_back(2); v.push_back(3); vector&lt;int&gt;::iterator it; for (it = v.begin(); it != v.end(); ++it) { cout &lt;&lt; *it &lt;&lt; &apos; &apos;; } cout &lt;&lt; endl; 迭代器可以很好的兼容C++的内置类型，特别是常见的C++指针被视为C++数组的迭代器。当然，在标准的C++库中所有的容器都定义了一个迭代器类型，即嵌套类型的迭代器，代表各自的指针类型。 迭代器的类型迭代器可以分为不同的种类，这是因为他们使用不同的算法、不同的要求附加在其身上。例如，find()算法需要一个可以递增的迭代器，而reverse()算法需要一个可以递减的迭代器等。总之，在STL和C++标准库中有5种迭代器。（1）、输入迭代器(Input Iterator):只能向前单步迭代元素，不允许修改由该迭代器所引用的元素；（2）、输出迭代器(Output Iterator):只能向前单步迭代元素，对由该迭代器所引用的元素只有写权限；（3）、向前迭代器(Forward Iterator):该迭代器可以在一个区间中进行读写操作，它拥有输入迭代器的所有特性和输出迭代器的部分特性，以及向前单步迭代元素的能力；（4）、双向迭代器(Bidirectional Iterator):在向前迭代器的基础上增加了向后单步迭代元素的能力；（5）、随机访问迭代器(Random Access Iterator):不仅综合以后4种迭代器的所有功能，还可以像指针那样进行算术计算；vector、deque提供的是随机访问迭代器，list提供的是双向迭代器，set和map提供的是向前迭代器。 相应的操作集为：除了输出迭代器，其他类别的迭代器形成了一个层次结构：需要低级类别迭代器的地方，可使用任意一种更高级的迭代器。例如，对于需要输入迭代器的算法，可传递前向、双向或随机访问迭代器调用该算法。而反之则不行。注意：向算法传递无效的迭代器类别所引起的错误，无法保证会在编译时被捕获到。map, set, list类型提供双向迭代器，而string, vector和deque容器上定义的迭代器都是随机访问迭代器，用作访问内置数组元素的指针也是随机访问迭代器。istream_iterator是输入迭代器，ostream_iterator是输出迭代器。另外，虽然map和set类型提供双向迭代器，但关联容器只能使用这部分算法的一个子集。因为关联容器的键是const对象。因此，关联容器不能使用任何写序列元素的算法。只能使用与关联容器绑在一起的迭代器来提供用于读操作的实参。因此，在处理算法时，最好将关联容器上的迭代器视为支持自减运算的输入迭代器，而不是完整的双向迭代器。最后需要注意的是，stack、queue、priority_queue 都不支持任一种迭代器，它们都是容器适配器类型，stack是用vector/deque/list对象创建了一个先进后出容器，queue是用deque或list对象创建了一个先进先出容器，priority_queue是用vector/deque创建了一个排序队列 常用的容器成员]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>-C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中struct和class的区别]]></title>
    <url>%2F2017%2Fstructclass.html</url>
    <content type="text"><![CDATA[C++中的struct对C中的struct进行了扩充，它已经不再只是一个包含不同数据类型的数据结构了，它已经获取了太多的功能。 struct和class都可以继承，都可以包含成员函数，都可以实现多态，都可以有构造函数和西沟函数。但主要有两点区别 1、最本质的一个区别就是默认的访问控制：默认的继承访问权限struct是public的，class是private的。所以我们在平时写类继承的时候，通常会这样写：class B : public A就是为了指明是public继承，而不是用默认的private继承。 当然，到底默认是public继承还是private继承，取决于子类而不是基类。如： struct A{}； class B : A{}; //private继承 struct C : B{}； //public继承 struct作为数据结构的实现体，它默认的数据访问控制是public的，而class作为对象的实现体，它默认的成员变量访问控制是private的 到底是用struct还是class，完全看个人的喜好，你可以将程序里所有的class全部替换成struct，它依旧可以很正常的运行。但我给出的最好建议，还是：当你觉得你要做的更像是一种数据结构的话，那么用struct，如果你要做的更像是一种对象的话，那么用class。 当然，我在这里还要强调一点的就是，对于访问控制，应该在程序里明确的指出，而不是依靠默认，这是一个良好的习惯，也让你的代码更具可读性。 2、“class”这个关键字还用于定义模板参数，但关键字“struct”不用于定义模板参数。这一点在Stanley B.Lippman写的Inside the C++ Object Model有过说明。 3、其他区别还是上面所说的，C++中的struct是对C中的struct的扩充，既然是扩充，那么它就要兼容过去C中struct应有的所有特性。例如你可以这样写： struct A//定义一个struct { char c1; int n2; double db3; }; A a={&apos;p&apos;, 7, 3.1415926}; //定义时直接赋值 也就是说struct可以在定义的时候用{}赋初值。但class不行，而且当struct中包含构造函数（或虚函数），struct也不能用{}赋初值了。 而加入一个普通的成员函数呢？你会发现{}依旧可用。其实你可以将普通的函数理解成对数据结构的一种算法，这并不打破它数据结构的特性。那么，看到这里，我们发现即使是struct想用{}来赋初值，它也必须满足很多的约束条件，这些条件实际上就是让struct更体现出一种数据机构而不是类的特性。那为什么我们在上面仅仅将struct改成class，{}就不能用了呢？其实问题恰巧是我们之前所讲的——访问控制！你看看，我们忘记了什么？对，将struct改成class的时候，访问控制由public变为private了，那当然就不能用{}来赋初值了。加上一个public，你会发现，class也是能用{}的，和struct毫无区别！！！做个总结，从上面的区别，我们可以看出，struct更适合看成是一个数据结构的实现体，class更适合看成是一个对象的实现体。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>-C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析B树，B+/-树，AVL树，红黑树]]></title>
    <url>%2F2017%2FBST.html</url>
    <content type="text"><![CDATA[B树——二叉搜索树##定义：1.所有非叶子结点至多拥有两个儿子（Left和Right）；2.所有结点存储一个关键字；3.非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树； B树的搜索，从根结点开始，如果查询的关键字与结点的关键字相等，那么就命中；否则，如果查询关键字比结点关键字小，就进入左儿子；如果比结点关键字大，就进入右儿子；如果左儿子或右儿子的指针为空，则报告找不到相应的关键字。 如果B树的所有非叶子结点的左右子树的结点数目均保持差不多（平衡），那么B树的搜索性能逼近二分查找；但它比连续内存空间的二分查找的优点是，改变B树结构（插入与删除结点）不需要移动大段的内存数据，甚至通常是常数开销。在实际使用中，通常是在B树的基础上添加平衡算法，编程平衡二叉树。平衡二叉树又叫AVL树，是由作者姓名命名的，平衡二叉树还有一个改进的版本，叫做红黑树。 BST效率总结 : 查找最好时间复杂度O(logN)，最坏时间复杂度O(N)。插入删除操作算法简单，时间复杂度与查找差不多 B-树——一种非二叉搜索树##定义 定义任意非叶子结点最多具有M个儿子，M&gt;2； 根节点的儿子树[2,M]； 除根节点之外的非叶子结点的儿子数为[M/2,M]； 每个节点存放至少M/2-1(向上取整)和至多M-1个关键字； 非叶子结点的关键字个数等于指向儿子的指针个数减去1 非叶子结点的关键字：K[1],K[2]…K[M-1],:且K[i]小于K[i+1]； 非叶子结点的指针：P[1],P[2],,,,,P[M],其中P[M]指向关键字大于K[M-1]的子树，其他P[i]指向关键字属于(K[i-1],k[i])的子树； 所有叶子节点位于同一层。 如M=3 B-树有着如下的特性： 关键字集合分布在整颗树中； 任何一个关键字出现且只出现在一个结点中； 搜索有可能在非叶子结点结束； 其搜索性能等价于在关键字全集内做一次二分查找； 自动层次控制； 同时，由于限制了除根结点以外的非叶子结点，至少含有M/2个儿子，确保了结点的至少利用率，其最低搜索性能为： 公式中，M为设定的非叶子节点最多子树的个数，N为关键字总数；所以B-树的性能总是等价于2分查找（与M值无关），也就没有B树平衡的问题；由于M/2的限制，在插入节点的时候，如果节点已经满了，需要将节点分裂成两个各占M/2的节点；删除节点的时候，需要将两个不足M/2的节点合并 B-Tree效率总结： 由于考虑磁盘储存结构，B树的查找、删除、插入的代价都远远要小于任何二叉结构树(读写磁盘次数的降低)。 B+树——多路搜索树定义：其定义基本与B-树同，除了： 非叶子结点的子树指针与关键字个数相同； 非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）； 为所有叶子结点增加一个链指针； 所有关键字都在叶子结点出现； AVL——平衡二叉搜索树定义： 平衡二叉树或为空树,或为如下性质的二叉排序树: 左右子树深度之差的绝对值不超过1; 左右子树仍然为平衡二叉树. 平衡因子BF=左子树深度－右子树深度.平衡二叉树每个结点的平衡因子只能是1，0，-1。若其绝对值超过1，则该二叉排序树就是不平衡的。 AVL树是最先发明的自平衡二叉查找树。在AVL树中任何节点的两个子树的高度最大差别为一，所以它也被称为高度平衡树。查找、插入和删除在平均和最坏情况下都是O（log n）。 红黑树——改进的AVL定义： 每个结点要么是红的，要么是黑的。 根结点是黑的。 每个叶结点，即空结点（NIL）是黑的。 如果一个结点是红的，那么它的俩个儿子都是黑的。 对每个结点，从该结点到其子孙结点的所有路径上包含相同数目的黑结点。 AVL是严格平衡树，因此在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多；红黑是弱平衡的，用非严格的平衡来换取增删节点时候旋转次数的降低,所以简单说，搜索的次数远远大于插入和删除，那么选择AVL树，如果搜索，插入删除次数几乎差不多，应该选择RB树。红黑树上每个结点内含五个域，color，key，left，right，p。如果相应的指针域没有，则设为NIL。 红黑树与AVL比较结构对比： AVL的结构高度平衡，RBT的结构基本平衡。平衡度AVL &gt; RBT.查找对比： AVL 查找时间复杂度最好，最坏情况都是O(logN)。 RBT 查找时间复杂度最好为O(logN)，最坏情况下比AVL略差。插入删除对比： AVL的插入和删除结点很容易造成树结构的不平衡，而RBT的平衡度要求较低。因此在大量数据插入的情况下，RBT需要通过旋转变色操作来重新达到平衡的频度要小于AVL。 如果需要平衡处理时，RBT比AVL多一种变色操作，而且变色的时间复杂度在O(logN)数量级上。但是由于操作简单，所以在实践中这种变色仍然是非常快速的。 当插入一个结点都引起了树的不平衡，AVL和RBT都最多需要2次旋转操作。但删除一个结点引起不平衡后，AVL最多需要logN 次旋转操作，而RBT最多只需要3次。因此两者插入一个结点的代价差不多，但删除一个结点的代价RBT要低一些。 AVL和RBT的插入删除代价主要还是消耗在查找待操作的结点上。因此时间复杂度基本上都是与O(logN) 成正比的。 总体评价：大量数据实践证明，RBT的总体统计性能要好于平衡二叉树。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>-数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++之inline内联函数浅析]]></title>
    <url>%2F2017%2Finline.html</url>
    <content type="text"><![CDATA[C语言中使用宏定义容易出错，而且不能调试，无法操作类的私有数据成员。所以，在C++中尽量用内联函数来代替宏代码。inline函数的另一个优点是，函数被内联后，编译器可以根据上下文自己决定优化措施。 什么是内联函数内联函数是C++的增强特性之一，用来降低程序的运行时间。当内联函数收到编译器的指示时，即可发生内联：编译器将使用函数的定义体来替代函数调用语句，这种替代行为发生在编译阶段而非程序运行阶段。 值得注意的是，内联函数仅仅是对编译器的内联建议，编译器是否觉得采取你的建议取决于函数是否符合内联的有利条件。如果函数体非常大，那么编译器将忽略函数的内联声明，而将内联函数作为普通函数处理。 如何使函数内联定义函数时，在函数的最前面以关键字“inline”声明函数，即可使函数称为内联声明函数。 例如： Class A { Public: inline int add(int a, int b) { return (a + b); }; } Class A { Public: int add(int a, int b); }; inline int A::add(int a, int b) { return (a + b); } 为什么要使用内联函数有时候我们会写一些功能专一的函数，这些函数的函数体不大，包含了很少的执行语句。例如在计算1~1000以内的素数时，我们经常会使用开方操作使运算范围缩小，这时我们会写一个函数： int root(int n) { return (int)sqrt((float)n); } 然后我们的求范围内素数的函数可以这样写。 int prime(int n) { int i; for (i = 2; i &lt;= root(n); i++) { if (n%i == 0) return 0; return 1; } } 当然，把root函数放在循环中不是个不明智的选择，但想象一下，在某个程序上下文内必须频繁地调用某个类似root的函数，其调用函数的花销会有多大：当遇到普通函数的调用指令时，程序会保存当前函数的执行现场，将函数中的局部变量以及函数地址压入堆栈，然后再将即将调用的新函数加载到内存中，这要经历复制参数值、跳转到所调用函数的内存位置、执行函数代码、存储函数返回值等过程，当函数执行完后，再获取之前正在调用的函数的地址，回去继续执行那个函数，运行时间开销简直太多了。 C++内联函数提供了替代函数调用的方案，通过inline声明，编译器首先在函数调用处使用函数体本身语句替换了函数调用语句，然后编译替换后的代码。因此，通过内联函数，编译器不需要跳转到内存其他地址去执行函数调用，也不需要保留函数调用时的现场数据。 inline函数的优缺点分析优点： 它通过避免函数调用所带来的开销来提高你程序的运行速度。 当函数调用发生时，它节省了变量弹栈、压栈的开销。 它避免了一个函数执行完返回原现场的开销。 通过将函数声明为内联，你可以把函数定义放在头文件内。 缺点： 因为代码的扩展，内联函数增大了可执行程序的体积。 C++内联函数的展开是中编译阶段，这就意味着如果你的内联函数发生了改动，那么就需要重新编译代码。 当你把内联函数放在头文件中时，它将会使你的头文件信息变多，不过头文件的使用者不用在意这些。 有时候内联函数并不受到青睐，比如在嵌入式系统中，嵌入式系统的存储约束可能不允许体积很大的可执行程序。 什么时候该使用内联函数当程序设计需要时，每个函数都可以声明为inline。下面列举一些有用的建议： 当对程序执行性能有要求时，那么就使用内联函数吧。 当你想宏定义一个函数时，那就果断使用内联函数吧。 在类内部定义的函数会默认声明为inline函数，这有利于 类实现细节的隐藏。 关键点 内联声明只是一种对编译器的建议，编译器是否采用内联措施由编译器自己来决定。甚至在汇编阶段或链接阶段，一些没有inline声明的函数编译器也会将它内联展开。 编译器的内联看起来就像是代码的复制与粘贴，这与预处理宏是很不同的：宏是强制的内联展开，可能将会污染所有的命名空间与代码，将为程序的调试带来困难。 所有中类中定义的函数都默认声明为inline函数，所有我们不用显示地去声明inline。 虚函数不允许内联。 虽然说模板函数放中头文件中，但它们不一定是内联的。（不是说定义在头文件中的函数都是内联函数）。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>-C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop分布式计算框架MapReduce浅析]]></title>
    <url>%2F2017%2Fhadoop-mapreduce.html</url>
    <content type="text"><![CDATA[分布式计算框架有很多，只是适合做的种类不一样。1、MapReduce适合做离线计算2、storm适合做流式计算，更适合实时计算3、spark是内存式计算框架，更适合做快速得到结果的计算 MapReduce设计理念何为分布式计算移动计算，而不是移动数据。把计算程序都进行部署到不同的机器上，然后在不同的机器上进行计算，然后进行汇总，做到不移动计算的数据，也能得到计算结果。 MR（MapReduce）计算框架图解 解决大数据的问题：1、数据存储（HDFS）2、数据计算(MapReduce) 首先对数据进行处理split为每一个数据片段，每一数据片段都会有一个map线程去执行，如果有多个片段会并发的同时执行。 所以：如上图：第一个步骤是：如何把数据切片，按照什么规则去切分。第二个步骤是：就是map部分第三个步骤是shuffle部分第四个部分是 reduce部分第五个部分就是 输出部分（计算生成的数据，也是保存在HDFS上） 整个MR过程就是：就是把HDFS数据进行计算处理，然后输出结果 实例MR计算在shuffling阶段会有相应的合并和排序有可能reduce为一个或者多个，这个是由程序去决定。 hadoop计算框架ShufflerShuffer的功能：在mapper 和reducer中间的一个步骤。可以把mapper的输出按照某种key值重新切分和组合成n份，把key值符合某种范围的输出送到特定的reducer那里，可以简化reducer过程。 map过程map是一个Java程序，或者其他计算机程序，map得到的结果在内存中， 内存有一定的阈值，当到达一定的阈值后，就需要写入到磁盘中， 这个过程叫做溢写。 在写入之前要做几件事情，partion和sort。把当前map的数据进行输出和排序，然后再溢写到磁盘。放在磁盘中的数据是已经排好序的数据。 什么是partition？ partition分区的数据是为以后产生作用的。把map的输出数据分成一个一个区，partition可以由程序员自定义编写代码。如果不写按照默认的分区模式进行分区，默认的分区模式是什么呢？ Hash模运算1、获取hash值，每个对象的hash值得到一个整数，把这个整数模reduce的个数，得到一个结果。假如：hash模2，只有两种结果0或者1，然后map的结果分成了两个部分，0区或者1区。 分区有什么作用？？？ 这是mapredure如何结局负载均衡和数据倾斜？ 分区是为了把map的输出进行负载均衡，解决数据倾斜的问题。这样后期通过reduce进行计算的数据就不会有数据倾斜问题，一个计算的过多，一个计算的过少。这就是分区的作用。 map为什么不会数据倾斜？？？map的数据是切片，每一片的大小相等，所以map的输入数据不会出现数据倾斜的问题。 sortsort也有默认的的sort。默认的sort是按照ascii进行排序的。（即按照字典进行排序的）为什么要sort？？？定义排序规则 上图中merge on disk什么意思？？？每次都会溢写到磁盘中，溢写会按照hash值进行合并，相同hash值放到一起。每一次溢写就会生成一个文件，溢写的次数越多，生成的文件越多，这些文件需要进行合并为一个大的文件，如何合并，就是按照hash值进行合并，这是默认的规则。 合并的目的？？？减少map的输出，因为后期reduce会移动map的输出到reduce服务器上，减少map的输出，就会减少网络io的操作，所以很有必要的。 以上是map的处理 reduce过程map的处理结果落到磁盘以后，然后会进行merge，为什么merge，如果merge？？？ reduce 的输入数据就是map的输出数据，reduce的数据来源是map输出数据的拷贝。拷贝哪些数据，是根据partition的结果，只拷贝分给对应的reduce的数据。之前分区是按照reduce去模后的值进行分区的，分区以后的数据在copy到reduce所在的机器上，同事进行merge，便于下一步reduce进行处理。 分区就是在把数据拷贝到reduce的时候起作用的 为什么reduce task开始也有merge操作？？？因为reduce会从很多的map输出结果中拷贝数据，这样会有很多个小文件，reduce为了计算，就需要对这些小文件进行merge。这就是为什么reduce开始时要进行merge操作。这个合并不是人为控制的，这个会根据key相同的进行合并，是hadoop自有的功能。合并完成以后相同key的数据会进行merge。 两个reduce是可以并发的。 抓重点：这个过程比较虽然比较复杂，但是有很多部分是hadoop框架已经做的工作，只有一部分需要我们编程实现！！！ 哪些部分需要我们编程实现？？？ 1、partition（如何分区）2、sort 比较（如何比较）3、比较会进行多次4、combiner 注意：在map执行之后，立刻进行partition，map的输出结果会分到哪个reduce，这个叫做分区，分区以后放在内存中，在溢写的时候，要执行sort和combiner，sort其实就是比较，默认按照ascii大小进行比较。 combiner可能会没有，所以上副图没有画combiner，这个意思是初次合并。 combiner可以减少map的输出数据。MapReduce的Split大小 1、max.split(100M)2、min.split(10M)3、block（64M）如何进行切分，切分大小算法4、max(min.split,min(max.split,block))代入如上值为： 64M]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>MapReduce</tag>
        <tag>分布式计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++内存管理详解（二）]]></title>
    <url>%2F2017%2FCppmemory2.html</url>
    <content type="text"><![CDATA[本文将继上一篇继续讲解内存管理的问题，这篇主要讨论一下malloc/free和new/delete的用法和区别，及做个总结。 指针参数是如何传递内存的如果函数的参数是一个指针，不要指望用该指针去申请动态内存。如下示例中，Test函数的语句GetMemory(str, 200)并没有使str获得期望的内存，str依旧是NULL，为什么？ void GetMemory(char *p, int num){ p = (char *)malloc(sizeof(char) * num); } void Test(void){ char *str = NULL; GetMemory(str, 100); // str 仍然为 NULL strcpy(str, &quot;hello&quot;); // 运行错误 } 毛病出在函数GetMemory中。编译器总是要为函数的每个参数制作临时副本，指针参数p的副本_p，编译器使_p=p。如果函数体内的程序修改了_p的内容，就导致参数p的内容作相应的修改。这就是指针可以用作输出参数的原因。在本例中，_p申请了新的内存，只是把 _p所指的内存地址改变了，但是p丝毫未变。所以函数GetMemory并不能输出任何东西。事实上，每执行一次GetMemory就会泄露一块内存，因为没有用free释放内存。 如果非得要用指针参数去申请内存，那么应该改用“指向指针的指针”，见示例： void GetMemory2(char **p, int num){ *p = (char *)malloc(sizeof(char) * num); } void Test2(void){ char *str = NULL; GetMemory2(&amp;str, 100); // 注意参数是 &amp;str，而不是str strcpy(str, &quot;hello&quot;); cout&lt;&lt; str &lt;&lt; endl; free(str); } 由于“指向指针的指针”这个概念不容易理解，我们可以用函数返回值来传递动态内存。这种方法更加简单，见示例： char *GetMemory3(int num){ char *p = (char *)malloc(sizeof(char) * num); return p;//返回值 } void Test3(void){ char *str = NULL; str = GetMemory3(100); strcpy(str, &quot;hello&quot;); cout&lt;&lt; str &lt;&lt; endl; free(str); } 用函数返回值来传递动态内存这种方法虽然好用，但是常常有人把return语句用错了。这里强调不要用return语句返回指向“栈内存”的指针，因为该内存在函数结束时自动消亡，见示例： char *GetString(void){ char p[] = &quot;hello world&quot;; return p; // 编译器将提出警告 } void Test4(void){ char *str = NULL; str = GetString(); // str 的内容是垃圾 cout&lt;&lt; str &lt;&lt; endl; } 用调试器逐步跟踪Test4，发现执行str = GetString语句后str不再是NULL指针，但是str的内容不是“hello world”而是垃圾。如果把上述示例改写成如下示例，会怎么样？ char *GetString2(void){ char *p = &quot;hello world&quot;; return p; } void Test5(void){ char *str = NULL; str = GetString2(); cout&lt;&lt; str &lt;&lt; endl; } 函数Test5运行虽然不会出错，但是函数GetString2的设计概念却是错误的。因为GetString2内的“hello world”是常量字符串，位于静态存储区，它在程序生命期内恒定不变。无论什么时候调用GetString2，它返回的始终是同一个“只读”的内存块。 杜绝“野指针”“野指针”不是NULL指针，是指向“垃圾”内存的指针。人们一般不会错用NULL指针，因为用if语句很容易判断。但是“野指针”是很危险的，if语句对它不起作用。 “野指针”的成因主要有三种：(1). 指针变量没有被初始化。任何指针变量刚被创建时不会自动成为NULL指针，它的缺省值是随机的，它会乱指一气。所以，指针变量在创建的同时应当被初始化，要么将指针设置为NULL，要么让它指向合法的内存。例如： char *p = NULL; char *str = (char *) malloc(100); (2). 指针p被free或者delete之后，没有置为NULL，让人误以为p是个合法的指针。(3). 指针操作超越了变量的作用域范围。这种情况让人防不胜防，示例程序如下： class A{ public: void Func(void){ cout &lt;&lt; “Func of class A” &lt;&lt; endl; } }; void Test(void){ A *p; { A a; p = &amp;a; // 注意 a 的生命期 } p-&gt;Func(); // p是“野指针” } 函数Test在执行语句p-&gt;Func()时，对象a已经消失，而p是指向a的，所以p就成了“野指针”。但奇怪的是我运行这个程序时居然没有出错，这可能与编译器有关。 有了malloc/free为什么还要new/deletemalloc与free是C++/C语言的标准库函数，new/delete是C++的运算符。它们都可用于申请动态内存和释放内存。对于非内部数据类型的对象而言，光用maloc/free无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于malloc/free是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于malloc/free。因此C++语言需要一个能完成动态内存分配和初始化工作的运算符new，以及一个能完成清理与释放内存工作的运算符delete。注意new/delete不是库函数。我们先看一看malloc/free和new/delete如何实现对象的动态内存管理，见示例： class Obj{ public : Obj(void){ cout &lt;&lt; “Initialization” &lt;&lt; endl; } ~Obj(void){ cout &lt;&lt; “Destroy” &lt;&lt; endl; } void Initialize(void){ cout &lt;&lt; “Initialization” &lt;&lt; endl; } void Destroy(void){ cout &lt;&lt; “Destroy” &lt;&lt; endl; } }; void UseMallocFree(void){ Obj *a = (obj *)malloc(sizeof(obj)); // 申请动态内存 a-&gt;Initialize(); // 初始化 //… a-&gt;Destroy(); // 清除工作 free(a); // 释放内存 } void UseNewDelete(void){ Obj *a = new Obj; // 申请动态内存并且初始化 //… delete a; // 清除并且释放内存 } 类Obj的函数Initialize模拟了构造函数的功能，函数Destroy模拟了析构函数的功能。函数UseMallocFree中，由于malloc/free不能执行构造函数与析构函数，必须调用成员函数Initialize和Destroy来完成初始化与清除工作。函数UseNewDelete则简单得多。所以我们不要企图用malloc/free来完成动态对象的内存管理，应该用new/delete。由于内部数据类型的“对象”没有构造与析构的过程，对它们而言malloc/free和new/delete是等价的。既然new/delete的功能完全覆盖了malloc/free，为什么C++不把malloc/free淘汰出局呢？这是因为C++程序经常要调用C函数，而C程序只能用malloc/free管理动态内存。如果用free释放“new创建的动态对象”，那么该对象因无法执行析构函数而可能导致程序出错。如果用delete释放“malloc申请的动态内存”，结果也会导致程序出错，但是该程序的可读性很差。所以new/delete必须配对使用，malloc/free也一样。 内存耗尽怎么办如果在申请动态内存时找不到足够大的内存块，malloc和new将返回NULL指针，宣告内存申请失败。通常有三种方式处理“内存耗尽”问题。(1). 判断指针是否为NULL，如果是则马上用return语句终止本函数。例如： void Func(void){ A *a = new A; if(a == NULL) return; … } (2). 判断指针是否为NULL，如果是则马上用exit(1)终止整个程序的运行。例如： void Func(void){ A *a = new A; if(a == NULL){ cout &lt;&lt; “Memory Exhausted” &lt;&lt; endl; exit(1); } … } (3). 为new和malloc设置异常处理函数。例如Visual C++可以用_set_new_hander函数为new设置用户自己定义的异常处理函数，也可以让malloc享用与new相同的异常处理函数。详细内容请参考C++使用手册。上述 (1)、(2) 方式使用最普遍。如果一个函数内有多处需要申请动态内存，那么方式 (1) 就显得力不从心（释放内存很麻烦），应该用方式 (2) 来处理。很多人不忍心用exit(1)，问：“不编写出错处理程序，让操作系统自己解决行不行？”不行。如果发生“内存耗尽”这样的事情，一般说来应用程序已经无药可救。如果不用exit(1)把坏程序杀死，它可能会害死操作系统。道理如同：如果不把歹徒击毙，歹徒在老死之前会犯下更多的罪。有一个很重要的现象要告诉大家。对于32位以上的应用程序而言，无论怎样使用malloc与new，几乎不可能导致“内存耗尽”。对于32位以上的应用程序，“内存耗尽”错误处理程序毫无用处。这下可把Unix和Windows程序员们乐坏了：反正错误处理程序不起作用，我就不写了，省了很多麻烦。必须强调：不加错误处理将导致程序的质量很差，千万不可因小失大。 void main(void){ float *p = NULL; while(TRUE){ p = new float[1000000]; cout &lt;&lt; “eat memory” &lt;&lt; endl; if(p==NULL) exit(1); } } malloc/free的使用要点函数malloc的原型如下： void * malloc(size_t size); 用malloc申请一块长度为length的整数类型的内存，程序如下： int *p = (int *) malloc(sizeof(int) * length); 我们应当把注意力集中在两个要素上：“类型转换”和“sizeof”。 malloc返回值的类型是void，所以在调用malloc时要显式地进行类型转换，将void 转换成所需要的指针类型。 malloc函数本身并不识别要申请的内存是什么类型，它只关心内存的总字节数。我们通常记不住int, float等数据类型的变量的确切字节数。例如int变量在16位系统下是2个字节，在32位下是4个字节；而float变量在16位系统下是4个字节，在32位下也是4个字节。最好用以下程序作一次测试： cout &lt;&lt; sizeof(char) &lt;&lt; endl; cout &lt;&lt; sizeof(int) &lt;&lt; endl; cout &lt;&lt; sizeof(unsigned int) &lt;&lt; endl; cout &lt;&lt; sizeof(long) &lt;&lt; endl; cout &lt;&lt; sizeof(unsigned long) &lt;&lt; endl; cout &lt;&lt; sizeof(float) &lt;&lt; endl; cout &lt;&lt; sizeof(double) &lt;&lt; endl; cout &lt;&lt; sizeof(void *) &lt;&lt; endl; 在malloc的“()”中使用sizeof运算符是良好的风格，但要当心有时我们会昏了头，写出 p = malloc(sizeof(p))这样的程序来。函数free的原型如下： void free( void * memblock ); 为什么free函数不象malloc函数那样复杂呢？这是因为指针p的类型以及它所指的内存的容量事先都是知道的，语句free(p)能正确地释放内存。如果p是NULL指针，那么free对p无论操作多少次都不会出问题。如果p不是NULL指针，那么free对p连续操作两次就会导致程序运行错误。 new/delete的使用要点运算符new使用起来要比函数malloc简单得多，例如： int *p1 = (int *)malloc(sizeof(int) * length); int *p2 = new int[length]; 这是因为new内置了sizeof、类型转换和类型安全检查功能。对于非内部数据类型的对象而言，new在创建动态对象的同时完成了初始化工作。如果对象有多个构造函数，那么new的语句也可以有多种形式。例如： class Obj{ public : Obj(void); // 无参数的构造函数 Obj(int x); // 带一个参数的构造函数 … } void Test(void){ Obj *a = new Obj; Obj *b = new Obj(1); // 初值为1 … delete a; delete b; } 如果用new创建对象数组，那么只能使用对象的无参数构造函数。例如： Obj *objects = new Obj[100]; // 创建100个动态对象 不能写成： Obj *objects = new Obj[100](1);// 创建100个动态对象的同时赋初值1 在用delete释放对象数组时，留意不要丢了符号‘[]’。例如： delete []objects; // 正确的用法 delete objects; // 错误的用法 后者有可能引起程序崩溃和内存泄漏。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>内存</tag>
        <tag>指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++内存管理详解（一）]]></title>
    <url>%2F2017%2FCppmemory.html</url>
    <content type="text"><![CDATA[内存管理是C++最令人切齿痛恨的问题，也是C++最有争议的问题，C++高手从中获得了更好的性能，更大的自由，C++菜鸟的收获则是一遍一遍的检查代码和对C++的痛恨，但内存管理在C++中无处不在，内存泄漏几乎在每个C++程序中都会发生，因此要想成为C++高手，内存管理一关是必须要过的，除非放弃C++，转到Java或者.NET，他们的内存管理基本是自动的，当然你也放弃了自由和对内存的支配权，还放弃了C++超绝的性能。 伟大的Bill Gates 曾经失言： 640K ought to be enough for everybody — Bill Gates 1981程序员们经常编写内存管理程序，往往提心吊胆。如果不想触雷，唯一的解决办法就是发现所有潜伏的地雷并且排除它们，躲是躲不了的。 内存分配方式简介在C++中，内存分成5个区，他们分别是堆、栈、自由存储区、全局/静态存储区和常量存储区。栈：在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。堆：就是那些由,malloc分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制，一般一个malloc对应一个 free。如果程序员没有释放掉，那么在程序结束后，操作系统会自动回收。自由存储区：就是那些由new等分配的内存块，他和堆是十分相似的，不过它是用delete来结束自己的生命的。自由存储区是否能够是堆（问题等价于 new 是否能在堆上动态分配内存），这取决于 operator new 的实现细节。事实上，自由存储区不仅可以是堆，还可以是静态存储区。 (new与malloc的区别之一：new操作符从自由存储区（free store）上为对象动态分配内存空间，而malloc函数从堆上动态分配内存。自由存储区是C++基于new操作符的一个抽象概念，凡是通过new操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C语言使用malloc从堆上分配内存，使用free释放已分配的对应内存。) 全局/静态存储区：全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。常量存储区：这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改。 明确区分堆与栈主要的区别由以下几点： (1). 管理方式不同 (2). 空间大小不同 (3). 能否产生碎片不同 (4). 生长方向不同 (5). 分配方式不同 (6). 分配效率不同管理方式：对于栈来讲，是由编译器自动管理，无需我们手工控制；对于堆来说，释放工作由程序员控制，容易产生memory leak。空间大小：一般来讲在32位系统下，堆内存可以达到4G的空间，从这个角度来看堆内存几乎是没有什么限制的。但是对于栈来讲，一般都是有一定的空间大小的，例如，在VC6下面，默认的栈空间大小是1M（好像是，记不清楚了）。当然，我们可以修改：打开工程，依次操作菜单如下：Project-&gt;Setting-&gt;Link，在Category 中选中Output，然后在Reserve中设定堆栈的最大值和commit。注意：reserve最小值为4Byte；commit是保留在虚拟内存的页文件里面，它设置的较大会使栈开辟较大的值，可能增加内存的开销和启动时间。碎片问题：对于堆来讲，频繁的new/delete势必会造成内存空间的不连续，从而造成大量的碎片，使程序效率降低。对于栈来讲，则不会存在这个问题，因为栈是先进后出的队列，他们是如此的一一对应，以至于永远都不可能有一个内存块从栈中间弹出，在他弹出之前，在他上面的后进的栈内容已经被弹出，详细的可以参考数据结构，这里我们就不再一一讨论了。生长方向：对于堆来讲，生长方向是向上的，也就是向着内存地址增加的方向；对于栈来讲，它的生长方向是向下的，是向着内存地址减小的方向增长。分配方式：堆都是动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由编译器进行释放，无需我们手工实现。分配效率：栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是C/C++函数库提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法（具体的算法可以参考数据结构/操作系统）在堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于内存碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。从这里我们可以看到，堆和栈相比，由于大量new/delete的使用，容易造成大量的内存碎片；由于没有专门的系统支持，效率很低；由于可能引发用户态和核心态的切换，内存的申请，代价变得更加昂贵。所以栈在程序中是应用最广泛的，就算是函数的调用也利用栈去完成，函数调用过程中的参数，返回地址，EBP和局部变量都采用栈的方式存放。所以，我们推荐大家尽量用栈，而不是用堆。虽然栈有如此众多的好处，但是由于和堆相比不是那么灵活，有时候分配大量的内存空间，还是用堆好一些。无论是堆还是栈，都要防止越界现象的发生（除非你是故意使其越界），因为越界的结果要么是程序崩溃，要么是摧毁程序的堆、栈结构，产生以想不到的结果,就算是在你的程序运行过程中，没有发生上面的问题，你还是要小心，说不定什么时候就崩掉，那时候debug可是相当困难的：） 控制C++的内存分配在嵌入式系统中使用C++的一个常见问题是内存分配，即对new 和 delete 操作符的失控。具有讽刺意味的是，问题的根源却是C++对内存的管理非常的容易而且安全。具体地说，当一个对象被消除时，它的析构函数能够安全的释放所分配的内存。这当然是个好事情，但是这种使用的简单性使得程序员们过度使用new 和 delete，而不注意在嵌入式C++环境中的因果关系。并且，在嵌入式系统中，由于内存的限制，频繁的动态分配不定大小的内存会引起很大的问题以及堆破碎的风险。作为忠告，保守的使用内存分配是嵌入式环境中的第一原则。但当你必须要使用new和delete时，你不得不控制C++中的内存分配。你需要用一个全局的new 和delete来代替系统的内存分配符，并且一个类一个类的重载new和delete。一个防止堆破碎的通用方法是从不同固定大小的内存持中分配不同类型的对象。对每个类重载new 和delete就提供了这样的控制。 重载全局的new和delete操作符可以很容易地重载new 和 delete 操作符，如下所示: void * operator new(size_t size){ void *p = malloc(size); return (p); } void operator delete(void *p){ free(p); } 这段代码可以代替默认的操作符来满足内存分配的请求。出于解释C++的目的，我们也可以直接调用malloc() 和free()。也可以对单个类的new 和 delete操作符重载。这是你能灵活的控制对象的内存分配。 class TestClass { public: void * operator new(size_t size); void operator delete(void *p); // .. other members here ... }; void *TestClass::operator new(size_t size){ void *p = malloc(size); // Replace this with alternative allocator return (p); } void TestClass::operator delete(void *p){ free(p); // Replace this with alternative de-allocator } 所有TestClass 对象的内存分配都采用这段代码。更进一步，任何从TestClass 继承的类也都采用这一方式，除非它自己也重载了new 和 delete 操作符。通过重载new 和 delete 操作符的方法，你可以自由地采用不同的分配策略，从不同的内存池中分配不同的类对象。 为单个的类重载new[]和delete[]必须小心对象数组的分配。你可能希望调用到被你重载过的new 和 delete 操作符，但并不如此。内存的请求被定向到全局的new[]和delete[] 操作符，而这些内存来自于系统堆。C++将对象数组的内存分配作为一个单独的操作，而不同于单个对象的内存分配。为了改变这种方式，你同样需要重载new[] 和 delete[]操作符。 class TestClass { public: void * operator new[ ](size_t size); void operator delete[ ](void *p); // .. other members here .. }; void *TestClass::operator new[ ](size_t size){ void *p = malloc(size); return (p); } void TestClass::operator delete[ ](void *p){ free(p); } int main(void){ TestClass *p = new TestClass[10]; // ... etc ... delete[ ] p; } 但是注意：对于多数C++的实现，new[]操作符中的个数参数是数组的大小加上额外的存储对象数目的一些字节。在你的内存分配机制重要考虑的这一点。你应该尽量避免分配对象数组，从而使你的内存分配策略简单。 常见的内存错误及其对策发生内存错误是件非常麻烦的事情。编译器不能自动发现这些错误，通常是在程序运行时才能捕捉到。而这些错误大多没有明显的症状，时隐时现，增加了改错的难度。有时用户怒气冲冲地把你找来，程序却没有发生任何问题，你一走，错误又发作了。 常见的内存错误及其对策如下： 内存分配未成功，却使用了它。编程新手常犯这种错误，因为他们没有意识到内存分配会不成功。常用解决办法是，在使用内存之前检查指针是否为NULL。如果指针p是函数的参数，那么在函数的入口处用assert(p!=NULL)进行检查。如果是用malloc或new来申请内存，应该用if(p==NULL) 或if(p!=NULL)进行防错处理。 内存分配虽然成功，但是尚未初始化就引用它。犯这种错误主要有两个起因：一是没有初始化的观念；二是误以为内存的缺省初值全为零，导致引用初值错误（例如数组）。内存的缺省初值究竟是什么并没有统一的标准，尽管有些时候为零值，我们宁可信其无不可信其有。所以无论用何种方式创建数组，都别忘了赋初值，即便是赋零值也不可省略，不要嫌麻烦。 内存分配成功并且已经初始化，但操作越过了内存的边界。例如在使用数组时经常发生下标“多1”或者“少1”的操作。特别是在for循环语句中，循环次数很容易搞错，导致数组操作越界。 忘记了释放内存或删除（delete）指向动态内存的指针失败，因而无法将该块内存返还给自由存储区，造成内存泄露。含有这种错误的函数每被调用一次就丢失一块内存。刚开始时系统的内存充足，你看不到错误。终有一次程序突然死掉，系统出现提示：内存耗尽。动态内存的申请与释放必须配对使用。 对同一块内存空间使用两次delete表达式。当两个指针指向同一个动态创建的对象，删除时就会发生错误。如果在其中一个指针做delete操作将释放内存，但接着delete第二个指针则会造成自由存储区的破坏。 释放了内存却继续使用它。 有三种情况： (1). 程序中的对象调用关系过于复杂，实在难以搞清楚某个对象究竟是否已经释放了内存，此时应该重新设计数据结构，从根本上解决对象管理的混乱局面。 (2). 函数的return语句写错了，注意不要返回指向“栈内存”的“指针”或者“引用”，因为该内存在函数体结束时被自动销毁。 (3). 使用free或delete释放了内存后，没有将指针设置为NULL。导致产生“野指针”。 那么如何避免产生野指针呢？这里列出了5条规则，平常写程序时多注意一下，养成良好的习惯。规则1：用malloc或new申请内存之后，应该立即检查指针值是否为NULL。防止使用指针值为NULL的内存。规则2：不要忘记为数组和动态内存赋初值。防止将未被初始化的内存作为右值使用。规则3：避免数组或指针的下标越界，特别要当心发生“多1”或者“少1”操作。规则4：动态内存的申请与释放必须配对，防止内存泄漏。规则5：用free或delete释放了内存之后，立即将指针设置为NULL，防止产生“野指针”。 指针与数组的对比C++/C程序中，指针和数组在不少地方可以相互替换着用，让人产生一种错觉，以为两者是等价的。数组要么在静态存储区被创建（如全局数组），要么在栈上被创建。数组名对应着（而不是指向）一块内存，其地址与容量在生命期内保持不变，只有数组的内容可以改变。指针可以随时指向任意类型的内存块，它的特征是“可变”，所以我们常用指针来操作动态内存。指针远比数组灵活，但也更危险。下面以字符串为例比较指针与数组的特性。 修改内容下面示例中，字符数组a的容量是6个字符，其内容为 hello。a的内容可以改变，如a[0]= ‘X’。指针p指向常量字符串“world”（位于静态存储区，内容为world），常量字符串的内容是不可以被修改的。从语法上看，编译器并不觉得语句p[0]= ‘X’有什么不妥，但是该语句企图修改常量字符串的内容而导致运行错误。 char a[] = “hello”; a[0] = ‘X’; cout &lt;&lt; a &lt;&lt; endl; char *p = “world”; // 注意p指向常量字符串 p[0] = ‘X’; // 编译器不能发现该错误 cout &lt;&lt; p &lt;&lt; endl; 内容复制与比较不能对数组名进行直接复制与比较。若想把数组a的内容复制给数组b，不能用语句 b = a ，否则将产生编译错误。应该用标准库函数strcpy进行复制。同理，比较b和a的内容是否相同，不能用if(b==a) 来判断，应该用标准库函数strcmp进行比较。语句 p = a 并不能把a的内容复制指针p，而是把a的地址赋给了p。要想复制a的内容，可以先用库函数malloc为p申请一块容量为strlen(a)+1个字符的内存，再用strcpy进行字符串复制。同理，语句if(p==a) 比较的不是内容而是地址，应该用库函数strcmp来比较。 // 数组… char a[] = &quot;hello&quot;; char b[10]; strcpy(b, a); // 不能用 b = a; if(strcmp(b, a) == 0) // 不能用 if (b == a) … // 指针… int len = strlen(a); char *p = (char *)malloc(sizeof(char)*(len+1)); strcpy(p,a); // 不要用 p = a; if(strcmp(p, a) == 0) // 不要用 if (p == a) … 计算内存容量用运算符sizeof可以计算出数组的容量（字节数）。如下示例中，sizeof(a)的值是12（注意别忘了’’）。指针p指向a，但是sizeof(p)的值却是4。这是因为sizeof(p)得到的是一个指针变量的字节数，相当于sizeof(char)，而不是p所指的内存容量。*C++/C语言没有办法知道指针所指的内存容量，除非在申请内存时记住它。 char a[] = &quot;hello world&quot;; char *p = a; cout&lt;&lt; sizeof(a) &lt;&lt; endl; // 12字节 cout&lt;&lt; sizeof(p) &lt;&lt; endl; // 4字节 注意当数组作为函数的参数进行传递时，该数组自动退化为同类型的指针。如下示例中，不论数组a的容量是多少，sizeof(a)始终等于sizeof(char *)。 void Func(char a[100]){ cout&lt;&lt; sizeof(a) &lt;&lt; endl; // 4字节而不是100字节 }]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>内存</tag>
        <tag>指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十大机器学习算法介绍（二）]]></title>
    <url>%2F2017%2FML2.html</url>
    <content type="text"><![CDATA[K均值算法K – 均值算法是一种非监督式学习算法，它能解决聚类问题。使用 K – 均值算法来将一个数据归入一定数量的集群（假设有 k 个集群）的过程是简单的。一个集群内的数据点是均匀齐次的，并且异于别的集群。 还记得从墨水渍里找出形状的活动吗？K – 均值算法在某方面类似于这个活动。观察形状，并延伸想象来找出到底有多少种集群或者总体。 K – 均值算法怎样形成集群： K – 均值算法给每个集群选择k个点。这些点称作为质心。每一个数据点与距离最近的质心形成一个集群，也就是 k 个集群。根据现有的类别成员，找出每个类别的质心。现在我们有了新质心。当我们有新质心后，重复步骤 2 和步骤 3。找到距离每个数据点最近的质心，并与新的k集群联系起来。重复这个过程，直到数据都收敛了，也就是当质心不再改变。 如何决定 K 值： K – 均值算法涉及到集群，每个集群有自己的质心。一个集群内的质心和各数据点之间距离的平方和形成了这个集群的平方值之和。同时，当所有集群的平方值之和加起来的时候，就组成了集群方案的平方值之和。 我们知道，当集群的数量增加时，K值会持续下降。但是，如果你将结果用图表来表示，你会看到距离的平方总和快速减少。到某个值 k 之后，减少的速度就大大下降了。在此，我们可以找到集群数量的最优值。 Python代码 #Import Library from sklearn.cluster import KMeans #Assumed you have, X (attributes) for training data set and x_test(attributes) of test_dataset # Create KNeighbors classifier object model k_means = KMeans(n_clusters=3, random_state=0) # Train the model using the training sets and check score model.fit(X) #Predict Output predicted= model.predict(x_test) 降维算法在过去的 4 到 5 年里，在每一个可能的阶段，信息捕捉都呈指数增长。公司、政府机构、研究组织在应对着新资源以外，还捕捉详尽的信息。 举个例子：电子商务公司更详细地捕捉关于顾客的资料：个人信息、网络浏览记录、他们的喜恶、购买记录、反馈以及别的许多信息，比你身边的杂货店售货员更加关注你。 作为一个数据科学家，我们提供的数据包含许多特点。这听起来给建立一个经得起考研的模型提供了很好材料，但有一个挑战：如何从 1000 或者 2000 里分辨出最重要的变量呢？在这种情况下，降维算法和别的一些算法（比如决策树、随机森林、PCA、因子分析）帮助我们根据相关矩阵，缺失的值的比例和别的要素来找出这些重要变量。 Python代码 #Import Library from sklearn import decomposition #Assumed you have training and test data set as train and test # Create PCA obeject pca= decomposition.PCA(n_components=k) #default value of k =min(n_sample, n_features) # For Factor analysis #fa= decomposition.FactorAnalysis() # Reduced the dimension of training dataset using PCA train_reduced = pca.fit_transform(train) #Reduced the dimension of test dataset test_reduced = pca.transform(test) #For more detail on this, please refer this link. Gradient Boosting 和 AdaBoost 算法当我们要处理很多数据来做一个有高预测能力的预测时，我们会用到 GBM 和 AdaBoost 这两种 boosting 算法。boosting 算法是一种集成学习算法。它结合了建立在多个基础估计值基础上的预测结果，来增进单个估计值的可靠程度。这些 boosting 算法通常在数据科学比赛如 Kaggl、AV Hackathon、CrowdAnalytix 中很有效。 Python代码： #Import Library from sklearn.ensemble import GradientBoostingClassifier #Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset # Create Gradient Boosting Classifier object model= GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0) # Train the model using the training sets and check score model.fit(X, y) #Predict Output predicted= model.predict(x_test)]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十大机器学习算法介绍（一）]]></title>
    <url>%2F2017%2FML.html</url>
    <content type="text"><![CDATA[机器学习算法分为三类：有监督学习、无监督学习、增强学习。有监督学习需要标识数据（用于训练，即有正例又有负例），无监督学习不需要标识数据，增强学习介于两者之间（有部分标识数据）。下面将向大家具体介绍机器学习中10大算法（主要介绍有监督、无监督两类）。 监督学习1 决策树决策树是一种树形结构，为人们提供决策依据，决策树可以用来回答yes和no问题，它通过树形结构将各种情况组合都表示出来，每个分支表示一次选择（选择yes还是no），直到所有选择都进行完毕，最终给出正确答案。 定义：决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。使用决策树进行决策的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果。构造决策树的关键步骤是分裂属性。所谓分裂属性就是在某个节点处按照某一特征属性的不同划分构造不同的分支，其目标是让各个分裂子集尽可能地“纯”。尽可能“纯”就是尽量让一个分裂子集中待分类项属于同一类别。分裂属性分为三种不同的情况： 1、属性是离散值且不要求生成二叉决策树。此时用属性的每一个划分作为一个分支。 2、属性是离散值且要求生成二叉决策树。此时使用属性划分的一个子集进行测试，按照“属于此子集”和“不属于此子集”分成两个分支。 3、属性是连续值。此时确定一个值作为分裂点split_point，按照 &gt;split_point和&lt;=split_point生成两个分支。 ID3信息增益（information gain）表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。定义：特征A对训练数据集D的信息增益g（D,A），定义集合D的经验熵H（D）与特征A给定条件下D的经验条件熵H（D|A）之差。一般地，熵与条件熵之差成为互信息（mutual information），决策树学习中的信息增益等价于训练数据集中类与特征的互信息。ID3算法的核心是在决策树各个子结点上应用信息增益准则选择特征，递归的构建决策树。具体方法是:从根结点开始，对结点计算所有可能的特征的信息增益，选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子结点；再对子结点递归调用以上方法，构建决策树。直到所有特征的信息增益均很小或没有特征可以选择为止。 C4.5ID3算法存在一个问题，就是偏向于多值属性，例如，如果存在唯一标识属性ID，则ID3会选择它作为分裂属性，这样虽然使得划分充分纯净，但这种划分对分类几乎毫无用处。ID3的后继算法C4.5使用增益率（gain ratio）的信息增益扩充，试图克服这个偏倚。C4.5算法首先定义了“分裂信息”，其定义可以表示成： 其中各符号意义和ID3算法相同，然后增益率定义为： C4.5选择具有最大增益率的属性作为分裂属性，其具体应用于ID3类似。python代码： #Import Library #Import other necessary libraries like pandas, numpy... from sklearn import tree #Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset # Create tree object model = tree.DecisionTreeClassifier(criterion=&apos;gini&apos;) # for classification, here you can change the algorithm as gini or entropy (information gain) by default it is gini # model = tree.DecisionTreeRegressor() for regression # Train the model using the training sets and check score model.fit(X, y) model.score(X, y) #Predict Output predicted= model.predict(x_test) 2 朴素贝叶斯分类（NBC）在预示变量间相互独立的前提下，根据贝叶斯定理可以得到朴素贝叶斯这个分类方法。用更简单的话来说，一个朴素贝叶斯分类器假设一个分类的特性与该分类的其它特性不相关。举个例子，如果一个水果又圆又红，并且直径大约是 3 英寸，那么这个水果可能会是苹果。即便这些特性互相依赖，或者依赖于别的特性的存在，朴素贝叶斯分类器还是会假设这些特性分别独立地暗示这个水果是个苹果。 朴素贝叶斯模型易于建造，且对于大型数据集非常有用。虽然简单，但是朴素贝叶斯的表现却超越了非常复杂的分类方法。 贝叶斯定理提供了一种从P(c)、P(x)和P(x|c) 计算后验概率 P(c|x) 的方法。请看以下等式：在这里， P(c|x) 是已知预示变量（属性）的前提下，类（目标）的后验概率P(c) 是类的先验概率P(x|c) 是可能性，即已知类的前提下，预示变量的概率P(x) 是预示变量的先验概率 例子：让我们用一个例子来理解这个概念。在下面，我有一个天气的训练集和对应的目标变量“Play”。现在，我们需要根据天气情况，将会“玩”和“不玩”的参与者进行分类。让我们执行以下步骤。 步骤1：把数据集转换成频率表。 步骤2：利用类似“当Overcast可能性为0.29时，玩耍的可能性为0.64”这样的概率，创造 Likelihood 表格。步骤3：现在，使用朴素贝叶斯等式来计算每一类的后验概率。后验概率最大的类就是预测的结果。 问题：如果天气晴朗，参与者就能玩耍。这个陈述正确吗？ 我们可以使用讨论过的方法解决这个问题。于是 P（会玩 | 晴朗）= P（晴朗 | 会玩）* P（会玩）/ P （晴朗） 我们有 P （晴朗 |会玩）= 3/9 = 0.33，P（晴朗） = 5/14 = 0.36, P（会玩）= 9/14 = 0.64 现在，P(会玩 | 晴朗）= 0.33 * 0.64 / 0.36 = 0.60，有更大的概率。 朴素贝叶斯使用了一个相似的方法，通过不同属性来预测不同类别的概率。这个算法通常被用于文本分类，以及涉及到多个类的问题。 一些应用例子: 判断垃圾邮件对新闻的类别进行分类，比如科技、政治、运动判断文本表达的感情是积极的还是消极的人脸识别 Python代码： #Import Library from sklearn.naive_bayes import GaussianNB #Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset # Create SVM classification object model = GaussianNB() # there is other distribution for multinomial classes like Bernoulli Naive Bayes, Refer link # Train the model using the training sets and check score model.fit(X, y) #Predict Output predicted= model.predict(x_test) 3 线性回归线性回归通常用于根据连续变量估计实际数值（房价、呼叫次数、总销售额等）。我们通过拟合最佳直线来建立自变量和因变量的关系。这条最佳直线叫做回归线，并且用 Y= a *X + b 这条线性等式来表示。 理解线性回归的最好办法是回顾一下童年。假设在不问对方体重的情况下，让一个五年级的孩子按体重从轻到重的顺序对班上的同学排序，你觉得这个孩子会怎么做？他（她）很可能会目测人们的身高和体型，综合这些可见的参数来排列他们。这是现实生活中使用线性回归的例子。实际上，这个孩子发现了身高和体型与体重有一定的关系，这个关系看起来很像上面的等式。 在这个等式中： Y：因变量a：斜率x：自变量b ：截距系数 a 和 b 可以通过最小二乘法获得。 参见下例。我们找出最佳拟合直线 y=0.2811x+13.9。已知人的身高，我们可以通过这条等式求出体重。线性回归的两种主要类型是一元线性回归和多元线性回归。一元线性回归的特点是只有一个自变量。多元线性回归的特点正如其名，存在多个自变量。找最佳拟合直线的时候，你可以拟合到多项或者曲线回归。这些就被叫做多项或曲线回归。 Python代码： #Import Library #Import other necessary libraries like pandas, numpy... from sklearn import linear_model #Load Train and Test datasets #Identify feature and response variable(s) and values must be numeric and numpy arrays x_train=input_variables_values_training_datasets y_train=target_variables_values_training_datasets x_test=input_variables_values_test_datasets # Create linear regression object linear = linear_model.LinearRegression() # Train the model using the training sets and check score linear.fit(x_train, y_train) linear.score(x_train, y_train) #Equation coefficient and Intercept print(&apos;Coefficient: n&apos;, linear.coef_) print(&apos;Intercept: n&apos;, linear.intercept_) #Predict Output predicted= linear.predict(x_test) 4 逻辑回归别被它的名字迷惑了！这是一个分类算法而不是一个回归算法。该算法可根据已知的一系列因变量估计离散数值（比方说二进制数值 0 或 1 ，是或否，真或假）。简单来说，它通过将数据拟合进一个逻辑函数来预估一个事件出现的概率。因此，它也被叫做逻辑回归。因为它预估的是概率，所以它的输出值大小在 0 和 1 之间（正如所预计的一样）。 让我们再次通过一个简单的例子来理解这个算法。 假设你的朋友让你解开一个谜题。这只会有两个结果：你解开了或是你没有解开。想象你要解答很多道题来找出你所擅长的主题。这个研究的结果就会像是这样：假设题目是一道十年级的三角函数题，你有 70%的可能会解开这道题。然而，若题目是个五年级的历史题，你只有30%的可能性回答正确。这就是逻辑回归能提供给你的信息。 从数学上看，在结果中，几率的对数使用的是预测变量的线性组合模型。 odds= p/ (1-p) = probability of event occurrence / probability of not event occurrence ln(odds) = ln(p/(1-p)) logit(p) = ln(p/(1-p)) = b0+b1X1+b2X2+b3X3....+bkXk 在上面的式子里，p 是我们感兴趣的特征出现的概率。它选用使观察样本值的可能性最大化的值作为参数，而不是通过计算误差平方和的最小值（就如一般的回归分析用到的一样）。现在你也许要问了，为什么我们要求出对数呢？简而言之，这种方法是复制一个阶梯函数的最佳方法之一。 Python代码： #Import Library from sklearn.linear_model import LogisticRegression #Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset # Create logistic regression object model = LogisticRegression() # Train the model using the training sets and check score model.fit(X, y) model.score(X, y) #Equation coefficient and Intercept print(&apos;Coefficient: n&apos;, model.coef_) print(&apos;Intercept: n&apos;, model.intercept_) #Predict Output predicted= model.predict(x_test) 你可以尝试更多的方法来改进这个模型： 加入交互项精简模型特性使用正则化方法使用非线性模型 5 K-最近邻算法（KNN）该算法可用于分类问题和回归问题。然而，在业界内，K – 最近邻算法更常用于分类问题。K – 最近邻算法是一个简单的算法。它储存所有的案例，通过周围k个案例中的大多数情况划分新的案例。根据一个距离函数，新案例会被分配到它的 K 个近邻中最普遍的类别中去。 这些距离函数可以是欧式距离、曼哈顿距离、明式距离或者是汉明距离。前三个距离函数用于连续函数，第四个函数（汉明函数）则被用于分类变量。如果 K=1，新案例就直接被分到离其最近的案例所属的类别中。有时候，使用 KNN 建模时，选择 K 的取值是一个挑战 我们可以很容易地在现实生活中应用到 KNN。如果想要了解一个完全陌生的人，你也许想要去找他的好朋友们或者他的圈子来获得他的信息。 在选择使用 KNN 之前，你需要考虑的事情： KNN 的计算成本很高。变量应该先标准化（normalized），不然会被更高范围的变量偏倚。在使用KNN之前，要在野值去除和噪音去除等前期处理多花功夫。 Python代码 #Import Library from sklearn.neighbors import KNeighborsClassifier #Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset # Create KNeighbors classifier object model KNeighborsClassifier(n_neighbors=6) # default value for n_neighbors is 5 # Train the model using the training sets and check score model.fit(X, y) #Predict Output predicted= model.predict(x_test) 6 随机森林随机森林是表示决策树总体的一个专有名词。在随机森林算法中，我们有一系列的决策树（因此又名“森林”）。为了根据一个新对象的属性将其分类，每一个决策树有一个分类，称之为这个决策树“投票”给该分类。这个森林选择获得森林里（在所有树中）获得票数最多的分类。 每棵树是像这样种植养成的： 如果训练集的案例数是 N，则从 N 个案例中用重置抽样法随机抽取样本。这个样本将作为“养育”树的训练集。假如有 M 个输入变量，则定义一个数字 m&lt;&lt;M。m 表示，从 M 中随机选中 m 个变量，这 m 个变量中最好的切分会被用来切分该节点。在种植森林的过程中，m 的值保持不变。尽可能大地种植每一棵树，全程不剪枝。 Python代码： #Import Library from sklearn.ensemble import RandomForestClassifier #Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset # Create Random Forest object model= RandomForestClassifier() # Train the model using the training sets and check score model.fit(X, y) #Predict Output predicted= model.predict(x_test) 7 SVM支持向量机是一种基于分类边界的方法。 基本原理： 如果训练数据分布在二维平面上的点,它们按照其分类 聚集在不同的区域。 基于分类边界的分类算法的目标是，通过训练，找到这些分类之间的边界。 对于多维数据（N维），可以将他们视为N维空间中的点，而分类边界就是N维空间中的面，称为超面。 线性分类器使用超平面类型的边界，非线性分类器使用超曲面。 支持向量机的原理是将低维空间的点映射到高维空间,使它们成为线性可分,再使用线性划分的原理来判断分类边界。在高维空间中是一种线性划分,而在原有的数据空间中,是一种非线性划分。 这是一种分类方法。在这个算法中，我们将每个数据在N维空间中用点标出（N是你所有的特征总数），每个特征的值是一个坐标的值。 举个例子，如果我们只有身高和头发长度两个特征，我们会在二维空间中标出这两个变量，每个点有两个坐标（这些坐标叫做支持向量）。现在，我们会找到将两组不同数据分开的一条直线。两个分组中距离最近的两个点到这条线的距离同时最优化。 上面示例中的黑线将数据分类优化成两个小组，两组中距离最近的点（图中A、B点）到达黑线的距离满足最优条件。这条直线就是我们的分割线。接下来，测试数据落到直线的哪一边，我们就将它分到哪一类去。 Python代码： #Import Library from sklearn import svm #Assumed you have, X (predic tor) and Y (target) for training data set and x_test(predictor) of test_dataset # Create SVM classification object model = svm.svc() # there is various option associated with it, this is simple for classification. You can refer link, for mo# re detail. # Train the model using the training sets and check score model.fit(X, y) model.score(X, y) #Predict Output predicted= model.predict(x_test)]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>-machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图解Vim常见命令]]></title>
    <url>%2F2017%2Fvim.html</url>
    <content type="text"><![CDATA[vi编辑器中有三种状态模式1.命令模式2.输入模式3.末行模式]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFmpeg在Ubuntu下的安装及常见视频处理方法]]></title>
    <url>%2F2017%2FFFmpeg.html</url>
    <content type="text"><![CDATA[安装可通过PPA进行安装 sudo add-apt-repository ppa:kirillshkrogalev/ffmpeg-next sudo apt-get update sudo apt-get install ffmpeg 相关概念比特率比特率，是一个决定音视频总体质量的参数。他决定每个时间单位处理的bit数，英文为 bit rate，描述每秒钟输出多少 KB 的参数，单位是 Kbps，也就是 kbit/s，8Kbit/s = 1KB/s。压缩同一个视频，视频编码率越大，文件体积越大，画质越好。 MP3一般使用的比特率为 8~320kbps。 设置比特率：比特率决定处理1s的编码流需要多少bits，设置用-b选项。区分音视频用-b:a和-b:v例如：设置整体1.5Mbit每秒 ffmpeg -i file.avi -b 1.5M file.mp4 ffmpeg -i input.avi -b:v 1500K output.mp4 帧数每秒钟播放的图片数，单位 fps（英文：Frames Per Second），帧率就是每秒编码进视频文件的帧数目。人类的眼睛需要每秒至少15帧才能将图像连贯在一起。帧率的单位是HZ，LCD显示一般有60Hz的平率。高的帧率可以得到更流畅、更逼真的动画。一般来说30fps就是可以接受的，但是将性能提升至60fps则可以明显提升交互感和逼真感，但是一般来说超过75fps一般就不容易察觉到有明显的流畅度提升了。如果帧率超过屏幕刷新率只会浪费图形处理的能力，因为显示器不能以这么快的速度更新，这样超过刷新率的帧率就浪费掉了。 在同一视频，同一码率的情况下，帧数越大，则画质越不好。尤其是运动的画面。因为每张画面会分担每秒有限的文件体积，如果画面越多，那么每张画面所能表现的内容就越有限。 当画面的FPS达到60帧/秒时，已经能满足绝大部分应用需求。一般情况下，如果能够保证游戏画面的平均FPS能够达到30帧/秒，那么画面已经基本流畅；能够达到50帧/秒，就基本可以体会到行云流水的感觉了。一般人很难分辨出60 帧/秒与100帧/秒有什么不同。 帧率设置使用-r选项ffmpeg -i input -r fps output例如：ffmpeg -i input.avi -r 30 output.mp4 分辨率最好理解的概念了，表示画面的大小，单位是像素 px。和编码率的关系：越高的分辨率，需要越高的编码率，因为图像的细节多了，需要的文件体积也应该增大，否则还不如画面小一些，你会发现同一码率，画面越大，图像的马赛克程度越明显。 采样率每秒钟对音频信号的采样次数，采样频率越高声音还原度越高，声音更加自然。单位是赫兹 Hz。音频文件一般使用的采样率是 44100 Hz ，也就是一秒钟采样 44100 次，之所以使用这个数值是因为经过了反复实验，人们发现这个采样精度最合适，低于这个值就会有较明显的损失，而高于这个值人的耳朵已经很难分辨，而且增大了数字音频所占用的空间。我们所使用的CD的采样标准就是44.1k，目前44.1k还是一个最通行的标准。 常见用法主要参数-i 设定输入流-f 设定输出格式-ss 开始时间视频参数：-b 设定视频流量，默认为200Kbit/s-r 设定帧速率，默认为25-s 设定画面的宽与高-aspect 设定画面的比例-vn 不处理视频-vcodec 设定视频编解码器，未设定时则使用与输入流相同的编解码器音频参数：-ar 设定采样率-ac 设定声音的Channel数-acodec 设定声音编解码器，未设定时则使用与输入流相同的编解码器-an 不处理音频 用法举例 格式转换ffmpeg最常用功能就是格式转换，在这里要特别提的是，音、视频文件格式有两个容器格式（如mov、flv)与编码格式（如H.264）ffmpeg -i input.flv output.mp4 尺寸变换ffmpeg -i input.mp4 -s 640x360 output.mp4 剪切视频段ffmpeg -i input.mp4 -ss 5 -t 10 output.mp4上面的命令-ss 5指定从输入视频第5秒开始截取，-t 10指明最多截取10秒。 但是上面的命令可能会比较慢，更好的命令如下： ffmpeg -ss 5 -i input.mp4 -t 10 -c:v copy -c:a copy output.mp4上面的命令把-ss 5放到-i前面，与原来的区别是，这样会先跳转到第5秒在开始解码输入视频，而原来的会从开始解码，只是丢弃掉前5秒的结果。 而-c:v copy -c:a copy标示视频与音频的编码不发生改变，而是直接复制，这样会大大提升速度，因为这样就不需要完全解码视频（视频剪切也不需要完全解码） 注意：-vcodec 有一个缩写叫做 -c:v ， -acodec 有一个缩写叫做 -c:a 。 改变FPSFFmpeg可以用于降低或提高视频的帧率，因为信息丢失不可逆法则，提高帧率只会简单地让某些帧的画面多重复一次或多次，所以提高帧率不会提高画质。 ffmpeg -i input.mp4 -r 30 output.mp4 上面的命令，不论原始视频帧率是多少，输出视频都会是30帧每秒。这种情况之下视频的时间轴不会变化，不会有慢动作或快动作的效果。 截取图片视频10秒的地方(-ss 参数)截取一张1920x1080尺寸大小的，格式为jpg的图片 -ss后跟的时间单位为秒 ffmpeg -i input_video.mp4 -y -f image2 -t 0.001 -ss 10 -s 1920x1080 output.jpg把视频的前30帧转换成一个Gif ffmpeg -i input_video.mp4 -vframes 30 -y -f gif output.gif 将视频转成 gif ffmpeg -ss 00:00:00.000 -i input.mp4 -pix_fmt rgb24 -r 10 -s 320x240 -t 00:00:10.000 output.gif 将输入的文件从(-ss)设定的时间开始以10帧频率，输出到320x240大小的 gif 中，时间长度为-t 设定的参数。通过这样转换出来的 gif 一般都比较大，可以使用 ImageMagick 来优化图片的大小。 转码时的输出信息 frame= 28 fps=0.0 q=0.0 size= 2kB time=00:00:01.49 bitrate= 11.3kbits/sframe= 30 fps= 17 q=-0.0 size= 13kB time=00:00:01.49 bitrate= 71.1kbits/frame= 34 fps= 15 q=-0.0 size= 20kB time=00:00:01.66 bitrate= 99.9kbits/frame= 38 fps= 13 q=-0.0 size= 31kB time=00:00:01.83 bitrate= 138.1kbits/frame= 42 fps= 12 q=-0.0 size= 40kB time=00:00:02.00 bitrate= 165.1kbits/frame= 46 fps= 11 q=-0.0 size= 49kB time=00:00:02.17 bitrate= 185.4kbits/frame= 50 fps= 10 q=-0.0 size= 57kB time=00:00:02.34 bitrate= 199.3kbits/frame= 54 fps= 10 q=-0.0 size= 63kB time=00:00:02.51 bitrate= 204.9kbits/frame= 58 fps=9.5 q=-0.0 size= 74kB time=00:00:02.68 bitrate= 226.2kbits/frame= 62 fps=9.2 q=-0.0 size= 85kB time=00:00:02.68 bitrate= 260.5kbits/frame= 65 fps=8.8 q=-0.0 size= 92kB time=00:00:02.85 bitrate= 264.9kbits/ FFmpeg 确实不会显示进度条和百分比，不过，它会给你比进度条和百分比还要多的信息。 最左边的 frame= 65 是转码所进行到的帧数，显示 65 就表示现在已经转到了第 65 帧。 第二个 fps=8.8 中的 FPS 就是 Frame per Second ，也就是现在电脑每秒所处理的帧的数量。注意这个数字跟视频的帧率并无关系。 其实我也不知道后面那个 q=-0.0 是什么意思。 接下来的 size= 92kB 表示现在已经转换出来的视频的体积，这个数字只会越变越大啊。 第五个 time=00:00:02.85 顾名思义就是时间了，它是已经转换出来的视频的时间。在我看来，它也是一个比百分比进度条更加精准的进度显示。 转码需要多久，最后在哪里能看到我也不懂，希望知道的人看见可以留言补充。 官方文档：https://www.ffmpeg.org/ffmpeg.html#Video-Options]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>FFmpeg</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用hexo+github搭建个人博客遇到的问题及解决方法]]></title>
    <url>%2F2017%2Fhexo.html</url>
    <content type="text"><![CDATA[之前一直就想搭建自己的个人博客了，但一直拖着没动手，昨天终于花了一天的时间完成了，从安装到域名注册到配置美化，但还没有完成，之后还会一直继续修改。 关于搭建的教程网上各种教程，但是要学会分辨，有些是错的，这里我也不多说了，只说一下搭建过程中遇到的问题及解决方法。 1、port：4000端口打不开1、可能被占用了，改为5000。但并不是修改配置文件中的port参数，而是hexo\node_modules\hexo-server中的index.js，修改其中的port参数。2、可能是修改主题配置文件时产生错误无法显示，重新下载主题配置文件覆盖后得到解决。 2、可以在本地预览但是不能同步到GitHub是deploy的空格问题，配置文件中所有的冒号后面都要加一个空格！ type: git， （不是GitHub）repository:git@github.com:qisenshi/qisenshi.github.io.git（也不是https那个url） 3、在本地预览正常但在Chrome上显示很错乱可能是main.css重写出现错误，删除public中的main.css后重新hexo g,hexo d，问题解决 4、注册域名到阿里云去注册了一个域名，然后绑定你的github.io域名，然后解析域名，但坑爹的是.win域名后缀不能备案，除此之外很多国际域名都不可以备案，谨慎购买！ 5、美化主题，修改配置文件浏览了一圈发现简介大方的next主题很不错，就clone了这个主题，而且这个主题有官方网站，之后的各种配置完全可以参考. 6、写文章问题搭建完博客怎么写文章呢，新建的文章new出来都是md格式的，所以要下载一个md编辑器，这里推荐MarkdownPad可以直接打开本地编辑，Learning-Markdown (Markdown 入门参考)也有一些markdown的写作方法，不难。 7、搜索引擎验证网站下载HTML文件验证的时候明明可以打开却一直提示验证失败，原来是上传GitHub的过程中会自动添加一些东西，直接去GitHub上修改，只保留HTML中的内容，然后验证成功完成添加。 最后，附个关于主题优化及hexo进阶的链接：Hexo+nexT主题搭建个人博客 再附上两个搭建过程写的还算清晰的博客： http://blog.csdn.net/wkzd2016/article/details/70170786 http://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>-hexo</tag>
      </tags>
  </entry>
</search>