<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[链表的常见操作]]></title>
    <url>%2F2017%2Fnodelist.html</url>
    <content type="text"><![CDATA[若只论链表与二叉树，链表又更容易将指针指的出神入化，二叉树稍逊，一个 left, 一个 right 的二次元世界，弄不出什么花来。 所以想要把握指针的灵魂，练就一身弹”指”神通的俊功夫，还得多练练链表。 下面，我就随意截取几道经典的链表问题，陪诸君练练手。（为简化问题，凸显实质，皆为单链表） struct ListNode { int val; ListNode *next; ListNode(int x) : val(x), next(nullptr) {} }; 链表的逆 1-&gt;2-&gt;3-&gt;4-&gt;5 ^ root想要逆序，最直接的想法，就是希望上图中的链表指向反过来。我们借用一个空指针 node 指向一个空节点: 1-&gt;2-&gt;3-&gt;4-&gt;5 | ListNode* reverse(ListNode *root) { ^ | ListNode *node = nullptr; root | } | null | ^ | node | 第一步，我们希望节点1从单链表中剥离，于是让其指向 node, 但我们不能因此而找不到链表索引，故需要一个额外的指针 next, 指向后续节点：几个简单的指针转移，便将节点1反向的去指向了 node 节点。如法炮制的话，节点2, 节点3, 节点4, 节点5 都调转枪头，我们的目的便达到了。 ListNode* reverse(ListNode *root) { ListNode *node = nullptr; while (root) { ListNode *next = root-&gt;next; root-&gt;next = node; node = root; root = next; } return node; } 链表除重1-&gt;1-&gt;2-&gt;2-&gt;3-&gt;4^headcur如果用一个指针 cur 来指向当前节点的话，出现重复的条件即为：cur-&gt;value == cur-&gt;next-&gt;value，如上图中，1 与 1 是重复的。我们只要想办法去掉重复的那个 1 即可。 1-&gt;1-&gt;2-&gt;2-&gt;3-&gt;4 | if (cur-&gt;val == cur-&gt;next-&gt;val) { ^ ^ ^ | ListNode *next = cur-&gt;next-&gt;next; cur next | delete cur-&gt;next; | ^ | cur-&gt;next = next; |_____| | } 这个思路简单，易懂，但这个问题却又是很多复杂问题的基础。还是需要注意的。 ListNode *removeDuplicates(ListNode *head) { if (head == nullptr) return head; for (ListNode *cur=head; cur-&gt;next; ) if (cur-&gt;val == cur-&gt;next-&gt;val) { ListNode *next = cur-&gt;next-&gt;next; delete cur-&gt;next; cur-&gt;next = next; } else { cur = cur-&gt;next; } return head; } 链表合并a(1-&gt;2-&gt;3) b(4-&gt;5-&gt;6) ==&gt; 1-&gt;4-&gt;2-&gt;5-&gt;3-&gt;6这个问题本身非常简单，但想通过这个基本问题，引申出链表问题一个非常常见的技巧。即设立 dummy 节点，可以称为是傀儡节点，其作用在于让合成的新链表有一个着手点。这个节点的值可以随意，我们最终返回的，实际上是 dummy.next;要注意，每一步指针的捣腾都是按照顺序的，用笔纸画一画会比较清楚。 ListNode *shuffleMerge(ListNode *a, ListNode *b) { ListNode dummy(0), *tail = &amp;dummy; while (a &amp;&amp; b) { tail-&gt;next = a; tail = a; a = a-&gt;next; tail-&gt;next = b; tail = b; b = b-&gt;next; } tail-&gt;next = a ? a : b; return dummy.next; } 移动节点a(1-&gt;2-&gt;3),b(1-&gt;2-&gt;3)==&gt; a(2-&gt;3),b(1-&gt;1-&gt;2-&gt;3)这个问题几乎不足为道，但这个操作，将有助于咱们更深入的对链表进行研究。封装这个操作，我们可以避免纠缠于非常基本的问题。(a 为 source(s), b 为 dest(d)) void moveNode(ListNode **destRef, ListNode **sourceRef) { ListNode *newNode = *sourceRef; *sourceRef = newNode-&gt;next; newNode-&gt;next = *destRef; *destRef = newNode; } 顺序合并1-&gt;3-&gt;5 , 2-&gt;4-&gt;6 ==&gt; 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;6 这也是非常基本的操作，结合上述的傀儡节点与 moveNode 两个技巧，应该可以很轻松的写出如下思路： ListNode *sortedMerge(ListNode *a, ListNode *b) { ListNode dummy(0), *tail = &amp;dummy; for ( ;a &amp;&amp; b; tail = tail-&gt;next) { if (a-&gt;val &lt;= b-&gt;val) moveNode(&amp;(tail-&gt;next), &amp;a); else moveNode(&amp;(tail-&gt;next), &amp;b); } tail-&gt;next = a ? a : b; return dummy.next; } 傀儡节点毕竟耗费了额外的空间，同样的思路，能否改进为不耗费额外空间呢？我们来思考另一个例子： ListNode *sortedMerge(ListNode *a, ListNode *b) { ListNode *ret = nullptr, **lastPtrRef = &amp;ret; for (; a &amp;&amp; b; lastPtrRef = &amp;((*lastPtrRef)-&gt;next)) { if (a-&gt;val &lt;= b-&gt;val) moveNode(lastPtrRef, &amp;a); else moveNode(lastPtrRef, &amp;b); } *lastPtrRef = a ? a : b; return ret; } 思路完全一致，但不消耗额外空间。即无需傀儡，直接上位。 另，这个问题也可以用递归解决，权当额外思考题了(可能更加直观)： ListNode *sortedMerge(ListNode *a, ListNode *b) { ListNode *ret = nullptr; if (a == nullptr) return b; else if (b == nullptr) return a; if (a-&gt;val &lt;= b-&gt;val) { ret = a; ret-&gt;next = sortedMerge(a-&gt;next, b); } else { ret = b; ret-&gt;next = sortedMerge(a, b-&gt;next); } return ret; } 顺序插入newnode(4),head(1-&gt;3-&gt;5-&gt;7-&gt;8)==&gt; 1-&gt;3-&gt;4-&gt;5-&gt;7-&gt;8 给一个有序链表 head, 一个新节点 newNode. 将新节点插入该链表中。 问题本身简单到不行，但我们仅仅是以此来复习一下上次所讲的三种策略。 直接插入法（教科书法） 傀儡节点 引用法（指针的指针） 首先最朴素的第一种方法，也是教科书上经常讲述的方案。在这个问题里，我们需要分别考虑两种情况：其一，newNode 的值比 head 还要小，那么它应该直接放到最前面（这个动作是连接而非插入）；其二，newNode 的值比 head 要大，那么毫无疑问，需要遍历整个链表，找到 newNode 应该插入的位置，进行插入。 if (*headRef == nullptr || (*headRef)-&gt;val &gt;= newNode-&gt;val) { newNode-&gt;next = *headRef; *headRef = newNode; } else { ListNode *curr = *headRef; while (curr-&gt;next != nullptr &amp;&amp; curr-&gt;next-&gt;val &lt; newNode-&gt;val) curr = curr-&gt;next; newNode-&gt;next = curr-&gt;next; curr-&gt;next = newNode; } 简单又好理解。 然后我们来看看第二种，很常用的傀儡法。为了避免像上面分两种情况分别处理那么麻烦，不如自立山头，统一处理。 void sortedInsert(ListNode **headRef, ListNode *newNode) { ListNode dummy(0), *tail = &amp;dummy; dummy.next = *headRef; while (tail-&gt;next != NULL &amp;&amp; tail-&gt;next-&gt;val &lt; newNode-&gt;val) tail = tail-&gt;next; newNode-&gt;next = tail-&gt;next; tail-&gt;next = newNode; *headRef = dummy.next; } 可以看到，代码完全照搬上面的第二种情况。更加紧凑。 好了，最后我们来看看最精简的第三种方案，使用引用。细心的童鞋会发现，上面我们定位的一直是 curr-&gt;next 节点。这个 next 很罗嗦，但普通的插入，必须要知道前后节点，所以也是不得已为之。如果我们采用引用，则只需要知道后面的节点即可。 ListNode **currRef = headRef; while (*currRef != nullptr &amp;&amp; (*currRef)-&gt;val &lt; newNode-&gt;val) currRef = &amp;((*currRef)-&gt;next); newNode-&gt;next = *currRef; *currRef = newNode; 可以看到，我们将 newNode-&gt;next 指向 curr 节点后，直接将 newNode 节点生生挪到链表里去了。这是因为 currRef 处于链表中第 2 个(从 0 开始)位置，当 *currRef = newNode 之后，相当于将这个位置指向的地址换成了 newNode. 而 newNode 已经和后面的节点相连，所以很顺利的顺延了后续链表。 寥寥五行，非常精简。上述三种思路都应该掌握，而核心应该掌握最后一种方案。 链表排序我们趁热打铁，上面讨论了 sortedInsert 方法的实现。那么我们倒过来，实现最基础的面试题，插入排序。 思路呢，非常简单，弄一个空链表：ListNode *newHead = nullptr;, 然后遍历整个链表，将每一个节点 sortedInsert 到 newHead 中。代码如下： void insertSort(ListNode **headRef) { ListNode *newHead = nullptr; for (ListNode *curr = *headRef, *next; curr; curr = next) { next = curr-&gt;next; sortedInsert(&amp;newHead, curr); } *headRef = newHead; } 转自：https://segmentfault.com/a/1190000002490878#articleHeader3]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析openstack虚拟化技术]]></title>
    <url>%2F2017%2Fvirtualization.html</url>
    <content type="text"><![CDATA[opensatck Openstack：OpenStack is a cloud operating system that controls large pools of compute, storage, and networking resources throughout a datacenter, all managed through a dashboard that gives administrators control while empowering their users to provision resources through a web interface. 以上是官网对 OpenStack 的定义，OpenStack 对数据中心的计算、存储和网络资源进行统一管理。 由此可见，OpenStack 针对的是 IT 基础设施，是 IaaS 这个层次的云操作系统。 虚拟化虚拟化是云计算的基础。虚拟机共享物理机的 CPU、内存、IO 硬件资源，但逻辑上虚拟机之间是相互隔离的。物理机我们一般称为宿主机（Host），宿主机上面的虚拟机称为客户机（Guest）。Host将自己的硬件资源虚拟化并提供给 Guest 使用主要是通过一个叫做 Hypervisor 的程序实现的。 Hypervisor是一种运行在物理服务器和操作系统之间的中间软件层,可允许多个操作系统和应用共享一套基础物理硬件，因此也可以看作是虚拟环境中的“元”操作系统，它可以协调访问服务器上的所有物理设备和虚拟机，也叫虚拟机监视器（Virtual Machine Monitor）。Hypervisor是所有虚拟化技术的核心。非中断地支持多工作负载迁移的能力是Hypervisor的基本功能。当服务器启动并执行Hypervisor时，它会给每一台虚拟机分配适量的内存、CPU、网络和磁盘，并加载所有虚拟机的客户操作系统。根据 Hypervisor 的实现方式和所处的位置，虚拟化又分为两种：1型虚拟化和2型虚拟化 1型虚拟化Hypervisor 直接安装在物理机上，多个虚拟机在 Hypervisor 上运行。Hypervisor 实现方式一般是一个特殊定制的 Linux 系统。Xen 和 VMWare 的 ESXi 都属于这个类型。 2型虚拟化物理机上首先安装常规的操作系统，比如 Redhat、Ubuntu 和 Windows。Hypervisor 作为 OS 上的一个程序模块运行，并对管理虚拟机进行管理。KVM、VirtualBox 和 VMWare Workstation 都属于这个类型。 理论上讲：1型虚拟化一般对硬件虚拟化功能进行了特别优化，性能上比2型要高；2型虚拟化因为基于普通的操作系统，会比较灵活，比如支持虚拟机嵌套。嵌套意味着可以在KVM虚拟机中再运行KVM。 KVM下面重点介绍KVM这种2型虚拟化技术。基本概念KVM 全称是Kernel-Based Virtual Machine。即 KVM 是基于 Linux 内核实现的。OpenStack 对 KVM 支持得也最好。KVM有一个内核模块叫 kvm.ko，只用于管理虚拟 CPU 和内存。而IO 的虚拟化，比如存储和网络设备由Linux 内核和Qemu来实现。即KVM 本身只关注虚拟机调度和内存管理这两个方面。IO 外设的任务交给 Linux 内核和Qemu。 Libvirt简单说就是 KVM 的管理工具。其实，Libvirt除了能管理 KVM 这种 Hypervisor，还能管理 Xen，VirtualBox 等。OpenStack底层也使用 Libvirt，所以很有必要学习一下。Libvirt 包含 3 个东西：后台 daemon 程序 libvirtd、API库和命令行工具 virsh libvirtd是服务程序，接收和处理 API 请求； API 库使得其他人可以开发基于 Libvirt 的高级工具，比如 virt-manager，这是个图形化的 KVM 管理工具，后面我们也会介绍； virsh 是我们经常要用的KVM 命令行工具，后面会有使用的示例。 作为 KVM 和OpenStack 的实施人员，virsh 和virt-manager 是一定要会用的。 CPU虚拟化KVM 的虚拟化是需要CPU 硬件支持的。虚机中的每一个虚拟 vCPU 则对应 qemu-kvm 进程中的一个线程。看下图即虚机的 vCPU 总数可以超过物理 CPU 数量，这个叫 CPU overcommit（超配）。 KVM 允许 overcommit，这个特性使得虚机能够充分利用宿主机的 CPU 资源。但在使用overcommit 的时候，需要对虚机的负载情况有所了解，需要测试。 内存虚拟化KVM 通过内存虚拟化共享物理系统内存，动态分配给虚拟机。看下图为了在一台机器上运行多个虚拟机，KVM 需要实现 VA（虚拟内存） -&gt; PA（物理内存） -&gt; MA（机器内存）直接的地址转换。虚机 OS 控制虚拟地址到客户内存物理地址的映射（VA -&gt; PA），但是虚机 OS 不能直接访问实际机器内存，因此 KVM 需要负责映射客户物理内存到实际机器内存 （PA -&gt; MA）。内存也是可以 overcommit 的，即所有虚机的内存之和可以超过宿主机的物理内存。但使用时也需要充分测试，否则性能会受影响。 网络虚拟化这是 OpenStack 官网上给出的计算节点（可以理解为 KVM 的宿主机）虚拟网络的逻辑图，上面的网络设备很多，层次也很复杂。网络虚拟化中最重要的两个东西：Linux Bridge 和 VLAN。]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>-openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析面向对象编程]]></title>
    <url>%2F2017%2Fobject.html</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>-object</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析C++之STL迭代器]]></title>
    <url>%2F2017%2Fiterator.html</url>
    <content type="text"><![CDATA[泛型编程 STL是一种泛型编程。面向对象编程关注的是编程的数据方面，而泛型编程关注的是算法。它们之间的共同点是抽象和创建可重用代码，但理念决然不同。 泛型编程旨在编写独立于数据类型的代码，在C++中完成通用程序的工具是模板，模板使得算法独立于存储的数据类型，而迭代器使算法独立于使用的容器的类型。 什么是迭代器迭代器可以理解为一种泛型的指针，可以指向容器中的任一位置；而普通指针可以指向内存中的任一地址。STL的每一个容器类模版中，都定义了一组对应的迭代器类。使用迭代器，算法函数可以访问容器中指定位置的元素，而无需关心元素的具体类型。泛型编程中的函数不仅独立于容器中存储的数据类型，而且独立于容器本身的数据结构。模板提供了存储在容器中的数据类型的通用表示，因此，还需要遍历容器中的值的通用表示，迭代器正是这样的通用表示。比如我们可以创建一个find()函数，不仅可以查找数组，链表，也可以查找其他的容器类型。 迭代器的用法(1) 每种容器类型都定义了自己的迭代器类型，如vector:vector&lt;int&gt;::iterator iter;这条语句定义了一个名为iter的变量，它的数据类型是由vector定义的iterator类型。 (2) 使用迭代器读取vector中的每一个元素：vector&lt;int&gt; ivec(10,1); for(vector&lt;int&gt;::iterator iter=ivec.begin();iter!=ivec.end();++iter) { *iter=2; //使用 * 访问迭代器所指向的元素 } const_iterator: 只能读取容器中的元素，而不能修改。 for(vector&lt;int&gt;::const_iterator citer=ivec.begin();citer!=ivec.end();citer++) { cout&lt;&lt;*citer; //*citer=3; error } vector::const_iterator 和 const vector::iterator的区别const vector::iterator newiter=ivec.begin();*newiter=11; //可以修改指向容器的元素//newiter++; //迭代器本身不能被修改 (3) iterator的算术操作：iterator除了进行++,–操作，可以将iter+n,iter-n赋给一个新的iteraor对象。还可以使用一个iterator减去另外一个iterator.const vector::iterator newiter=ivec.begin();vector::iterator newiter2=ivec.end();cout&lt;&lt;”\n”&lt;&lt;newiter2-newiter;一個很典型使用vector的STL程式: #include &lt;vector&gt; #include &lt;iostream&gt; using namespace std; int main(void) { vector&lt;int&gt; v; v.push_back(1); v.push_back(2); v.push_back(3); vector&lt;int&gt;::iterator it; for (it = v.begin(); it != v.end(); ++it) { cout &lt;&lt; *it &lt;&lt; &apos; &apos;; } cout &lt;&lt; endl; 迭代器可以很好的兼容C++的内置类型，特别是常见的C++指针被视为C++数组的迭代器。当然，在标准的C++库中所有的容器都定义了一个迭代器类型，即嵌套类型的迭代器，代表各自的指针类型。 迭代器的类型迭代器可以分为不同的种类，这是因为他们使用不同的算法、不同的要求附加在其身上。例如，find()算法需要一个可以递增的迭代器，而reverse()算法需要一个可以递减的迭代器等。总之，在STL和C++标准库中有5种迭代器。（1）、输入迭代器(Input Iterator):只能向前单步迭代元素，不允许修改由该迭代器所引用的元素；（2）、输出迭代器(Output Iterator):只能向前单步迭代元素，对由该迭代器所引用的元素只有写权限；（3）、向前迭代器(Forward Iterator):该迭代器可以在一个区间中进行读写操作，它拥有输入迭代器的所有特性和输出迭代器的部分特性，以及向前单步迭代元素的能力；（4）、双向迭代器(Bidirectional Iterator):在向前迭代器的基础上增加了向后单步迭代元素的能力；（5）、随机访问迭代器(Random Access Iterator):不仅综合以后4种迭代器的所有功能，还可以像指针那样进行算术计算；vector、deque提供的是随机访问迭代器，list提供的是双向迭代器，set和map提供的是向前迭代器。 相应的操作集为：除了输出迭代器，其他类别的迭代器形成了一个层次结构：需要低级类别迭代器的地方，可使用任意一种更高级的迭代器。例如，对于需要输入迭代器的算法，可传递前向、双向或随机访问迭代器调用该算法。而反之则不行。注意：向算法传递无效的迭代器类别所引起的错误，无法保证会在编译时被捕获到。map, set, list类型提供双向迭代器，而string, vector和deque容器上定义的迭代器都是随机访问迭代器，用作访问内置数组元素的指针也是随机访问迭代器。istream_iterator是输入迭代器，ostream_iterator是输出迭代器。另外，虽然map和set类型提供双向迭代器，但关联容器只能使用这部分算法的一个子集。因为关联容器的键是const对象。因此，关联容器不能使用任何写序列元素的算法。只能使用与关联容器绑在一起的迭代器来提供用于读操作的实参。因此，在处理算法时，最好将关联容器上的迭代器视为支持自减运算的输入迭代器，而不是完整的双向迭代器。最后需要注意的是，stack、queue、priority_queue 都不支持任一种迭代器，它们都是容器适配器类型，stack是用vector/deque/list对象创建了一个先进后出容器，queue是用deque或list对象创建了一个先进先出容器，priority_queue是用vector/deque创建了一个排序队列 常用的容器成员]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>-C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中struct和class的区别]]></title>
    <url>%2F2017%2Fstructclass.html</url>
    <content type="text"><![CDATA[C++中的struct对C中的struct进行了扩充，它已经不再只是一个包含不同数据类型的数据结构了，它已经获取了太多的功能。 struct和class都可以继承，都可以包含成员函数，都可以实现多态，都可以有构造函数和西沟函数。但主要有两点区别 1、最本质的一个区别就是默认的访问控制：默认的继承访问权限struct是public的，class是private的。所以我们在平时写类继承的时候，通常会这样写：class B : public A就是为了指明是public继承，而不是用默认的private继承。 当然，到底默认是public继承还是private继承，取决于子类而不是基类。如： struct A{}； class B : A{}; //private继承 struct C : B{}； //public继承 struct作为数据结构的实现体，它默认的数据访问控制是public的，而class作为对象的实现体，它默认的成员变量访问控制是private的 到底是用struct还是class，完全看个人的喜好，你可以将程序里所有的class全部替换成struct，它依旧可以很正常的运行。但我给出的最好建议，还是：当你觉得你要做的更像是一种数据结构的话，那么用struct，如果你要做的更像是一种对象的话，那么用class。 当然，我在这里还要强调一点的就是，对于访问控制，应该在程序里明确的指出，而不是依靠默认，这是一个良好的习惯，也让你的代码更具可读性。 2、“class”这个关键字还用于定义模板参数，但关键字“struct”不用于定义模板参数。这一点在Stanley B.Lippman写的Inside the C++ Object Model有过说明。 3、其他区别还是上面所说的，C++中的struct是对C中的struct的扩充，既然是扩充，那么它就要兼容过去C中struct应有的所有特性。例如你可以这样写： struct A//定义一个struct { char c1; int n2; double db3; }; A a={&apos;p&apos;, 7, 3.1415926}; //定义时直接赋值 也就是说struct可以在定义的时候用{}赋初值。但class不行，而且当struct中包含构造函数（或虚函数），struct也不能用{}赋初值了。 而加入一个普通的成员函数呢？你会发现{}依旧可用。其实你可以将普通的函数理解成对数据结构的一种算法，这并不打破它数据结构的特性。那么，看到这里，我们发现即使是struct想用{}来赋初值，它也必须满足很多的约束条件，这些条件实际上就是让struct更体现出一种数据机构而不是类的特性。那为什么我们在上面仅仅将struct改成class，{}就不能用了呢？其实问题恰巧是我们之前所讲的——访问控制！你看看，我们忘记了什么？对，将struct改成class的时候，访问控制由public变为private了，那当然就不能用{}来赋初值了。加上一个public，你会发现，class也是能用{}的，和struct毫无区别！！！做个总结，从上面的区别，我们可以看出，struct更适合看成是一个数据结构的实现体，class更适合看成是一个对象的实现体。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>-C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十大机器学习算法介绍（一）]]></title>
    <url>%2F2017%2FML.html</url>
    <content type="text"><![CDATA[机器学习算法分为三类：有监督学习、无监督学习、增强学习。有监督学习需要标识数据（用于训练，即有正例又有负例），无监督学习不需要标识数据，增强学习介于两者之间（有部分标识数据）。下面将向大家具体介绍机器学习中10大算法（主要介绍有监督、无监督两类）。 监督学习1、 决策树决策树是一种树形结构，为人们提供决策依据，决策树可以用来回答yes和no问题，它通过树形结构将各种情况组合都表示出来，每个分支表示一次选择（选择yes还是no），直到所有选择都进行完毕，最终给出正确答案。 定义：决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。使用决策树进行决策的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果。构造决策树的关键步骤是分裂属性。所谓分裂属性就是在某个节点处按照某一特征属性的不同划分构造不同的分支，其目标是让各个分裂子集尽可能地“纯”。尽可能“纯”就是尽量让一个分裂子集中待分类项属于同一类别。分裂属性分为三种不同的情况： 1、属性是离散值且不要求生成二叉决策树。此时用属性的每一个划分作为一个分支。 2、属性是离散值且要求生成二叉决策树。此时使用属性划分的一个子集进行测试，按照“属于此子集”和“不属于此子集”分成两个分支。 3、属性是连续值。此时确定一个值作为分裂点split_point，按照&gt;split_point和&lt;=split_point生成两个分支。 ID3信息增益（information gain）表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。定义：特征A对训练数据集D的信息增益g（D,A），定义集合D的经验熵H（D）与特征A给定条件下D的经验条件熵H（D|A）之差。一般地，熵与条件熵之差成为互信息（mutual information），决策树学习中的信息增益等价于训练数据集中类与特征的互信息。ID3算法的核心是在决策树各个子结点上应用信息增益准则选择特征，递归的构建决策树。具体方法是:从根结点开始，对结点计算所有可能的特征的信息增益，选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子结点；再对子结点递归调用以上方法，构建决策树。直到所有特征的信息增益均很小或没有特征可以选择为止。 C4.5ID3算法存在一个问题，就是偏向于多值属性，例如，如果存在唯一标识属性ID，则ID3会选择它作为分裂属性，这样虽然使得划分充分纯净，但这种划分对分类几乎毫无用处。ID3的后继算法C4.5使用增益率（gain ratio）的信息增益扩充，试图克服这个偏倚。C4.5算法首先定义了“分裂信息”，其定义可以表示成： 其中各符号意义和ID3算法相同，然后增益率定义为： C4.5选择具有最大增益率的属性作为分裂属性，其具体应用于ID3类似。 2、 朴素贝叶斯分类器]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>-machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用hexo+github搭建个人博客遇到的问题及解决方法]]></title>
    <url>%2F2017%2Fhexo.html</url>
    <content type="text"><![CDATA[之前一直就想搭建自己的个人博客了，但一直拖着没动手，昨天终于花了一天的时间完成了，从安装到域名注册到配置美化，但还没有完成，之后还会一直继续修改。 关于搭建的教程网上各种教程，但是要学会分辨，有些是错的，这里我也不多说了，只说一下搭建过程中遇到的问题及解决方法。 1、port：4000端口打不开1、可能被占用了，改为5000。但并不是修改配置文件中的port参数，而是hexo\node_modules\hexo-server中的index.js，修改其中的port参数。2、可能是修改主题配置文件时产生错误无法显示，重新下载主题配置文件覆盖后得到解决。 2、可以在本地预览但是不能同步到GitHub是deploy的空格问题，配置文件中所有的冒号后面都要加一个空格！ type: git， （不是GitHub）repository:git@github.com:qisenshi/qisenshi.github.io.git（也不是https那个url） 3、在本地预览正常但在Chrome上显示很错乱可能是main.css重写出现错误，删除public中的main.css后重新hexo g,hexo d，问题解决 4、注册域名到阿里云去注册了一个域名，然后绑定你的github.io域名，然后解析域名，但坑爹的是.win域名后缀不能备案，除此之外很多国际域名都不可以备案，谨慎购买！ 5、美化主题，修改配置文件浏览了一圈发现简介大方的next主题很不错，就clone了这个主题，而且这个主题有官方网站，之后的各种配置完全可以参考. 6、写文章问题搭建完博客怎么写文章呢，新建的文章new出来都是md格式的，所以要下载一个md编辑器，这里推荐MarkdownPad可以直接打开本地编辑，Learning-Markdown (Markdown 入门参考)也有一些markdown的写作方法，不难。 7、搜索引擎验证网站下载HTML文件验证的时候明明可以打开却一直提示验证失败，原来是上传GitHub的过程中会自动添加一些东西，直接去GitHub上修改，只保留HTML中的内容，然后验证成功完成添加。 最后，附个关于主题优化及hexo进阶的链接：Hexo+nexT主题搭建个人博客 再附上两个搭建过程写的还算清晰的博客： http://blog.csdn.net/wkzd2016/article/details/70170786 http://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html]]></content>
      <categories>
        <category>others</category>
      </categories>
      <tags>
        <tag>-hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析B树，B+/-树，AVL树，红黑树]]></title>
    <url>%2F2017%2FBST.html</url>
    <content type="text"><![CDATA[B树——二叉搜索树##定义：1.所有非叶子结点至多拥有两个儿子（Left和Right）；2.所有结点存储一个关键字；3.非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树； B树的搜索，从根结点开始，如果查询的关键字与结点的关键字相等，那么就命中；否则，如果查询关键字比结点关键字小，就进入左儿子；如果比结点关键字大，就进入右儿子；如果左儿子或右儿子的指针为空，则报告找不到相应的关键字。 如果B树的所有非叶子结点的左右子树的结点数目均保持差不多（平衡），那么B树的搜索性能逼近二分查找；但它比连续内存空间的二分查找的优点是，改变B树结构（插入与删除结点）不需要移动大段的内存数据，甚至通常是常数开销。在实际使用中，通常是在B树的基础上添加平衡算法，编程平衡二叉树。平衡二叉树又叫AVL树，是由作者姓名命名的，平衡二叉树还有一个改进的版本，叫做红黑树。 BST效率总结 : 查找最好时间复杂度O(logN)，最坏时间复杂度O(N)。插入删除操作算法简单，时间复杂度与查找差不多 B-树——一种非二叉搜索树##定义 定义任意非叶子结点最多具有M个儿子，M&gt;2； 根节点的儿子树[2,M]； 除根节点之外的非叶子结点的儿子数为[M/2,M]； 每个节点存放至少M/2-1(向上取整)和至多M-1个关键字； 非叶子结点的关键字个数等于指向儿子的指针个数减去1 非叶子结点的关键字：K[1],K[2]…K[M-1],:且K[i]小于K[i+1]； 非叶子结点的指针：P[1],P[2],,,,,P[M],其中P[M]指向关键字大于K[M-1]的子树，其他P[i]指向关键字属于(K[i-1],k[i])的子树； 所有叶子节点位于同一层。 如M=3 B-树有着如下的特性： 关键字集合分布在整颗树中； 任何一个关键字出现且只出现在一个结点中； 搜索有可能在非叶子结点结束； 其搜索性能等价于在关键字全集内做一次二分查找； 自动层次控制； 同时，由于限制了除根结点以外的非叶子结点，至少含有M/2个儿子，确保了结点的至少利用率，其最低搜索性能为： 公式中，M为设定的非叶子节点最多子树的个数，N为关键字总数；所以B-树的性能总是等价于2分查找（与M值无关），也就没有B树平衡的问题；由于M/2的限制，在插入节点的时候，如果节点已经满了，需要将节点分裂成两个各占M/2的节点；删除节点的时候，需要将两个不足M/2的节点合并 B-Tree效率总结： 由于考虑磁盘储存结构，B树的查找、删除、插入的代价都远远要小于任何二叉结构树(读写磁盘次数的降低)。 B+树——多路搜索树定义：其定义基本与B-树同，除了： 非叶子结点的子树指针与关键字个数相同； 非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）； 为所有叶子结点增加一个链指针； 所有关键字都在叶子结点出现； AVL——平衡二叉搜索树定义： 平衡二叉树或为空树,或为如下性质的二叉排序树: 左右子树深度之差的绝对值不超过1; 左右子树仍然为平衡二叉树. 平衡因子BF=左子树深度－右子树深度.平衡二叉树每个结点的平衡因子只能是1，0，-1。若其绝对值超过1，则该二叉排序树就是不平衡的。 AVL树是最先发明的自平衡二叉查找树。在AVL树中任何节点的两个子树的高度最大差别为一，所以它也被称为高度平衡树。查找、插入和删除在平均和最坏情况下都是O（log n）。 红黑树——改进的AVL定义： 每个结点要么是红的，要么是黑的。 根结点是黑的。 每个叶结点，即空结点（NIL）是黑的。 如果一个结点是红的，那么它的俩个儿子都是黑的。 对每个结点，从该结点到其子孙结点的所有路径上包含相同数目的黑结点。 AVL是严格平衡树，因此在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多；红黑是弱平衡的，用非严格的平衡来换取增删节点时候旋转次数的降低,所以简单说，搜索的次数远远大于插入和删除，那么选择AVL树，如果搜索，插入删除次数几乎差不多，应该选择RB树。红黑树上每个结点内含五个域，color，key，left，right，p。如果相应的指针域没有，则设为NIL。 红黑树与AVL比较结构对比： AVL的结构高度平衡，RBT的结构基本平衡。平衡度AVL &gt; RBT.查找对比： AVL 查找时间复杂度最好，最坏情况都是O(logN)。 RBT 查找时间复杂度最好为O(logN)，最坏情况下比AVL略差。插入删除对比： AVL的插入和删除结点很容易造成树结构的不平衡，而RBT的平衡度要求较低。因此在大量数据插入的情况下，RBT需要通过旋转变色操作来重新达到平衡的频度要小于AVL。 如果需要平衡处理时，RBT比AVL多一种变色操作，而且变色的时间复杂度在O(logN)数量级上。但是由于操作简单，所以在实践中这种变色仍然是非常快速的。 当插入一个结点都引起了树的不平衡，AVL和RBT都最多需要2次旋转操作。但删除一个结点引起不平衡后，AVL最多需要logN 次旋转操作，而RBT最多只需要3次。因此两者插入一个结点的代价差不多，但删除一个结点的代价RBT要低一些。 AVL和RBT的插入删除代价主要还是消耗在查找待操作的结点上。因此时间复杂度基本上都是与O(logN) 成正比的。 总体评价：大量数据实践证明，RBT的总体统计性能要好于平衡二叉树。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>-数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++之inline内联函数浅析]]></title>
    <url>%2F2017%2Finline.html</url>
    <content type="text"><![CDATA[C语言中使用宏定义容易出错，而且不能调试，无法操作类的私有数据成员。所以，在C++中尽量用内联函数来代替宏代码。inline函数的另一个优点是，函数被内联后，编译器可以根据上下文自己决定优化措施。 什么是内联函数内联函数是C++的增强特性之一，用来降低程序的运行时间。当内联函数收到编译器的指示时，即可发生内联：编译器将使用函数的定义体来替代函数调用语句，这种替代行为发生在编译阶段而非程序运行阶段。 值得注意的是，内联函数仅仅是对编译器的内联建议，编译器是否觉得采取你的建议取决于函数是否符合内联的有利条件。如果函数体非常大，那么编译器将忽略函数的内联声明，而将内联函数作为普通函数处理。 如何使函数内联定义函数时，在函数的最前面以关键字“inline”声明函数，即可使函数称为内联声明函数。 例如： Class A { Public: inline int add(int a, int b) { return (a + b); }; } Class A { Public: int add(int a, int b); }; inline int A::add(int a, int b) { return (a + b); } 为什么要使用内联函数有时候我们会写一些功能专一的函数，这些函数的函数体不大，包含了很少的执行语句。例如在计算1~1000以内的素数时，我们经常会使用开方操作使运算范围缩小，这时我们会写一个函数： int root(int n) { return (int)sqrt((float)n); } 然后我们的求范围内素数的函数可以这样写。 int prime(int n) { int i; for (i = 2; i &lt;= root(n); i++) { if (n%i == 0) return 0; return 1; } } 当然，把root函数放在循环中不是个不明智的选择，但想象一下，在某个程序上下文内必须频繁地调用某个类似root的函数，其调用函数的花销会有多大：当遇到普通函数的调用指令时，程序会保存当前函数的执行现场，将函数中的局部变量以及函数地址压入堆栈，然后再将即将调用的新函数加载到内存中，这要经历复制参数值、跳转到所调用函数的内存位置、执行函数代码、存储函数返回值等过程，当函数执行完后，再获取之前正在调用的函数的地址，回去继续执行那个函数，运行时间开销简直太多了。 C++内联函数提供了替代函数调用的方案，通过inline声明，编译器首先在函数调用处使用函数体本身语句替换了函数调用语句，然后编译替换后的代码。因此，通过内联函数，编译器不需要跳转到内存其他地址去执行函数调用，也不需要保留函数调用时的现场数据。 inline函数的优缺点分析优点： 它通过避免函数调用所带来的开销来提高你程序的运行速度。 当函数调用发生时，它节省了变量弹栈、压栈的开销。 它避免了一个函数执行完返回原现场的开销。 通过将函数声明为内联，你可以把函数定义放在头文件内。 缺点： 因为代码的扩展，内联函数增大了可执行程序的体积。 C++内联函数的展开是中编译阶段，这就意味着如果你的内联函数发生了改动，那么就需要重新编译代码。 当你把内联函数放在头文件中时，它将会使你的头文件信息变多，不过头文件的使用者不用在意这些。 有时候内联函数并不受到青睐，比如在嵌入式系统中，嵌入式系统的存储约束可能不允许体积很大的可执行程序。 什么时候该使用内联函数当程序设计需要时，每个函数都可以声明为inline。下面列举一些有用的建议： 当对程序执行性能有要求时，那么就使用内联函数吧。 当你想宏定义一个函数时，那就果断使用内联函数吧。 在类内部定义的函数会默认声明为inline函数，这有利于 类实现细节的隐藏。 关键点 内联声明只是一种对编译器的建议，编译器是否采用内联措施由编译器自己来决定。甚至在汇编阶段或链接阶段，一些没有inline声明的函数编译器也会将它内联展开。 编译器的内联看起来就像是代码的复制与粘贴，这与预处理宏是很不同的：宏是强制的内联展开，可能将会污染所有的命名空间与代码，将为程序的调试带来困难。 所有中类中定义的函数都默认声明为inline函数，所有我们不用显示地去声明inline。 虚函数不允许内联。 虽然说模板函数放中头文件中，但它们不一定是内联的。（不是说定义在头文件中的函数都是内联函数）。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>-C++</tag>
      </tags>
  </entry>
</search>